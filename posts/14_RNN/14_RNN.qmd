---
title: "14: Recurrent Neural Networks"
author: "Derek Sollberger"
date: "2025-03-19"
format:
  html:
    toc: true
---

```{r}
#| echo: false
#| message: false
#| warning: false

library("palmerpenguins")
library("patchwork")
library("tidyverse")

penguins_df <- penguins |>
  na.omit()

adelie_color = "#fb7504"
chinstrap_color = "#c65ccc"
gentoo_color = "#067476"
```

# Session 14: Recurrent Neural Networks

## Learning objectives:

:::: {.columns}

::: {.column width="45%"}
- Discuss hidden layer size
- Introduce the notion of memory for neural nets
:::

::: {.column width="10%"}

:::

::: {.column width="45%"}
![neural network](NN_4_2_3.png)
:::

::::


# Cross Entropy

Recall, a step size in back propagation is

$$\text{step size} = \text{derivative} \cdot \text{learning rate}$$

::: {.callout-note}
## Cross Entropy Loss

When classifying among $C$ classes, for an array of predictions (after computing a softmax) $\vec{s}$ and its associated vector of true observations $\vec{y}$, the **cross entropy loss** is calculated as

$$L(\vec{s}, \vec{y}) = -\sum_{i=1}^{C} y_{i}\log s_{i}$$
:::

![cross entropy loss](cross_entropy_graph.png)

* logarithm of softmax
* larger derivative values for larger misclassification values
* larger step sizes for larger misclassification values
* image source: [Machine Learning Glossary](https://ml-cheatsheet.readthedocs.io/en/latest/index.html)

::: {.callout-tip}
## Cross Entropy Inference

As a logarithm (a monotonic transformation) of softmax and similar to the sum-of-squared residuals (SSR), we are likewise seeking lower values of errors.

* smaller cross entropy $\rightarrow$ better network
:::











# Math Example

We start with a sequence of natural numbers

$$\{8, 9, 10, ..., 100\}$$
and we will use a neural network to try to classify the numbers as prime numbers or composite numbers. In this simple example, the inputs are indicator variables

:::: {.columns}

::: {.column width="45%"}
* `div2`: number is divisible by 2
* `div3`: number is divisible by 3
* `div5`: number is divisible by 5
* `div7`: number is divisible by 7	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
and our network looks like

```{mermaid}
flowchart LR

input_1[div2]
input_2[div3]
input_3[div5]
input_4[div7]
output_1[composite]
output_2[prime]

input_1 --> output_1
input_1 --> output_2
input_2 --> output_1
input_2 --> output_2
input_3 --> output_1
input_3 --> output_2
input_4 --> output_1
input_4 --> output_2
```	
:::

::::

> What do you think will happen to the *weights* and bias values upon training the network?

After running the code for 100 epochs, the network calculations so far look like

$$Wx + b$$

$$\left[\begin{array}{rrrr}
  0.92 & 0.34 & 0.79 & 0.68 \\
  -0.40 & -0.45 & 0.80 & -0.36 \\
\end{array}\right]
\left[\begin{array}{c}
  x_{1} \\ x_{2} \\ x_{3} \\ x_{4} \\
\end{array}\right]
+
\left[\begin{array}{c}
  0.92 \\ 0.42 \\
\end{array}\right]$$


# Hidden Layer

To try to capture abstract notions with a neural network, we can employ a **hidden layer** between the input and output layers.

::: {.callout-note collapse="true"}
## Python code

```{python}
#| eval: false
class NN1H(pl.LightningModule):
  # Neural Network object
  # assumes one hidden layer (and default learning rate: 0.01)
  # inheirited class from LightningModule (for faster computations)

    def __init__(self, input_layer_size, hidden_layer_size,
                 output_layer_size, learning_rate = None):
        super().__init__()
        self.input_layer_size = input_layer_size #input layer size (number of explanatory variables)
        self.hidden_layer_size = hidden_layer_size
        self.learning_rate = learning_rate if learning_rate is not None else 0.01
        self.output_layer_size = output_layer_size #output layer size: 3 (number of penguin species)
        self.fc1 = nn.Linear(input_layer_size, hidden_layer_size)
        self.fc2 = nn.Linear(hidden_layer_size, output_layer_size)
        self.test_step_outputs = []

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

    def training_step(self, batch, batch_idx): # what happen in each train step
        x, y = batch
        output = self(x)
        loss = F.cross_entropy(output, y)
        # self.log('train_loss', loss, on_epoch=True) # use this for logging (e.g. using TensorBoard)
        return {'loss':loss}

    def test_step(self, batch, batch_idx): # what happen in each test step
        x, y = batch
        output = self(x)
        loss = F.cross_entropy(output, y)
        self.test_step_outputs.append(loss)
        return {'loss':loss}

    def on_test_epoch_end(self):
        epoch_average = torch.stack(self.test_step_outputs).mean()
        self.log("test_epoch_average", epoch_average)
        self.test_step_outputs.clear()  # free memory

    def configure_optimizers(self):
        optimizer = torch.optim.SGD(self.parameters(), lr = lr)
        return optimizer
```
:::

Once again, let us deploy the `palmerpenguins`:

* $x_{1}$: bill length (mm)
* $x_{2}$: bill depth (mm)
* $x_{3}$: flipper length (mm)
* $x_{4}$: body mass (g)

![neural network](NN_4_2_3.png)

$$\text{min-max normalization} \rightarrow Wx + b \rightarrow \text{ReLU} \rightarrow Wx + b \rightarrow \text{cross entropy}$$

After 100 epochs, our weights and bias values are

$$\begin{array}{c}
\text{min-max normalization} \\ 
\downarrow \\
\left[\begin{array}{rrrr}
  0.04 & -1.19 & 0.96 & 0.91 \\
  -1.59 & 0.65 & 0.02 & 0.16 \\
\end{array}\right]
\left[\begin{array}{c}
  x_{1} \\ x_{2} \\ x_{3} \\ x_{4} \\
\end{array}\right]
+
\left[\begin{array}{r}
  0.55 \\ 0.62 \\
\end{array}\right] \\
\downarrow \\
\text{ReLU} \\
\downarrow \\
\left[\begin{array}{rr}
  -1.00 & 1.17 \\
  -1.07 & -1.21 \\
  1.08 & -0.74 \\
\end{array}\right]
\left[\begin{array}{c}
  x_{1} \\ x_{2} \\ 
\end{array}\right]
+
\left[\begin{array}{r}
  -0.29 \\ 1.28 \\ -1.38 \\
\end{array}\right] \\
\downarrow \\
\text{cross entropy}
\end{array}$$


# Ethics Segment: How Data Happened

:::: {.columns}

::: {.column width="40%"}
![How Data Happened](How_Data_Happened.png)
:::

::: {.column width="10%"}
	
:::

::: {.column width="50%"}
* Chris Wiggins, Princeton PhD (1998) in theoretical physics

* "Statistical thinking from the 1700s onward rested fundamentally on the explosion of the collection of data about states, their people, and, quite often, people deemed to be deviant" --- How Data Happened, page 23
:::

::::


# Hidden Layer Size

::: {.callout-note collapse="true"}
## How do we decide on a hidden layer size?

Industry professionals and writers suggest powers of two:

$$d_{\text{model}} = 2, 4, 8, 16, ...$$

and choose a model with a low cross-entropy result (i.e. when increasing the hidden layer size barely reduces the cross-entropy amount).

* MNIST paper: $d_{\text{model}} = 16$
* Attention paper: $d_{\text{model}} = 1024$

:::

::::: {.panel-tabset}

## 2

![h = 2](NN_4_2_3.png)

* cross-entropy: 0.0800

## 4

![h = 4](NN_4_4_3.png)

* cross-entropy: 0.0509

## 8

![h = 8](NN_4_8_3.png)

* cross-entropy: 0.0599

## 16

![h = 16](NN_4_16_3.png)

* cross-entropy: 0.0280

:::::


# Deep Learning

::: {.callout-note}
## Deep Learning

In our studies of artificial learning, **deep learning** is using multiple hidden layers.

:::

::: {.callout-note collapse="true"}
## Python Code

```{python}
#| eval: false
class NN2H(pl.LightningModule):
  # Neural Network object
  # assumes two hidden layers (and default learning rate: 0.01)
  # inheirited class from LightningModule (for faster computations)

    def __init__(self, input_layer_size, h1, h2,
                 output_layer_size, learning_rate = None):
        super().__init__()
        self.input_layer_size = input_layer_size #input layer size (number of explanatory variables)
        self.h1 = h1
        self.h2 = h2
        self.learning_rate = learning_rate if learning_rate is not None else 0.01
        self.output_layer_size = output_layer_size #output layer size: 3 (number of penguin species)
        self.fc1 = nn.Linear(input_layer_size, h1)
        self.fc2 = nn.Linear(h1, h2)
        self.fc3 = nn.Linear(h2, output_layer_size)
        self.test_step_outputs = []

    def forward(self, x):
        x = F.relu(self.fc1(x))
        x = F.relu(self.fc2(x))
        x = self.fc3(x)
        return x

    def training_step(self, batch, batch_idx): # what happen in each train step
        x, y = batch
        output = self(x)
        loss = F.cross_entropy(output, y)
        # self.log('train_loss', loss, on_epoch=True) # use this for logging (e.g. using TensorBoard)
        return {'loss':loss}

    def test_step(self, batch, batch_idx): # what happen in each test step
        x, y = batch
        output = self(x)
        loss = F.cross_entropy(output, y)
        self.test_step_outputs.append(loss)
        return {'loss':loss}

    def on_test_epoch_end(self):
        epoch_average = torch.stack(self.test_step_outputs).mean()
        self.log("test_epoch_average", epoch_average)
        self.test_step_outputs.clear()  # free memory

    def configure_optimizers(self):
        optimizer = torch.optim.SGD(self.parameters(), lr = lr)
        return optimizer
```
:::

![deep learning](NN_4_2_4_3.png)


# Recurrent Neural Networks

::: {.callout-note}
## Recurrent Neural Networks

In order to move toward retaining some *memory* in our inputs to artificial intelligence models, we will here briefly discuss **recurrent neural networks**.

```{mermaid}
flowchart LR

input1[input]

neuron1[neuron]

output1[output]

input1 --> neuron1
neuron1 --> output1
neuron1 --> neuron1
```

As we *unfold* the network, we use the same weights and bias values between the layers.

:::

## Example: 867-5309

We start with a sequence that has 

$$\{8, 6, 7, 5, 3, 0, 9, ...\}$$
repeated over and over, and we hope that

* input "8" leads to a prediction of "6"
* input "6" leads to a prediction of "7"
* input "7" leads to a prediction of "5"
* input "5" leads to a prediction of "3"
* input "3" leads to a prediction of "0"
* input "0" leads to a prediction of "9"

## Unfolding



### 8

* Does input "8" leads to a prediction of "6"?

```{mermaid}
flowchart TD

input1[8]

neuron1[ReLU]

output1[6.2494]

input1 -- 0.20x + 0.86 --> neuron1

neuron1 -- 0.91x - 0.25 --> output1
```

* SSR:0.0622

### 6

* Does input "6" leads to a prediction of "7"?

```{mermaid}
flowchart TD

input1[8]
input2[6]

neuron1[ReLU]
neuron2[ReLU]

output1[NA]
output2[5.2948]

input1 -- 0.20x + 0.86 --> neuron1
input2 -- 0.20x + 0.86 --> neuron2

neuron1 -- 0.91x - 0.25 --> output1
neuron2 -- 0.91x - 0.25 --> output2

neuron1 -- -0.85x + 0.81 --> neuron2
```

* SSR: 2.9077

### 7

* Does input "7" leads to a prediction of "5"?

```{mermaid}
flowchart TD

input1[8]
input2[6]
input3[7]

neuron1[ReLU]
neuron2[ReLU]
neuron3[ReLU]

output1[NA]
output2[NA]
output3[6.2882]

input1 -- 0.20x + 0.86 --> neuron1
input2 -- 0.20x + 0.86 --> neuron2
input3 -- 0.20x + 0.86 --> neuron3

neuron1 -- 0.91x - 0.25 --> output1
neuron2 -- 0.91x - 0.25 --> output2
neuron3 -- 0.91x - 0.25 --> output3

neuron1 -- -0.85x + 0.81 --> neuron2
neuron2 -- -0.85x + 0.81 --> neuron3
```

* SSR: 1.6595

### 5

* Does input "5" leads to a prediction of "3"?

```{mermaid}
flowchart TD

input1[8]
input2[6]
input3[7]
input4[5]

neuron1[ReLU]
neuron2[ReLU]
neuron3[ReLU]
neuron4[ReLU]

output1[NA]
output2[NA]
output3[NA]
output4[5.0798]

input1 -- 0.20x + 0.86 --> neuron1
input2 -- 0.20x + 0.86 --> neuron2
input3 -- 0.20x + 0.86 --> neuron3
input4 -- 0.20x + 0.86 --> neuron4

neuron1 -- 0.91x - 0.25 --> output1
neuron2 -- 0.91x - 0.25 --> output2
neuron3 -- 0.91x - 0.25 --> output3
neuron4 -- 0.91x - 0.25 --> output4

neuron1 -- -0.85x + 0.81 --> neuron2
neuron2 -- -0.85x + 0.81 --> neuron3
neuron3 -- -0.85x + 0.81 --> neuron4
```

* SSR: 4.3257

### 3

* Does input "3" leads to a prediction of "0"?

```{mermaid}
flowchart TD

input1[8]
input2[6]
input3[7]
input4[5]
input5[3]

neuron1[ReLU]
neuron2[ReLU]
neuron3[ReLU]
neuron4[ReLU]
neuron5[ReLU]

output1[NA]
output2[NA]
output3[NA]
output4[NA]
output5[5.7430]

input1 -- 0.20x + 0.86 --> neuron1
input2 -- 0.20x + 0.86 --> neuron2
input3 -- 0.20x + 0.86 --> neuron3
input4 -- 0.20x + 0.86 --> neuron4
input5 -- 0.20x + 0.86 --> neuron5

neuron1 -- 0.91x - 0.25 --> output1
neuron2 -- 0.91x - 0.25 --> output2
neuron3 -- 0.91x - 0.25 --> output3
neuron4 -- 0.91x - 0.25 --> output4
neuron5 -- 0.91x - 0.25 --> output5

neuron1 -- -0.85x + 0.81 --> neuron2
neuron2 -- -0.85x + 0.81 --> neuron3
neuron3 -- -0.85x + 0.81 --> neuron4
neuron4 -- -0.85x + 0.81 --> neuron5
```

* SSR: 32.9815

### 0

* Does input "0" leads to a prediction of "9"?

```{mermaid}
flowchart TD

input1[8]
input2[6]
input3[7]
input4[5]
input5[3]
input6[0]

neuron1[ReLU]
neuron2[ReLU]
neuron3[ReLU]
neuron4[ReLU]
neuron5[ReLU]
neuron6[ReLU]

output1[NA]
output2[NA]
output3[NA]
output4[NA]
output5[NA]
output6[4.6333]

input1 -- 0.20x + 0.86 --> neuron1
input2 -- 0.20x + 0.86 --> neuron2
input3 -- 0.20x + 0.86 --> neuron3
input4 -- 0.20x + 0.86 --> neuron4
input5 -- 0.20x + 0.86 --> neuron5
input6 -- 0.20x + 0.86 --> neuron6

neuron1 -- 0.91x - 0.25 --> output1
neuron2 -- 0.91x - 0.25 --> output2
neuron3 -- 0.91x - 0.25 --> output3
neuron4 -- 0.91x - 0.25 --> output4
neuron5 -- 0.91x - 0.25 --> output5
neuron6 -- 0.91x - 0.25 --> output6

neuron1 -- -0.85x + 0.81 --> neuron2
neuron2 -- -0.85x + 0.81 --> neuron3
neuron3 -- -0.85x + 0.81 --> neuron4
neuron4 -- -0.85x + 0.81 --> neuron5
neuron5 -- -0.85x + 0.81 --> neuron6
```

* SSR: 19.0682

# Vanishing Gradients

In our recurrent neural network with

* input layer size: 1
* hidden layer size: 1
* output layer size: 1

```{mermaid}
flowchart LR

input1[input]

neuron1[neuron]

output1[output]

input1 -- w_i,h + b_i,h --> neuron1
neuron1 -- w_h,0 + b_h,0 --> output1
neuron1 -- w_h,h + b_h,h --> neuron1
```

we have functions

* $L_{i,h} = w_{i,h}x + b_{i,h}$
* $L_{h,o} = w_{h,o}x + b_{h,o}$
* $L_{h,h} = w_{h,h}x + b_{h,h}$

and ReLU activation function

$$\text{ReLU}(x) = \text{max}(x,0)$$
whose derivative is

$$\frac{d\text{ReLU}}{dx} = \begin{cases} 1, & x \geq 0 \\ 0, & x < 0 \end{cases}$$

## Chain Rule

Toward back propagation, the derivative based on output $k$ given inputs $\{1, 2, ..., k\}$ is

$$\begin{array}{rcl}
\frac{\partial\text{SSR}}{\partial x_{k}} & = & \displaystyle\sum_{a = 1}^{k}
\frac{\partial\text{SSR}}{\partial L_{h,o}}
\left(\displaystyle\prod_{b=1}^{a-1}
\frac{\partial L_{h,o}}{\partial\text{ReLU}}\cdot
\frac{\partial\text{ReLU}}{\partial L_{h,h}}\cdot
\frac{\partial L_{h,h}}{L_{i,h}}
\right)
\frac{\partial L_{i,h}}{\partial x_{k}} \\
~ & = & \displaystyle\sum_{a = 1}^{k}
w_{i,h}
\left(\displaystyle\prod_{b=1}^{a-1}
w_{h,h}\right)
w_{h,0} \\
\end{array}$$

## Example: 867-5309

For today's example, the derviative is

$$\frac{\partial\text{SSR}}{\partial x_{k}} = \sum_{a = 1}^{k}
(0.20)
\left(\prod_{b=1}^{a-1}
(-0.85)
\right)
(0.91)$$

::: {.callout-tip}
## Gradient Propagation

* we have **vanishing gradients** if $|w_{h,h}| < 1$
* we have **exploding gradients** if $|w_{h,h}| > 1$
:::


# Preview: Word Prediction

```{mermaid}
flowchart LR

input1[eggs]
input2[bread]
stem1[pairs]
stem2[well]
stem3[with]
output1[bacon]
output2[butter]

input1 --> stem1
input2 --> stem1
stem1 --> stem2
stem2 --> stem3
stem3 --> output1
stem3 --> output2
```

* "eggs pairs well with bacon"
* "bread pairs well with butter"
* but how to represent words as numbers?


# Derek's Research

::::: {.panel-tabset}

## Paper

:::: {.columns}

::: {.column width="50%"}
![pedagogy research](MBVP SABER poster.png)
:::

::: {.column width="50%"}
- regression (LASSO penalization)
- decision trees (XGBoost)
- K nearest neighbors
- neural networks
:::

::::

## Poster

:::: {.columns}

::: {.column width="50%"}
![topic modeling](topic_modeling.png)
:::

::: {.column width="50%"}
* topic modeling
* PCA
* image credit: [Joyce Xu](https://www.joycexu.io/2018/topic-modeling/)
:::

::::

:::::


# Quo Vadimus?

:::: {.columns}

::: {.column width="45%"}
* due this Friday (March 21):

    - Precept 6
    - Pick project
    - Art Images Use-Case Collection
  

    
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}
* due next Friday (March 28):

    - Poster Feedback
    - Precept 7
    - Literature search
:::

::::


# Footnotes

::: {.callout-note collapse="true"}

## (optional) Additional Resources and References

* derivation of the [derivative of cross entropy](https://shivammehta25.github.io/posts/deriving-categorical-cross-entropy-and-softmax/) by Shivam Mehta

:::

::: {.callout-note collapse="true"}
## Session Info

```{r}
sessionInfo()
```
:::


:::: {.columns}

::: {.column width="45%"}
	
:::

::: {.column width="10%"}
	
:::

::: {.column width="45%"}

:::

::::

::::: {.panel-tabset}



:::::