{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6BWPyLD6Lo2Y"
      },
      "outputs": [],
      "source": [
        "#%pip install palmerpenguins #https://github.com/mcnakhaee/palmerpenguins"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "\n",
        "from palmerpenguins import load_penguins\n",
        "from sklearn import metrics\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB"
      ],
      "metadata": {
        "id": "Ri-sRplzL1KW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "penguins = load_penguins()\n",
        "type(penguins)"
      ],
      "metadata": {
        "id": "kGv9nd4xL9JI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Cleaning"
      ],
      "metadata": {
        "id": "KgFeUp1qPshf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguins['chinstrap_bool'] = np.where(penguins['species'] == 'Chinstrap', 1, 0)\n",
        "penguins.head()"
      ],
      "metadata": {
        "id": "d2fdr3rSMipD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# remember to remove missing values before a machine learning algorithm\n",
        "penguins_subset = penguins[['chinstrap_bool', 'flipper_length_mm', 'bill_length_mm']].dropna()\n",
        "penguins_subset.head()"
      ],
      "metadata": {
        "id": "862dmkq6O2_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Logistic Regression"
      ],
      "metadata": {
        "id": "E1GMWHK1Pvpx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One predictor variable"
      ],
      "metadata": {
        "id": "ZDDQZa8dRXns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = penguins_subset[['flipper_length_mm']] #explanatory variable\n",
        "y = penguins_subset['chinstrap_bool'] #response variable (Boolean)"
      ],
      "metadata": {
        "id": "zmp1da25Rab1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main code for logistic regression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "z8D9O7gIRe4l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "2lGQ0XbERgFm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Confusion Matrix"
      ],
      "metadata": {
        "id": "uEOBlGKiRl0G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(confusion_mat)"
      ],
      "metadata": {
        "id": "ccpmS_g1RlTu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics from a confusion matrix\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "PomXuhMZRyMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preview: ROC Curves\n",
        "\n",
        "ROC curves (receiver operating characteristic) are very popular for helping judge the quality of a classification computation.  "
      ],
      "metadata": {
        "id": "XHZ7lj3oQhR7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "jmjxWrZQQP2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two predictor variables"
      ],
      "metadata": {
        "id": "PLQx1nP-Rgux"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = penguins_subset[['flipper_length_mm', 'bill_length_mm']] #explanatory variables\n",
        "y = penguins_subset['chinstrap_bool'] #response variable (Boolean)"
      ],
      "metadata": {
        "id": "xFDzkqLpNosI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#main code for logistic regression\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\n",
        "logreg = LogisticRegression()\n",
        "logreg.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "oAJUeaYHOXqd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make predictions\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "metadata": {
        "id": "kJxFLnmWPjqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "print(confusion_mat)"
      ],
      "metadata": {
        "id": "xR0aYh6jP48V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics from a confusion matrix\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "TaeEoBWFQMsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
        "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
        "plt.figure()\n",
        "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver operating characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.savefig('Log_ROC')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "yonekORTSlpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes"
      ],
      "metadata": {
        "id": "OI3QMn7vSuwN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## One categorical predictor"
      ],
      "metadata": {
        "id": "asxBiO0oT12J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mean_weight = penguins['body_mass_g'].mean()\n",
        "penguins['above_average_weight'] = np.where(penguins['body_mass_g'] > mean_weight, 1, 0)\n",
        "penguins_subset = penguins[['species', 'above_average_weight']].dropna()\n",
        "penguins_subset.head()\n",
        "X = penguins_subset[['above_average_weight']] #explanatory variable\n",
        "y = penguins_subset['species'] #response variable (Boolean)"
      ],
      "metadata": {
        "id": "Pn6_HMvrSxot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main code for Naive Bayes\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\n",
        "NB_model = GaussianNB()\n",
        "NB_model.fit(X_train, y_train)\n",
        "y_pred = NB_model.predict(X_test)"
      ],
      "metadata": {
        "id": "JE4PYUg0UQkP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make one prediction\n",
        "print(NB_model.predict([[0]])) #here, \"0\" for \"below-average weight\""
      ],
      "metadata": {
        "id": "tiRff5pGV101"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', cbar=False)"
      ],
      "metadata": {
        "id": "HGQknSwaVOeO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics from a confusion matrix\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "oFr5X3pYVcKB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# One numerical predictor"
      ],
      "metadata": {
        "id": "zWb5P8EKVmH2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguins_subset = penguins[['species', 'bill_length_mm']].dropna()\n",
        "penguins_subset.head()\n",
        "X = penguins_subset[['bill_length_mm']] #explanatory variable\n",
        "y = penguins_subset['species'] #response variable (Boolean)"
      ],
      "metadata": {
        "id": "CmmumvOJViGx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main code for Naive Bayes\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\n",
        "NB_model = GaussianNB()\n",
        "NB_model.fit(X_train, y_train)\n",
        "y_pred = NB_model.predict(X_test)"
      ],
      "metadata": {
        "id": "Sk9lyyswWp_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make one prediction\n",
        "print(NB_model.predict([[50]]))"
      ],
      "metadata": {
        "id": "s3glrMlYWsJs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', cbar=False)"
      ],
      "metadata": {
        "id": "Ald0y1kHXCNZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics from a confusion matrix\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "GoWNsxgsXEqL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Two predictor variables"
      ],
      "metadata": {
        "id": "yDJr1cPJXJ0s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "penguins_subset = penguins[['species', 'bill_length_mm', 'flipper_length_mm']].dropna()\n",
        "penguins_subset.head()\n",
        "X = penguins_subset[['bill_length_mm', 'flipper_length_mm']] #explanatory variables\n",
        "y = penguins_subset['species'] #response variable (Boolean)"
      ],
      "metadata": {
        "id": "JY2NjpE7XLjF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main code for Naive Bayes\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\n",
        "NB_model = GaussianNB()\n",
        "NB_model.fit(X_train, y_train)\n",
        "y_pred = NB_model.predict(X_test)"
      ],
      "metadata": {
        "id": "dAyZghUzXXnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# make one prediction\n",
        "print(NB_model.predict([[50, 195]]))"
      ],
      "metadata": {
        "id": "QbDTrOQRXZLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "confusion_mat = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', cbar=False)"
      ],
      "metadata": {
        "id": "cS8wjGTpXimg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# metrics from a confusion matrix\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "id": "M37UrM1FXj78"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}