{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6edbbc5d",
   "metadata": {},
   "source": [
    "# SML 301\n",
    "\n",
    "## Session 8: Nearest Neighbors\n",
    "\n",
    "* clustering\n",
    "* KNN (K Nearest Neighbors)\n",
    "* imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f7279e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install packages (if need be)\n",
    "#%pip install palmerpenguins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7fbaae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib.pyplot import subplots\n",
    "from palmerpenguins import load_penguins\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, MiniBatchKMeans\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.neighbors import NearestNeighbors, KNeighborsClassifier as KNN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "297441fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "penguins = load_penguins()\n",
    "\n",
    "df = penguins[['species', 'body_mass_g', 'flipper_length_mm']] #load in needed columns\n",
    "df = df.dropna() #then remove missing data\n",
    "X = df[['body_mass_g', 'flipper_length_mm']] #explanatory variables\n",
    "y = df['species'] #target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b6e1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], color = \"black\")\n",
    "\n",
    "ax.set_title(\"Training Data (seeking structure)\")\n",
    "ax.set_xlabel(\"body mass (g)\")\n",
    "ax.set_ylabel(\"flipper length (mm)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518f9187",
   "metadata": {},
   "source": [
    "# Clustering\n",
    "\n",
    "* $k$ cluster centers are randomly created\n",
    "* for each observation, assign it a label by the closest center by *distance*\n",
    "* redefine centers as group means\n",
    "* repeat until there are no changes in membership"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c01f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning with Python Cookbook\n",
    "cluster = KMeans(n_clusters = 3, n_init = \"auto\", random_state = 301)\n",
    "model = cluster.fit(X_train)\n",
    "\n",
    "# view cluster centers\n",
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8733f5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "centers_df = pd.DataFrame(model.cluster_centers_)\n",
    "centers_df[\"id\"] = centers_df.index + 1\n",
    "#colors_array = ['red', 'blue', 'green']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], color = \"#aaaaaa\")\n",
    "ax.scatter(centers_df.iloc[:, 0], centers_df.iloc[:, 1], c = centers_df.id, cmap = 'Set1', s = 301)\n",
    "\n",
    "ax.set_title(\"K Centers\")\n",
    "ax.set_xlabel(\"body mass (g)\")\n",
    "ax.set_ylabel(\"flipper length (mm)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d51cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "ax1.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], c = y_train)\n",
    "ax1.set_title(\"training data\")\n",
    "ax1.set_xlabel(\"body mass (g)\")\n",
    "ax1.set_ylabel(\"flipper length (mm)\")\n",
    "\n",
    "ax2.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], c = model.labels_, cmap = 'Set1')\n",
    "ax2.set_title(\"clustering predictions\")\n",
    "ax2.set_xlabel(\"body mass (g)\")\n",
    "ax2.set_ylabel(\"flipper length (mm)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f1ffbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "acc_train = np.mean(model.labels_ == y_train)\n",
    "acc_test  = np.mean(y_pred == y_test)\n",
    "print(f'train accuracy: {acc_train:.4f}')\n",
    "print(f'test accuracy: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce8ec2e0",
   "metadata": {},
   "source": [
    "## Scaling Numerical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb88b337",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = penguins[['species', 'body_mass_g', 'flipper_length_mm']] #load in needed columns\n",
    "df = df.dropna() #then remove missing data\n",
    "X = df[['body_mass_g', 'flipper_length_mm']] #explanatory variables\n",
    "y = df['species'] #target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# rescale variables\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X_std, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b821f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning with Python Cookbook\n",
    "cluster = KMeans(n_clusters = 3, n_init = \"auto\", random_state = 301)\n",
    "model = cluster.fit(X_train)\n",
    "\n",
    "# view cluster centers\n",
    "model.cluster_centers_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a39f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "ax1.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], c = y_train)\n",
    "ax1.set_title(\"training data\")\n",
    "ax1.set_xlabel(\"body mass (g)\")\n",
    "ax1.set_ylabel(\"flipper length (mm)\")\n",
    "\n",
    "ax2.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], c = model.labels_, cmap = 'Set1')\n",
    "ax2.set_title(\"clustering predictions\")\n",
    "ax2.set_xlabel(\"body mass (g)\")\n",
    "ax2.set_ylabel(\"flipper length (mm)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c448cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "acc_train = np.mean(model.labels_ == y_train)\n",
    "acc_test  = np.mean(y_pred == y_test)\n",
    "print(f'train accuracy: {acc_train:.4f}')\n",
    "print(f'test accuracy: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d86711",
   "metadata": {},
   "source": [
    "## Another Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "856f2f1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = penguins[['species', 'flipper_length_mm', 'bill_length_mm']] #load in needed columns\n",
    "df = df.dropna() #then remove missing data\n",
    "X = df[['flipper_length_mm', 'bill_length_mm']] #explanatory variables\n",
    "y = df['species'] #target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# rescale variables\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X_std, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 301)\n",
    "\n",
    "cluster = KMeans(n_clusters = 3, n_init = \"auto\", random_state = 301)\n",
    "model = cluster.fit(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e8e06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "ax1.scatter(X_train['flipper_length_mm'], X_train['bill_length_mm'], c = y_train)\n",
    "ax1.set_title(\"training data\")\n",
    "ax1.set_xlabel(\"body mass (g)\")\n",
    "ax1.set_ylabel(\"flipper length (mm)\")\n",
    "\n",
    "ax2.scatter(X_train['flipper_length_mm'], X_train['bill_length_mm'], c = model.labels_, cmap = 'Set1')\n",
    "ax2.set_title(\"clustering predictions\")\n",
    "ax2.set_xlabel(\"body mass (g)\")\n",
    "ax2.set_ylabel(\"flipper length (mm)\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e230e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: what if model labels don't match LabelEncoder values?  Hungarian Algorithm\n",
    "y_pred = (model.predict(X_test) + 2) % 3 #hacked the alignment\n",
    "acc_train = np.mean((model.labels_  + 2) % 3 == y_train)\n",
    "acc_test  = np.mean(y_pred == y_test)\n",
    "print(f'train accuracy: {acc_train:.4f}')\n",
    "print(f'test accuracy: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2559d73",
   "metadata": {},
   "source": [
    "## Choosing the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "232fcccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all numerical predictors\n",
    "df = penguins[['species', 'flipper_length_mm', 'body_mass_g', 'bill_length_mm', 'bill_depth_mm']] #load in needed columns\n",
    "df = df.dropna() #then remove missing data\n",
    "X = df[['flipper_length_mm', 'body_mass_g', 'bill_length_mm', 'bill_depth_mm']] #explanatory variables\n",
    "y = df['species'] #target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# rescale variables\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X_std, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 301)\n",
    "\n",
    "#cluster = KMeans(n_clusters = 3, n_init = \"auto\", random_state = 301)\n",
    "#model = cluster.fit(X_train)\n",
    "#model.get_params()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d5be5b",
   "metadata": {},
   "source": [
    "### Scree Plot (\"Elbow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fee68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = [2, 3, 4, 5, 6, 7]\n",
    "SSE_ratios = np.full(len(k_vals), np.nan)\n",
    "\n",
    "for k in k_vals:\n",
    "    cluster = KMeans(n_clusters = k, n_init = \"auto\", random_state = 301)\n",
    "    model = cluster.fit(X_train)\n",
    "    SSE_ratios[k-2] = model.inertia_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(k_vals, SSE_ratios)\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"Scree Plot\")\n",
    "ax.set_xlabel(\"number of clusters\")\n",
    "ax.set_ylabel(\"total within sum of squares\")\n",
    "ax.set_xticks(range(2,7))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "240cd06f",
   "metadata": {},
   "source": [
    "### Silhouette Analysis\n",
    "\n",
    "\"The silhouette plot displays a measure of how close each point in one cluster is to points in the neighboring clusters and thus provides a way to assess parameters like number of clusters visually. This measure has a range of [-1, 1].\n",
    "\n",
    "Silhouette coefficients (as these values are referred to as) near +1 indicate that the sample is far away from the neighboring clusters. A value of 0 indicates that the sample is on or very close to the decision boundary between two neighboring clusters and negative values indicate that those samples might have been assigned to the wrong cluster.\" \n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c0b2a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = [2, 3, 4, 5, 6, 7]\n",
    "\n",
    "for n_clusters in k_vals:\n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(18, 7)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example all\n",
    "    # lie within [-0.1, 1]\n",
    "    ax1.set_xlim([-0.1, 1])\n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # Initialize the clusterer with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    clusterer = KMeans(n_clusters=n_clusters, random_state=301)\n",
    "    cluster_labels = clusterer.fit_predict(X)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\n",
    "        \"For n_clusters =\",\n",
    "        n_clusters,\n",
    "        \"The average silhouette_score is :\",\n",
    "        silhouette_avg,\n",
    "    )\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(n_clusters):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(\n",
    "            np.arange(y_lower, y_upper),\n",
    "            0,\n",
    "            ith_cluster_silhouette_values,\n",
    "            facecolor=color,\n",
    "            edgecolor=color,\n",
    "            alpha=0.7,\n",
    "        )\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.1, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    ax2.scatter(\n",
    "       X.iloc[:, 0], X.iloc[:, 1], marker=\".\", s=30, lw=0, alpha=0.7, c=colors, edgecolor=\"k\"\n",
    "    )\n",
    "\n",
    "    # Labeling the clusters\n",
    "    centers = clusterer.cluster_centers_\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(\n",
    "        centers[:, 0],\n",
    "        centers[:, 1],\n",
    "        marker=\"o\",\n",
    "        c=\"white\",\n",
    "        alpha=1,\n",
    "        s=200,\n",
    "        edgecolor=\"k\",\n",
    "    )\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker=\"$%d$\" % i, alpha=1, s=50, edgecolor=\"k\")\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"Feature space for the 1st feature\")\n",
    "    ax2.set_ylabel(\"Feature space for the 2nd feature\")\n",
    "\n",
    "    plt.suptitle(\n",
    "        \"Silhouette analysis for KMeans clustering on sample data with n_clusters = %d\" %n_clusters,\n",
    "        fontsize=14,\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8275b336",
   "metadata": {},
   "source": [
    "## Modern Approaches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4e3fedf",
   "metadata": {},
   "source": [
    "### Batch Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e335cda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = MiniBatchKMeans(n_clusters = 3, n_init = \"auto\", random_state = 301,\n",
    "  batch_size = 50) #work with data in smaller batches\n",
    "model = cluster.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c549d01",
   "metadata": {},
   "source": [
    "### DBSCAN\n",
    "\n",
    "\"Density-Based Spatial Clustering of Applications with Noise. Finds core samples of high density and expands clusters from them. Good for data which contains clusters of similar density.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306979d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = DBSCAN(eps = 3, #max distance (from center)\n",
    "  min_samples = 5,\n",
    "  metric = 'euclidean')\n",
    "model = cluster.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53d64d7",
   "metadata": {},
   "source": [
    "### Hierarchical Merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbfc1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = AgglomerativeClustering(n_clusters = 3)\n",
    "model = cluster.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf49e7d",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aee4e2a",
   "metadata": {},
   "source": [
    "## Neighbors (and distances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff48af",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = penguins[['species', 'body_mass_g', 'flipper_length_mm']] #load in needed columns\n",
    "df = df.dropna() #then remove missing data\n",
    "X = df[['body_mass_g', 'flipper_length_mm']] #explanatory variables\n",
    "y = df['species'] #target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d3d871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning with Python Cookbook\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors = 10).fit(X_train)\n",
    "\n",
    "new_penguin = [4500, 201]\n",
    "distances, indices = nearest_neighbors.kneighbors([new_penguin])\n",
    "neighbors_df = X_train.iloc[indices[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a747c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "ax1.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], c = y_train)\n",
    "ax1.scatter(new_penguin[0], new_penguin[1], color = \"black\", marker = \"X\", s = 301)\n",
    "ax1.set_title(\"training data\")\n",
    "ax1.set_xlabel(\"body mass (g)\")\n",
    "ax1.set_ylabel(\"flipper length (mm)\")\n",
    "ax1.set_xlim(min(X_train['body_mass_g']), max(X_train['body_mass_g']))\n",
    "ax1.set_ylim(min(X_train['flipper_length_mm']), max(X_train['flipper_length_mm']))\n",
    "\n",
    "ax2.scatter(neighbors_df.iloc[:, 0], neighbors_df.iloc[:, 1])\n",
    "ax2.set_title(\"nearest neighbors\")\n",
    "ax2.set_xlabel(\"body mass (g)\")\n",
    "ax2.set_ylabel(\"flipper length (mm)\")\n",
    "ax2.set_xlim(min(X_train['body_mass_g']), max(X_train['body_mass_g']))\n",
    "ax2.set_ylim(min(X_train['flipper_length_mm']), max(X_train['flipper_length_mm']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5c8917",
   "metadata": {},
   "source": [
    "## Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cba976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = penguins[['species', 'body_mass_g', 'flipper_length_mm']] #load in needed columns\n",
    "df = df.dropna() #then remove missing data\n",
    "X = df[['body_mass_g', 'flipper_length_mm']] #explanatory variables\n",
    "y = df['species'] #target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# rescale variables\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X_std, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66ea41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Machine Learning with Python Cookbook\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors = 10, metric = 'euclidean').fit(X_train)\n",
    "\n",
    "new_penguin = [0, 0]\n",
    "distances, indices = nearest_neighbors.kneighbors([new_penguin])\n",
    "neighbors_df = X_train.iloc[indices[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c39c0d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "ax1.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], c = y_train)\n",
    "ax1.scatter(new_penguin[0], new_penguin[1], color = \"black\", marker = \"X\", s = 301)\n",
    "ax1.set_title(\"training data\")\n",
    "ax1.set_xlabel(\"body mass (g)\")\n",
    "ax1.set_ylabel(\"flipper length (mm)\")\n",
    "ax1.set_xlim(min(X_train['body_mass_g']), max(X_train['body_mass_g']))\n",
    "ax1.set_ylim(min(X_train['flipper_length_mm']), max(X_train['flipper_length_mm']))\n",
    "\n",
    "# TODO: don't hard code radius (max distance value) or circle center\n",
    "ax1.add_patch(patches.Circle((0,0), 0.32, alpha = 0.301, color = \"orange\", fill = True))\n",
    "\n",
    "ax2.scatter(neighbors_df.iloc[:, 0], neighbors_df.iloc[:, 1])\n",
    "ax2.set_title(\"nearest neighbors\")\n",
    "ax2.set_xlabel(\"body mass (g)\")\n",
    "ax2.set_ylabel(\"flipper length (mm)\")\n",
    "ax2.set_xlim(min(X_train['body_mass_g']), max(X_train['body_mass_g']))\n",
    "ax2.set_ylim(min(X_train['flipper_length_mm']), max(X_train['flipper_length_mm']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ffe8e9",
   "metadata": {},
   "source": [
    "## L1 Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d028025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manhattan norm\n",
    "nearest_neighbors = NearestNeighbors(n_neighbors = 10, metric = 'manhattan').fit(X_train)\n",
    "\n",
    "new_penguin = [0, 0]\n",
    "distances, indices = nearest_neighbors.kneighbors([new_penguin])\n",
    "neighbors_df = X_train.iloc[indices[0], :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b54f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "\n",
    "ax1.scatter(X_train['body_mass_g'], X_train['flipper_length_mm'], c = y_train)\n",
    "ax1.scatter(new_penguin[0], new_penguin[1], color = \"black\", marker = \"X\", s = 301)\n",
    "ax1.set_title(\"training data\")\n",
    "ax1.set_xlabel(\"body mass (g)\")\n",
    "ax1.set_ylabel(\"flipper length (mm)\")\n",
    "ax1.set_xlim(min(X_train['body_mass_g']), max(X_train['body_mass_g']))\n",
    "ax1.set_ylim(min(X_train['flipper_length_mm']), max(X_train['flipper_length_mm']))\n",
    "\n",
    "# TODO: don't hard code radius (max distance value)\n",
    "ax1.add_patch(patches.Rectangle((-0.32,-0.32), 0.64, 0.64, alpha = 0.301, color = \"orange\", fill = True))\n",
    "\n",
    "ax2.scatter(neighbors_df.iloc[:, 0], neighbors_df.iloc[:, 1])\n",
    "ax2.set_title(\"nearest neighbors\")\n",
    "ax2.set_xlabel(\"body mass (g)\")\n",
    "ax2.set_ylabel(\"flipper length (mm)\")\n",
    "ax2.set_xlim(min(X_train['body_mass_g']), max(X_train['body_mass_g']))\n",
    "ax2.set_ylim(min(X_train['flipper_length_mm']), max(X_train['flipper_length_mm']))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "787ae967",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717a345d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KNN(n_neighbors = 3, n_jobs = -1).fit(X_train, y_train)\n",
    "y_pred_train = model.predict(X_train)\n",
    "y_pred_test = model.predict(X_test)\n",
    "acc_train = np.mean(y_pred_train == y_train)\n",
    "acc_test  = np.mean(y_pred_test == y_test)\n",
    "print(f'train accuracy: {acc_train:.4f}')\n",
    "print(f'test accuracy: {acc_test:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca66bdf",
   "metadata": {},
   "source": [
    "### Choosing the number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b285c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "k_vals = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    "acc_train = np.full(len(k_vals), np.nan)\n",
    "acc_test = np.full(len(k_vals), np.nan)\n",
    "\n",
    "for k in k_vals:\n",
    "    model = KNN(n_neighbors = k, n_jobs = -1).fit(X_train, y_train)\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "    acc_train[k-1] = np.mean(y_pred_train == y_train)\n",
    "    acc_test[k-1] = np.mean(y_pred_test == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc66a093",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(k_vals, acc_train, label = \"training accuracy\")\n",
    "ax.plot(k_vals, acc_test, label = \"testing accuracy\")\n",
    "\n",
    "ax.legend()\n",
    "ax.set_title(\"KNN parameter search\")\n",
    "ax.set_xlabel(\"number of neighbors\")\n",
    "ax.set_ylabel(\"accuracy\")\n",
    "ax.set_xticks(range(1,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad4c888",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4474934e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model\n",
    "knn = KNN(n_neighbors = 5, n_jobs = -1)\n",
    "\n",
    "# define pipeline\n",
    "pipeline = Pipeline([(\"knn\", knn)])\n",
    "\n",
    "# define search space (Python dictionary)\n",
    "search_space = [{\"knn__n_neighbors\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"knn__metric\": ['euclidean', 'manhattan']}]\n",
    "\n",
    "# perform cross-validation and grid search\n",
    "classifier = GridSearchCV(pipeline, search_space, cv = 10, verbose = 0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1393356",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve best parameters\n",
    "classifier.best_estimator_.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e1428e",
   "metadata": {},
   "source": [
    "## Imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c96b0ff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = penguins[['species', 'body_mass_g', 'flipper_length_mm', 'bill_length_mm', 'bill_depth_mm']] #load in needed columns\n",
    "df = df.dropna() #then remove missing data\n",
    "X = df[['body_mass_g', 'flipper_length_mm', 'bill_length_mm', 'bill_depth_mm']] #explanatory variables\n",
    "y = df['species'] #target variable\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "# rescale variables\n",
    "X_std = StandardScaler().fit_transform(X)\n",
    "X = pd.DataFrame(X_std, columns = X.columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 301)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1614e180",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_penguin = np.array([[0.6, 0.7, np.nan, np.nan]]) #standardized values\n",
    "new_penguin_df = pd.DataFrame(new_penguin, columns = X_train.columns)\n",
    "\n",
    "X_train_2 = pd.concat([X_train, new_penguin_df])\n",
    "print(X_train_2.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ed9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_imputed = KNNImputer(n_neighbors = 4).fit_transform(X_train_2)\n",
    "X_train_imputed = pd.DataFrame(X_train_imputed, columns = X_train.columns)\n",
    "print(X_train_imputed.tail())"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
