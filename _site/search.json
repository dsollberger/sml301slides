[
  {
    "objectID": "posts/301_01_introduction/01_introduction.html",
    "href": "posts/301_01_introduction/01_introduction.html",
    "title": "1: Introductions",
    "section": "",
    "text": "Goal: Introduce course\nObjective: Explore some Python codes\n\n\n\n\n\ntextbooks"
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#start",
    "href": "posts/301_01_introduction/01_introduction.html#start",
    "title": "1: Introductions",
    "section": "",
    "text": "Goal: Introduce course\nObjective: Explore some Python codes\n\n\n\n\n\ntextbooks"
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#data-intelligence-modern-data-science-methods",
    "href": "posts/301_01_introduction/01_introduction.html#data-intelligence-modern-data-science-methods",
    "title": "1: Introductions",
    "section": "Data Intelligence: Modern Data Science Methods",
    "text": "Data Intelligence: Modern Data Science Methods\n\nSpring 2025\nMonday, Wednesday, 11 AM to 1250 PM\nLecturer: Derek\n\nI go by “Derek” or “teacher”\n\n\n\n\n\n\n\n\nCourse Description\n\n\n\n\n\nThis course provides the training for students to be independent in modern data analysis. The course emphasizes the rigorous treatment of data and the programming skills and conceptual understanding required for dealing with modern datasets. The course examines data analysis through the lens of statistics and machine learning methods. Students verify their understanding by working with real datasets. The course also covers supporting topics such as experiment design, ethical data use, best practices for statistical and machine learning methods, reproducible research, writing a quantitative research paper, and presenting research results."
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#lecturer",
    "href": "posts/301_01_introduction/01_introduction.html#lecturer",
    "title": "1: Introductions",
    "section": "Lecturer",
    "text": "Lecturer"
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#current-research-in-pedagogy",
    "href": "posts/301_01_introduction/01_introduction.html#current-research-in-pedagogy",
    "title": "1: Introductions",
    "section": "Current Research in Pedagogy",
    "text": "Current Research in Pedagogy\n\n\n\n\n\nactive learning\ncomputer programming\nflipped classrooms"
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#textbooks",
    "href": "posts/301_01_introduction/01_introduction.html#textbooks",
    "title": "1: Introductions",
    "section": "Textbooks",
    "text": "Textbooks\n\nList1234\n\n\n\nAn Introduction to Statistical Learning by James, Witten, Hastie, Tibshirani, Taylor\nDeep Learning Illustrated by Jon Krohn\nHow AI Works by Ronald T Kneusel\nProbabilistic Machine Learning by Kevin Patrick Murphy\n\n\n\n\n\n\nISLP\n\n\n\nAn Introduction to Statistical Learning by James, Witten, Hastie, Tibshirani, Taylor\n\n\n\n\n\n\nDeep Learning\n\n\n\nDeep Learning Illustrated by Jon Krohn\n\n\n\n\n\n\nHow AI Works\n\n\n\nHow AI Works by Ronald T Kneusel\n\n\n\n\n\n\nProbabilistic Machine Learning\n\n\n\nProbabilistic Machine Learning by Kevin Patrick Murphy"
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#cooperative-classroom",
    "href": "posts/301_01_introduction/01_introduction.html#cooperative-classroom",
    "title": "1: Introductions",
    "section": "Cooperative Classroom",
    "text": "Cooperative Classroom\nLearning in a cooperative environment should be stimulating, demanding, and fair. Because this approach to learning is different from the competitive classroom structure that many other courses used to be based on, it is important for us to be clear about mutual expectations. Below are my expectations for students in this class. This set of expectations is intended to maximize debate and exchange of ideas in an atmosphere of mutual respect while preserving individual ownership of ideas and written words. If you feel you do not understand or cannot agree to these expectations, you should discuss this with your instructor and classmates.\n\nStudents are expected to work cooperatively with other members of the class and show respect for the ideas and contributions of other people.\nWhen working as part of a group, students should strive to be good contributors to the group, listen to others, not dominate, and recognize the contributions of others. Students should try to ensure that everyone in the group is welcome to contribute and recognize that everyone contributes in different ways to a group process.\nStudents should explore data, make observations, and develop inferences as part of a group. If you use material from published sources, you must provide appropriate attribution.\n\n\n\n(Students will be asked to acknowledge this document in an online form.)\nThis document has been adapted from Scientific Teaching by Jo Handelsman, Sarah Miller, and Christine Pfund\n\n\n\n\nScientific Teaching"
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#pep-talk",
    "href": "posts/301_01_introduction/01_introduction.html#pep-talk",
    "title": "1: Introductions",
    "section": "Pep Talk",
    "text": "Pep Talk\nLearning R can be difficult at first—it is like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you will be using like ggplot2—made this wise observation:\n\n\n\n\n\n\nWisdom from Hadley Wickham\n\n\n\n\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\n\n\nIf you are finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, ask questions … e-mail [Derek], etc. I promise you can do this.\n—Andrew Heiss, Georgia State University"
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#inclusion-statement",
    "href": "posts/301_01_introduction/01_introduction.html#inclusion-statement",
    "title": "1: Introductions",
    "section": "Inclusion Statement",
    "text": "Inclusion Statement\nI value all students regardless of their background, country of origin, race, religion, ethnicity, gender, sexual orientation, disability status, etc. and am committed to providing a climate of excellence and inclusiveness within all aspects of the course. If there are aspects of your culture or identity that you would like to share with me as they relate to your success in this class, I am happy to meet to discuss. Likewise, if you have any concerns in this area or facing any special issues or challenges, you are encouraged to discuss the matter with me (set up a meeting by e-mail) with an assurance of full confidentiality (only exception being mandatory reporting of academic integrity code violations or sexual harassment)."
  },
  {
    "objectID": "posts/301_01_introduction/01_introduction.html#tensorflow-playground",
    "href": "posts/301_01_introduction/01_introduction.html#tensorflow-playground",
    "title": "1: Introductions",
    "section": "TensorFlow Playground",
    "text": "TensorFlow Playground\n\nlink: https://playground.tensorflow.org\nexplore the various menus and buttons\nfeel free to run a simulation"
  },
  {
    "objectID": "posts/301_02_convergence/02_convergence.html",
    "href": "posts/301_02_convergence/02_convergence.html",
    "title": "2: Convergence",
    "section": "",
    "text": "Goal: Discuss convergence\nObjective: Explore some Python codes about root finding and stochastic processes\n\n\nAs we get started, try to load a session in Google Colab"
  },
  {
    "objectID": "posts/301_02_convergence/02_convergence.html#start",
    "href": "posts/301_02_convergence/02_convergence.html#start",
    "title": "2: Convergence",
    "section": "",
    "text": "Goal: Discuss convergence\nObjective: Explore some Python codes about root finding and stochastic processes\n\n\nAs we get started, try to load a session in Google Colab"
  },
  {
    "objectID": "posts/301_02_convergence/02_convergence.html#tensorflow-playground",
    "href": "posts/301_02_convergence/02_convergence.html#tensorflow-playground",
    "title": "2: Convergence",
    "section": "TensorFlow Playground",
    "text": "TensorFlow Playground\n\nlink: https://playground.tensorflow.org\nexplore the various menus and buttons\nfeel free to run a simulation"
  },
  {
    "objectID": "posts/301_02_convergence/02_convergence.html#sequences",
    "href": "posts/301_02_convergence/02_convergence.html#sequences",
    "title": "2: Convergence",
    "section": "Sequences",
    "text": "Sequences\n\nindex: \\(n \\in \\mathbb{N} = \\{1, 2, 3, 4, 5, ...\\}\\)\nformulaic: f(n) = 2n - 1\n\n\\[1, 3, 5, 7, 9, ...\\]\n\nconstructive:\n\n\\[3, 3.1, 3.14, 3.141, 3.1415, 3.14159, ...\\]\n\nshapes:\n\n\n\n\ntriangular numbers\n\n\n\nimage source: BYJUs"
  },
  {
    "objectID": "posts/301_02_convergence/02_convergence.html#random-variables",
    "href": "posts/301_02_convergence/02_convergence.html#random-variables",
    "title": "2: Convergence",
    "section": "Random Variables",
    "text": "Random Variables\nA random variable has no set value, but rather represents an element of chance. We can better understand a random variable through statistics like\n\nmean\nvariance\ndistribution\n\n\n\n\n\n\n\nStochastic Process\n\n\n\n\n\nA stochastic process is a sequence of random variables"
  },
  {
    "objectID": "posts/301_02_convergence/02_convergence.html#application-dinner-choices",
    "href": "posts/301_02_convergence/02_convergence.html#application-dinner-choices",
    "title": "2: Convergence",
    "section": "Application: Dinner Choices",
    "text": "Application: Dinner Choices\nSuppose that we have a Princeton student whose behavior includes eating only three types of dinner:\n\\[S = \\{\\text{ramen}, \\text{pizza}, \\text{sushi}\\}\\]\nwith transition matrix\n\\[P = \\left(\\begin{array}{ccc}\n0.2 & 0.4 & 0.4 \\\\\n0.3 & 0.4 & 0.3 \\\\\n0.2 & 0.2 & 0.6\n\\end{array}\\right)\\]\n\n\n\ndinner choices network\n\n\n\n\n\n\n\n\nNetwork terminology\n\n\n\n\n\n\ndirected versus undirected graphs\ncyclic versus acyclic graphs\n\nLater studies focus on DAGs: directed, acyclic network graphs\n\n\n\nSuppose that, on a Monday, the student’s preferences are\n\\[x_0 = \\left(\\begin{array}{ccc} 0.5 & 0.25 & 0.25 \\end{array}\\right)\\]\n\nWhat is the probability that the student will eat ramen on Tuesday (i.e. the next day)?\nWhat is the probability that the student will eat pizza on Wednesday (i.e. two days later)?\nWhat is the long-term dinner-choice behavior of this student?"
  },
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Lecture Sessions",
    "section": "",
    "text": "3: Regression\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2025\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n1: Introductions\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2025\n\n\nDerek Sollberger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "SML 301 (Spring 2025)",
    "section": "",
    "text": "3: Regression\n\n\n\n\n\n\n\n\n\n\n\nSep 8, 2025\n\n\nDerek Sollberger\n\n\n\n\n\n\n\n\n\n\n\n\n1: Introductions\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2025\n\n\nDerek Sollberger\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/03_regression/03_regression.html",
    "href": "posts/03_regression/03_regression.html",
    "title": "3: Regression",
    "section": "",
    "text": "Goal: Discuss the bias-variance trade-ff\nObjective: Explore linear regression\n\n\nAs we get started, try to install the ISLP package in your Python software"
  },
  {
    "objectID": "posts/03_regression/03_regression.html#start",
    "href": "posts/03_regression/03_regression.html#start",
    "title": "3: Regression",
    "section": "",
    "text": "Goal: Discuss the bias-variance trade-ff\nObjective: Explore linear regression\n\n\nAs we get started, try to install the ISLP package in your Python software"
  },
  {
    "objectID": "posts/03_regression/03_regression.html#residuals",
    "href": "posts/03_regression/03_regression.html#residuals",
    "title": "3: Regression",
    "section": "Residuals",
    "text": "Residuals\nA residual is the difference between a predicted value and its true value."
  },
  {
    "objectID": "posts/03_regression/03_regression.html#method-of-least-squares",
    "href": "posts/03_regression/03_regression.html#method-of-least-squares",
    "title": "3: Regression",
    "section": "Method of Least Squares",
    "text": "Method of Least Squares\nIdea: The best-fit line is where the sum-of-squared residuals is minimized.\n\\[E(a,b) = \\sum_{i=1}^{n} (y_{i} - a - bx_{i})^{2}\\]\nClaim: \\[a = \\frac{ (\\sum y_{i})(\\sum x_{i}^{2}) - (\\sum x_{i})(\\sum x_{i}y_{i}) }{ n\\sum x_{i}^{2} - (\\sum x_{i})^{2} }, \\quad b = \\frac{ n\\sum x_{i}y_{i} - (\\sum x_{i})(\\sum y_{i}) }{ n\\sum x_{i}^{2} - (\\sum x_{i})^{2} }\\]\n\n\n\n\n\n\n(optional) Proof\n\n\n\n\n\nSearch for a critical point by setting the partial derivatives (along with the Chain Rule) equal to zero.\n\\[0 = \\frac{\\partial E}{\\partial a} = -2\\sum_{i = 1}^{n} (y_{i} - a - bx_{i}) = 2an + 2b\\sum_{i = 1}^{n}x_{i} - 2\\sum_{i = 1}^{n} y_{i}\\] \\[0 = \\frac{\\partial E}{\\partial b} = -2\\sum_{i = 1}^{n} (y_{i} - a - bx_{i})x_{i} = 2a\\sum_{i = 1}^{n}x_{i} + 2b\\sum_{i = 1}^{n}x_{i}^{2} - 2\\sum_{i = 1}^{n} x_{i}y_{i}\\]\nCreate a matrix system of equations.\n\\[\\left[  \\begin{array}{cc}\n  n & \\sum_{i = 1}^{n}x_{i} \\\\\n  \\sum_{i = 1}^{n}x_{i} & \\sum_{i = 1}^{n}x_{i}^{2} \\\\\n  \\end{array}\\right]\n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right]\n  =\n  \\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right]\n  \\]\nEmploy a matrix inverse.\n$$\n\\[\\begin{array}{rcl}\n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = &\n  \\left[  \\begin{array}{cc}\n  n & \\sum_{i = 1}^{n}x_{i} \\\\\n  \\sum_{i = 1}^{n}x_{i} & \\sum_{i = 1}^{n}x_{i}^{2} \\\\\n  \\end{array}\\right]^{-1}\\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right] \\\\\n  \n  ~ & ~ & ~ \\\\\n  \n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = & \\frac{1}{n\\sum x_{i}^{2} - (\\sum x_{i})^{2}} \\left[  \\begin{array}{cc}\n  \\sum_{i = 1}^{n}x_{i}^{2} & -\\sum_{i = 1}^{n}x_{i} \\\\\n  -\\sum_{i = 1}^{n}x_{i} & n \\\\\n  \\end{array}\\right]  \\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right] \\\\\n  \n  ~ & ~ & ~ \\\\\n  \n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = & \\frac{1}{n\\sum x_{i}^{2} - (\\sum x_{i})^{2}}\n  \\left[  \\begin{array}{c}  (\\sum y_{i})(\\sum x_{i}^{2}) - (\\sum x_{i})(\\sum x_{i}y_{i}) \\\\  n\\sum x_{i}y_{i} - (\\sum x_{i})(\\sum y_{i}) \\end{array}\\right] \\\\\n\\end{array}\\]\n$$"
  },
  {
    "objectID": "posts/03_regression/03_regression.html#multiple-linear-regression",
    "href": "posts/03_regression/03_regression.html#multiple-linear-regression",
    "title": "3: Regression",
    "section": "Multiple Linear Regression",
    "text": "Multiple Linear Regression\n\\[\\hat{y} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{3} + ...\\]\nis likewise solved by ordinary least squares"
  },
  {
    "objectID": "posts/03_regression/03_regression.html#adaboost",
    "href": "posts/03_regression/03_regression.html#adaboost",
    "title": "3: Regression",
    "section": "Adaboost",
    "text": "Adaboost\n\nA Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting (1997—published as abstract in 1995), Freund and Schapire"
  },
  {
    "objectID": "posts/03_regression/03_regression.html#alexnet",
    "href": "posts/03_regression/03_regression.html#alexnet",
    "title": "3: Regression",
    "section": "AlexNet",
    "text": "AlexNet\n\nImageNet Classification with Deep Convolutional Neural Networks (2012)"
  },
  {
    "objectID": "posts/03_regression/03_regression.html#dropout",
    "href": "posts/03_regression/03_regression.html#dropout",
    "title": "3: Regression",
    "section": "DropOut",
    "text": "DropOut\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting (2014), Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov"
  },
  {
    "objectID": "posts/03_regression/03_regression.html#gans",
    "href": "posts/03_regression/03_regression.html#gans",
    "title": "3: Regression",
    "section": "GANs",
    "text": "GANs\n\nGeneral Adversarial Nets (2014), Goodfellow et al."
  },
  {
    "objectID": "posts/03_regression/03_regression.html#tensorflow",
    "href": "posts/03_regression/03_regression.html#tensorflow",
    "title": "3: Regression",
    "section": "TensorFlow",
    "text": "TensorFlow\n\nTensorFlow: A system for large-scale machine learning (2016), Abadi et al."
  },
  {
    "objectID": "posts/03_regression/03_regression.html#word2vec",
    "href": "posts/03_regression/03_regression.html#word2vec",
    "title": "3: Regression",
    "section": "Word2Vec",
    "text": "Word2Vec\n\nEfficient Estimation of Word Representations in Vector Space (2013), Mikolov, Chen, Corrado, and Dean"
  },
  {
    "objectID": "posts/03_regression/03_regression.html#bias-variance-trade-off",
    "href": "posts/03_regression/03_regression.html#bias-variance-trade-off",
    "title": "3: Regression",
    "section": "Bias-Variance Trade-off",
    "text": "Bias-Variance Trade-off\nWithin a hypothesis class of similar modeling functions, we are concerned with the bias-variance tradeoff in model selection.\n\n\n\nbias-variance tradeoff\n\n\nimage source: Scott Fortmann-Roe"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html",
    "href": "posts/01_introduction/01_introduction.html",
    "title": "1: Introductions",
    "section": "",
    "text": "Goal: Introduce course\nObjective: Describe types of learning\n\n\n\n\n\nmachine learning\n\n\nimage source: Sankalp Salve"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#start",
    "href": "posts/01_introduction/01_introduction.html#start",
    "title": "1: Introductions",
    "section": "",
    "text": "Goal: Introduce course\nObjective: Describe types of learning\n\n\n\n\n\nmachine learning\n\n\nimage source: Sankalp Salve"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#data-intelligence-modern-data-science-methods",
    "href": "posts/01_introduction/01_introduction.html#data-intelligence-modern-data-science-methods",
    "title": "1: Introductions",
    "section": "Data Intelligence: Modern Data Science Methods",
    "text": "Data Intelligence: Modern Data Science Methods\n\nFall 2025\nMonday, Wednesday, 1040 AM to 12 noon\nLecturer: Derek Sollberger\n\nI go by “Derek” or “teacher”\noffice hours:\n\nMon, 2 to 4 PM\nBendheim House 201\n\n\n\n\n\n\n\n\n\nCourse Description\n\n\n\n\n\nThis course provides the training for students to be independent in modern data analysis. The course emphasizes the rigorous treatment of data and the programming skills and conceptual understanding required for dealing with modern datasets. The course examines data analysis through the lens of statistics and machine learning methods. Students verify their understanding by working with real datasets. The course also covers supporting topics such as experiment design, ethical data use, best practices for statistical and machine learning methods, reproducible research, writing a quantitative research paper, and presenting research results."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#lecturer",
    "href": "posts/01_introduction/01_introduction.html#lecturer",
    "title": "1: Introductions",
    "section": "Lecturer",
    "text": "Lecturer"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#current-research-in-pedagogy",
    "href": "posts/01_introduction/01_introduction.html#current-research-in-pedagogy",
    "title": "1: Introductions",
    "section": "Current Research in Pedagogy",
    "text": "Current Research in Pedagogy\n\n\n\n\n\nactive learning\ncomputer programming\nflipped classrooms"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#textbooks",
    "href": "posts/01_introduction/01_introduction.html#textbooks",
    "title": "1: Introductions",
    "section": "Textbooks",
    "text": "Textbooks\n\nGeneralEnthusiastsCerebralHumanitiesall\n\n\n\n\nDeep Learning Illustrated Jon Krohn et al\nISLP James, Witten, Hastie, Tibshirani, Taylor\nML Cookbook Gallatin, Albon\n\n\n\n\n\nDL with Python Francois Chollet\nHands-On LLMs Allammar, Grootendorst\nStatQuest AI Josh Starmer\n\n\n\n\n\nProbabilistic ML Kevin P Murphy\nProgrammer’s Brain Felienne Hermans\nWhy Machines Learn Anil Ananthaswamy\n\n\n\n\n\nCo-Intelligence Ethan Mollick\nHow Data Happened Wiggins, Jones\nWeapons of Math Destruction Cathy O’Neil"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#cooperative-classroom",
    "href": "posts/01_introduction/01_introduction.html#cooperative-classroom",
    "title": "1: Introductions",
    "section": "Cooperative Classroom",
    "text": "Cooperative Classroom\nLearning in a cooperative environment should be stimulating, demanding, and fair. Because this approach to learning is different from the competitive classroom structure that many other courses used to be based on, it is important for us to be clear about mutual expectations. Below are my expectations for students in this class. This set of expectations is intended to maximize debate and exchange of ideas in an atmosphere of mutual respect while preserving individual ownership of ideas and written words. If you feel you do not understand or cannot agree to these expectations, you should discuss this with your instructor and classmates.\n\nStudents are expected to work cooperatively with other members of the class and show respect for the ideas and contributions of other people.\nWhen working as part of a group, students should strive to be good contributors to the group, listen to others, not dominate, and recognize the contributions of others. Students should try to ensure that everyone in the group is welcome to contribute and recognize that everyone contributes in different ways to a group process.\nStudents should explore data, make observations, and develop inferences as part of a group. If you use material from published sources, you must provide appropriate attribution.\n\n\n\n(Students will be asked to acknowledge this document in an online form.)\nThis document has been adapted from Scientific Teaching by Jo Handelsman, Sarah Miller, and Christine Pfund\n\n\n\n\nScientific Teaching"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#pep-talk",
    "href": "posts/01_introduction/01_introduction.html#pep-talk",
    "title": "1: Introductions",
    "section": "Pep Talk",
    "text": "Pep Talk\nLearning R can be difficult at first—it is like learning a new language, just like Spanish, French, or Chinese. Hadley Wickham—the chief data scientist at RStudio and the author of some amazing R packages you will be using like ggplot2—made this wise observation:\n\n\n\n\n\n\nWisdom from Hadley Wickham\n\n\n\n\n\nIt’s easy when you start out programming to get really frustrated and think, “Oh it’s me, I’m really stupid,” or, “I’m not made out to program.” But, that is absolutely not the case. Everyone gets frustrated. I still get frustrated occasionally when writing R code. It’s just a natural part of programming. So, it happens to everyone and gets less and less over time. Don’t blame yourself. Just take a break, do something fun, and then come back and try again later.\n\n\n\nIf you are finding yourself taking way too long hitting your head against a wall and not understanding, take a break, talk to classmates, ask questions … e-mail [Derek], etc. I promise you can do this.\n—Andrew Heiss, Georgia State University"
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#inclusion-statement",
    "href": "posts/01_introduction/01_introduction.html#inclusion-statement",
    "title": "1: Introductions",
    "section": "Inclusion Statement",
    "text": "Inclusion Statement\nI value all students regardless of their background, country of origin, race, religion, ethnicity, gender, sexual orientation, disability status, etc. and am committed to providing a climate of excellence and inclusiveness within all aspects of the course. If there are aspects of your culture or identity that you would like to share with me as they relate to your success in this class, I am happy to meet to discuss. Likewise, if you have any concerns in this area or facing any special issues or challenges, you are encouraged to discuss the matter with me (set up a meeting by e-mail) with an assurance of full confidentiality (only exception being mandatory reporting of academic integrity code violations or sexual harassment)."
  },
  {
    "objectID": "posts/01_introduction/01_introduction.html#tensorflow-playground",
    "href": "posts/01_introduction/01_introduction.html#tensorflow-playground",
    "title": "1: Introductions",
    "section": "TensorFlow Playground",
    "text": "TensorFlow Playground\n\nlink: https://playground.tensorflow.org\nexplore the various menus and buttons\nfeel free to run a simulation"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "SML 301 Spring 2025"
  },
  {
    "objectID": "posts/02_convergence/02_convergence.html",
    "href": "posts/02_convergence/02_convergence.html",
    "title": "2: Convergence",
    "section": "",
    "text": "Goal: Discuss convergence\nObjective: Explore some Python codes about root finding and stochastic processes\n\n\nAs we get started, try to load a session in Google Colab"
  },
  {
    "objectID": "posts/02_convergence/02_convergence.html#start",
    "href": "posts/02_convergence/02_convergence.html#start",
    "title": "2: Convergence",
    "section": "",
    "text": "Goal: Discuss convergence\nObjective: Explore some Python codes about root finding and stochastic processes\n\n\nAs we get started, try to load a session in Google Colab"
  },
  {
    "objectID": "posts/02_convergence/02_convergence.html#tensorflow-playground",
    "href": "posts/02_convergence/02_convergence.html#tensorflow-playground",
    "title": "2: Convergence",
    "section": "TensorFlow Playground",
    "text": "TensorFlow Playground\n\nlink: https://playground.tensorflow.org\nexplore the various menus and buttons\nfeel free to run a simulation"
  },
  {
    "objectID": "posts/02_convergence/02_convergence.html#sequences",
    "href": "posts/02_convergence/02_convergence.html#sequences",
    "title": "2: Convergence",
    "section": "Sequences",
    "text": "Sequences\n\nindex: \\(n \\in \\mathbb{N} = \\{1, 2, 3, 4, 5, ...\\}\\)\nformulaic: f(n) = 2n - 1\n\n\\[1, 3, 5, 7, 9, ...\\]\n\nconstructive:\n\n\\[3, 3.1, 3.14, 3.141, 3.1415, 3.14159, ...\\]\n\nshapes:\n\n\n\n\ntriangular numbers\n\n\n\nimage source: BYJUs"
  },
  {
    "objectID": "posts/02_convergence/02_convergence.html#random-variables",
    "href": "posts/02_convergence/02_convergence.html#random-variables",
    "title": "2: Convergence",
    "section": "Random Variables",
    "text": "Random Variables\nA random variable has no set value, but rather represents an element of chance. We can better understand a random variable through statistics like\n\nmean\nvariance\ndistribution\n\n\n\n\n\n\n\nStochastic Process\n\n\n\n\n\nA stochastic process is a sequence of random variables"
  },
  {
    "objectID": "posts/02_convergence/02_convergence.html#application-dinner-choices",
    "href": "posts/02_convergence/02_convergence.html#application-dinner-choices",
    "title": "2: Convergence",
    "section": "Application: Dinner Choices",
    "text": "Application: Dinner Choices\nSuppose that we have a Princeton student whose behavior includes eating only three types of dinner:\n\\[S = \\{\\text{ramen}, \\text{pizza}, \\text{sushi}\\}\\]\nwith transition matrix\n\\[P = \\left(\\begin{array}{ccc}\n0.2 & 0.4 & 0.4 \\\\\n0.3 & 0.4 & 0.3 \\\\\n0.2 & 0.2 & 0.6\n\\end{array}\\right)\\]\n\n\n\ndinner choices network\n\n\n\n\n\n\n\n\nNetwork terminology\n\n\n\n\n\n\ndirected versus undirected graphs\ncyclic versus acyclic graphs\n\nLater studies focus on DAGs: directed, acyclic network graphs\n\n\n\nSuppose that, on a Monday, the student’s preferences are\n\\[x_0 = \\left(\\begin{array}{ccc} 0.5 & 0.25 & 0.25 \\end{array}\\right)\\]\n\nWhat is the probability that the student will eat ramen on Tuesday (i.e. the next day)?\nWhat is the probability that the student will eat pizza on Wednesday (i.e. two days later)?\nWhat is the long-term dinner-choice behavior of this student?"
  },
  {
    "objectID": "posts/04_classification/04_classification.html",
    "href": "posts/04_classification/04_classification.html",
    "title": "4: Classification",
    "section": "",
    "text": "Goal: Start to discuss classification methods\nObjective: Explore logistic regression and Naive Bayes classifiers\n\n\nAs we get started, try to install the palmerpenguins package in your Python software"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#start",
    "href": "posts/04_classification/04_classification.html#start",
    "title": "4: Classification",
    "section": "",
    "text": "Goal: Start to discuss classification methods\nObjective: Explore logistic regression and Naive Bayes classifiers\n\n\nAs we get started, try to install the palmerpenguins package in your Python software"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#palmer-penguins-example",
    "href": "posts/04_classification/04_classification.html#palmer-penguins-example",
    "title": "4: Classification",
    "section": "Palmer Penguins Example",
    "text": "Palmer Penguins Example\n\n\n\n\n\n\n\n\n\n\n\nR Code\n\n\nadelie_color = \"#fb7504\"\nchinstrap_color = \"#c65ccc\"\ngentoo_color = \"#067476\"\n\npenguin_class_df &lt;- penguins |&gt;\n  na.omit() |&gt;\n  mutate(chinstrap_bool = ifelse(species == \"Chinstrap\", 1, 0)) |&gt;\n  mutate(across(chinstrap_bool, as.factor)) #https://stackoverflow.com/questions/33180058/coerce-multiple-columns-to-factors-at-once\n\npenguin_class_df |&gt;\nggplot(aes(x = flipper_length_mm, y = bill_length_mm, \n           color = chinstrap_bool)) + \n  geom_point(size = 3) + \n  labs(title = \"Classification Task\",\n       subtitle = \"Finding the &lt;span style = 'color:#c65ccc'&gt;Chinstrap&lt;/span&gt; penguins among n = 333 penguins\",\n       caption = \"SML 301\") +\n  scale_color_manual(values = c(\"gray70\", chinstrap_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n\n\n\nGeneralized Linear Models\n\nlogistic_model &lt;- stats::glm(chinstrap_bool ~ flipper_length_mm + bill_length_mm,\n                      data = penguin_class_df,\n                      family = binomial) #makes logistic regression\n\n\n\n\n\n\n\n\n\n\n\n\nR code\n\n\n# https://stats.stackexchange.com/questions/6206/how-to-plot-decision-boundary-in-r-for-logistic-regression-model\nbeta_0 &lt;- coef(logistic_model)[1]\nbeta_1 &lt;- coef(logistic_model)[2]\nbeta_2 &lt;- coef(logistic_model)[3]\nboundary_slope &lt;- -1.0 * beta_1 / beta_2\nboundary_intercept &lt;- -1.0 * beta_0 / beta_2\n\npenguin_pred_df &lt;- penguin_class_df |&gt;\n  mutate(species_pred = ifelse(\n    bill_length_mm &gt; boundary_intercept + boundary_slope * flipper_length_mm,\n    1,0)) |&gt;\n  mutate(across(species_pred, as.factor))\n\npenguin_pred_df |&gt;\nggplot(aes(x = flipper_length_mm, y = bill_length_mm, \n           color = species_pred)) + \n  geom_point(size = 3) + \n  geom_abline(intercept = boundary_intercept,\n              slope = boundary_slope,\n              color = adelie_color,\n              linewidth = 2,\n              linetype = 2) +\n  labs(title = \"&lt;span style = 'color:#fb7504'&gt;Decision Boundary&lt;/span&gt;\",\n       subtitle = \"where logit a = 0\",\n       caption = \"SML 301\") +\n  scale_color_manual(values = c(\"gray70\", chinstrap_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n\n\n\npenguin_pred_df |&gt;\n  janitor::tabyl(chinstrap_bool, species_pred) |&gt;\n  janitor::adorn_totals(c(\"row\", \"col\"))\n\n chinstrap_bool   0  1 Total\n              0 258  7   265\n              1   8 60    68\n          Total 266 67   333\n\n\n\naccuracy: 0.9550\nsensitivity: 0.8824\nspecificity: 0.9736"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#adaboost",
    "href": "posts/04_classification/04_classification.html#adaboost",
    "title": "4: Classification",
    "section": "Adaboost",
    "text": "Adaboost\n\nA Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting (1997—published as abstract in 1995), Freund and Schapire"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#alexnet",
    "href": "posts/04_classification/04_classification.html#alexnet",
    "title": "4: Classification",
    "section": "AlexNet",
    "text": "AlexNet\n\nImageNet Classification with Deep Convolutional Neural Networks (2012)"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#dropout",
    "href": "posts/04_classification/04_classification.html#dropout",
    "title": "4: Classification",
    "section": "DropOut",
    "text": "DropOut\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting (2014), Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#gans",
    "href": "posts/04_classification/04_classification.html#gans",
    "title": "4: Classification",
    "section": "GANs",
    "text": "GANs\n\nGeneral Adversarial Nets (2014), Goodfellow et al."
  },
  {
    "objectID": "posts/04_classification/04_classification.html#tensorflow",
    "href": "posts/04_classification/04_classification.html#tensorflow",
    "title": "4: Classification",
    "section": "TensorFlow",
    "text": "TensorFlow\n\nTensorFlow: A system for large-scale machine learning (2016), Abadi et al."
  },
  {
    "objectID": "posts/04_classification/04_classification.html#word2vec",
    "href": "posts/04_classification/04_classification.html#word2vec",
    "title": "4: Classification",
    "section": "Word2Vec",
    "text": "Word2Vec\n\nEfficient Estimation of Word Representations in Vector Space (2013), Mikolov, Chen, Corrado, and Dean"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#data-palmer-penguins",
    "href": "posts/04_classification/04_classification.html#data-palmer-penguins",
    "title": "4: Classification",
    "section": "Data: Palmer Penguins",
    "text": "Data: Palmer Penguins\nThere exist multiple penguin species throughout Antarctica, including the Adelie, Chinstrap, and Gentoo. When encountering one of these penguins on an Antarctic trip, we might classify its species\n\\[Y = \\begin{cases} A & \\text{Adelie} \\\\ C & \\text{Chinstrap} \\\\ G & \\text{Gentoo} \\end{cases}\\]\n\n\n\nthree species\n\n\nExample comes from chapter 14 of Bayes Rules!\n\n\n\nBayes Rules! textbook\n\n\n\\(X_{1}\\) categorical variable: whether the penguin weighs more than the average 4200 grams\n\\[X_{1} = \\begin{cases} 1 & \\text{above-average weight} \\\\ 0 & \\text{below-average weight} \\end{cases}\\]\n\n\n\nAKA culmen length and depth\n\n\nNumerical variables:\n\\[\\begin{array}{rcl}\n  X_{2} & = & \\text{bill length (mm)} \\\\\n  X_{3} & = & \\text{flipper length (mm)} \\\\\n\\end{array}\\]\n\ndata(penguins_bayes)\npenguins &lt;- penguins_bayes\n\nadelie_color = \"#fb7504\"\nchinstrap_color = \"#c65ccc\"\ngentoo_color = \"#067476\"\n\npenguins |&gt;\n  tabyl(species)\n\n   species   n   percent\n    Adelie 152 0.4418605\n Chinstrap  68 0.1976744\n    Gentoo 124 0.3604651"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#motivation",
    "href": "posts/04_classification/04_classification.html#motivation",
    "title": "4: Classification",
    "section": "Motivation",
    "text": "Motivation\nHere, we have three categories, whereas logistic regression is limited to classifying binary response variables. As an alternative, naive Bayes classification\n\ncan classify categorical response variables \\(Y\\) with two or more categories\ndoesn’t require much theory beyond Bayes’ Rule\nit’s computationally efficient, i.e., doesn’t require MCMC simulation\n\nBut why is it called “naive”?"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#one-categorical-predictor",
    "href": "posts/04_classification/04_classification.html#one-categorical-predictor",
    "title": "4: Classification",
    "section": "One Categorical Predictor",
    "text": "One Categorical Predictor\nSuppose an Antarctic researcher comes across a penguin that weighs less than 4200g with a 195mm-long flipper and 50mm-long bill. Our goal is to help this researcher identify the species of this penguin: Adelie, Chinstrap, or Gentoo\n\n\n\n\n\n\n\n\n\n\n\nimage code\n\n\npenguins |&gt;\n  drop_na(above_average_weight) |&gt;\n  ggplot(aes(fill = above_average_weight, x = species)) + \n  geom_bar(position = \"fill\") + \n  labs(title = \"&lt;span style = 'color:#067476'&gt;For which species is a&lt;br&gt;below-average weight most likely?&lt;/span&gt;\",\n       subtitle = \"(focus on the &lt;span style = 'color:#c65ccc'&gt;below-average&lt;/span&gt; category)\",\n       caption = \"SML 301\") +\n  scale_fill_manual(values = c(\"#c65ccc\", \"#fb7504\")) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n\n\n\nRecall: Bayes Rule\n\\[f(y|x_{1}) = \\frac{\\text{prior}\\cdot\\text{likelihood}}{\\text{normalizing constant}} = \\frac{f(y) \\cdot L(y|x_{1})}{f(x_{1})}\\] where, by the Law of Total Probability,\n\\[\\begin{array}{rcl}\nf(x_{1} & = & \\displaystyle\\sum_{\\text{all } y'} f(y')L(y'|x_{1}) \\\\\n~ & = & f(y' = A)L(y' = A|x_{1}) + f(y' = C)L(y' = C|x_{1}) + f(y' = G)L(y' = G|x_{1}) \\\\\n\\end{array}\\]\nover our three penguin species.\n\n\nCalculation\n\npenguins |&gt; \n  select(species, above_average_weight) |&gt; \n  na.omit() |&gt; \n  tabyl(species, above_average_weight) |&gt; \n  adorn_totals(c(\"row\", \"col\"))\n\n   species   0   1 Total\n    Adelie 126  25   151\n Chinstrap  61   7    68\n    Gentoo   6 117   123\n     Total 193 149   342\n\n\nPrior probabilities:\n\\[f(y = A) = \\frac{151}{342}, \\quad f(y = C) = \\frac{68}{342}, \\quad f(y = G) = \\frac{123}{342}\\]\nLikelihoods:\n\\[\\begin{array}{rcccl}\n  L(y = A | x_{1} = 0) & = & \\frac{126}{151} & \\approx & 0.8344 \\\\\n  L(y = C | x_{1} = 0) & = & \\frac{61}{68} & \\approx & 0.8971 \\\\\n  L(y = G | x_{1} = 0) & = & \\frac{6}{123} & \\approx & 0.0488 \\\\\n\\end{array}\\]\nTotal probability:\n\\[f(x_{1} = 0) = \\frac{151}{342}\\cdot\\frac{126}{151} + \\frac{68}{342}\\cdot\\frac{61}{68} + \\frac{123}{342}\\cdot\\frac{6}{123} = \\frac{193}{342}\\]\nBayes’ Rules:\n\\[\\begin{array}{rcccccl}\n  f(y = A | x_{1} = 0) & = & \\frac{f(y = A) \\cdot L(y = A | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{151}{342}\\cdot\\frac{126}{151}}{\\frac{193}{342}} & \\approx & 0.6528 \\\\\n  f(y = C | x_{1} = 0) & = & \\frac{f(y = A) \\cdot L(y = C | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{68}{342}\\cdot\\frac{61}{68}}{\\frac{193}{342}} & \\approx & 0.3161 \\\\\n  f(y = G | x_{1} = 0) & = & \\frac{f(y = A) \\cdot L(y = G | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{123}{342}\\cdot\\frac{6}{123}}{\\frac{193}{342}} & \\approx & 0.0311 \\\\\n\\end{array}\\]\nThe posterior probability that this penguin is an Adelie is more than double that of the other two species"
  },
  {
    "objectID": "posts/04_classification/04_classification.html#one-numerical-predictor",
    "href": "posts/04_classification/04_classification.html#one-numerical-predictor",
    "title": "4: Classification",
    "section": "One Numerical Predictor",
    "text": "One Numerical Predictor\nLet’s ignore the penguin’s weight for now and classify its species using only the fact that it has a 50mm-long bill\n\n\n\n\n\n\n\n\n\n\n\nimage code\n\n\npenguins|&gt;\n  ggplot(aes(x = bill_length_mm, fill = species)) + \n  geom_density(alpha = 0.7) + \n  geom_vline(xintercept = 50, linetype = \"dashed\", linewidth = 3) + \n  labs(title = \"&lt;span style = 'color:#c65ccc'&gt;For which species is a&lt;br&gt;50mm-long bill the most common?&lt;/span&gt;\",\n       subtitle = \"one numerical predictor\",\n       caption = \"SML 301\") +\n  scale_fill_manual(values = c(adelie_color, chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n\n\nOur data points to our penguin being a Chinstrap\n\nwe must weigh this data against the fact that Chinstraps are the rarest of these three species\ndifficult to compute likelihood \\(L(y = A | x_{2} = 50)\\)\n\nThis is where one “naive” part of naive Bayes classification comes into play. The naive Bayes method typically assumes that any quantitative predictor, here \\(X_{2}\\), is continuous and conditionally normal:\n\\[\\begin{array}{rcl}\n  X_{2} | (Y = A) & \\sim & N(\\mu_{A}, \\sigma_{A}^{2}) \\\\\n  X_{2} | (Y = C) & \\sim & N(\\mu_{C}, \\sigma_{C}^{2}) \\\\\n  X_{2} | (Y = G) & \\sim & N(\\mu_{G}, \\sigma_{G}^{2}) \\\\\n\\end{array}\\]\n\nPrior Probability Distributions\n\n# Calculate sample mean and sd for each Y group\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(mean = mean(bill_length_mm, na.rm = TRUE), \n            sd = sd(bill_length_mm, na.rm = TRUE))\n\n# A tibble: 3 × 3\n  species    mean    sd\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     38.8  2.66\n2 Chinstrap  48.8  3.34\n3 Gentoo     47.5  3.08\n\n\n\npenguins |&gt;\n  ggplot(aes(x = bill_length_mm, color = species)) + \n  stat_function(fun = dnorm, args = list(mean = 38.8, sd = 2.66), \n                aes(color = \"Adelie\"), linewidth = 3) +\n  stat_function(fun = dnorm, args = list(mean = 48.8, sd = 3.34),\n                aes(color = \"Chinstrap\"), linewidth = 3) +\n  stat_function(fun = dnorm, args = list(mean = 47.5, sd = 3.08),\n                aes(color = \"Gentoo\"), linewidth = 3) +\n  ...\n\n\n\n\n\n\n\n\n\n\n\n\nimage code\n\n\npenguins |&gt;\n  ggplot(aes(x = bill_length_mm, color = species)) + \n  stat_function(fun = dnorm, args = list(mean = 38.8, sd = 2.66), \n                aes(color = \"Adelie\"), linewidth = 3) +\n  stat_function(fun = dnorm, args = list(mean = 48.8, sd = 3.34),\n                aes(color = \"Chinstrap\"), linewidth = 3) +\n  stat_function(fun = dnorm, args = list(mean = 47.5, sd = 3.08),\n                aes(color = \"Gentoo\"), linewidth = 3) + \n  geom_vline(xintercept = 50, linetype = \"dashed\") + \n  labs(title = \"&lt;span style = 'color:#c65ccc'&gt;Prior Probabilities&lt;/span&gt;\",\n       subtitle = \"conditionally normal\",\n       caption = \"SML 301\") +\n  scale_color_manual(values = c(adelie_color, chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n\n\nComputing the likelihoods in R:\n\n# L(y = A | x_2 = 50) = 2.12e-05\ndnorm(50, mean = 38.8, sd = 2.66)\n\n# L(y = C | x_2 = 50) = 0.112\ndnorm(50, mean = 48.8, sd = 3.34)\n\n# L(y = G | x_2 = 50) = 0.09317\ndnorm(50, mean = 47.5, sd = 3.08)\n\nTotal probability:\n\\[f(x_{2} = 50) = \\frac{151}{342} \\cdot 0.0000212 + \\frac{68}{342} \\cdot 0.112 + \\frac{123}{342} \\cdot 0.09317 \\approx 0.05579\\]\nBayes’ Rules:\n\\[\\begin{array}{rcccccl}\n  f(y = A | x_{2} = 50) & = & \\frac{f(y = A) \\cdot L(y = A | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{151}{342} \\cdot 0.0000212}{0.05579} & \\approx & 0.0002 \\\\\n  f(y = C | x_{2} = 50) & = & \\frac{f(y = A) \\cdot L(y = C | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{68}{342} \\cdot 0.112}{0.05579} & \\approx & 0.3992 \\\\\n  f(y = G | x_{2} = 50) & = & \\frac{f(y = A) \\cdot L(y = G | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{123}{342} \\cdot 0.09317}{0.05579} & \\approx & 0.6006 \\\\\n\\end{array}\\]\nThough a 50mm-long bill is relatively less common among Gentoo than among Chinstrap, it follows that our naive Bayes classification, based on our prior information and penguin’s bill length alone, is that this penguin is a Gentoo – it has the highest posterior probability.\nWe’ve now made two naive Bayes classifications of our penguin’s species, one based solely on the fact that our penguin has below-average weight and the other based solely on its 50mm-long bill (in addition to our prior information). And these classifications disagree: we classified the penguin as Adelie in the former analysis and Gentoo in the latter. This discrepancy indicates that there’s room for improvement in our naive Bayes classification method."
  },
  {
    "objectID": "posts/04_classification/04_classification.html#two-predictor-variables",
    "href": "posts/04_classification/04_classification.html#two-predictor-variables",
    "title": "4: Classification",
    "section": "Two Predictor Variables",
    "text": "Two Predictor Variables\n\n\n\n\n\n\n\n\n\n\n\nimage code\n\n\npenguins |&gt;\nggplot(aes(x = flipper_length_mm, y = bill_length_mm, \n           color = species)) + \n  geom_point(size = 3) + \n  geom_segment(aes(x = 195, y = 30, xend = 195, yend = 50),\n               color = \"black\", linetype = 2, linewidth = 2) +\n  geom_segment(aes(x = 170, y = 50, xend = 195, yend = 50),\n               color = \"black\", linetype = 2, linewidth = 2) +\n  labs(title = \"&lt;span style = 'color:#c65ccc'&gt;Two Predictor Variables&lt;/span&gt;\",\n       subtitle = \"50mm-long bill and 195mm-long flipper\",\n       caption = \"SML 301\") +\n  scale_color_manual(values = c(adelie_color, chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n\n\nGeneralizing Bayes’ Rule:\n\\[f(y | x_{2}, x_{3}) = \\frac{f(y) \\cdot L(y | x_{2}, x_{3})}{\\sum_{y'} f(y') \\cdot L(y' | x_{2}, x_{3})}\\]\nAnother “naive” assumption of conditionally independent:\n\\[L(y | x_{2}, x_{3}) = f(x_{2}, x_{3} | y) = f(x_{2} | y) \\cdot f(x_{3} | y)\\]\n\nmathematically efficient\nbut what about correlation?\n\n\n# sample statistics of x_3: flipper length\npenguins |&gt; \n  group_by(species) |&gt; \n  summarize(mean = mean(flipper_length_mm, na.rm = TRUE), \n            sd = sd(flipper_length_mm, na.rm = TRUE))\n\n# A tibble: 3 × 3\n  species    mean    sd\n  &lt;fct&gt;     &lt;dbl&gt; &lt;dbl&gt;\n1 Adelie     190.  6.54\n2 Chinstrap  196.  7.13\n3 Gentoo     217.  6.48\n\n\nLikelihoods of a flipper length of 195 mm:\n\n# L(y = A | x_3 = 195) = 0.04554\ndnorm(195, mean = 190, sd = 6.54)\n\n# L(y = C | x_3 = 195) = 0.05541\ndnorm(195, mean = 196, sd = 7.13)\n\n# L(y = G | x_3 = 195) = 0.0001934\ndnorm(195, mean = 217, sd = 6.48)\n\nTotal probability:\n\\[f(x_{2} = 50, x_{3} = 195) = \\frac{151}{342} \\cdot 0.0000212 \\cdot 0.04554 + \\frac{68}{342} \\cdot 0.112 \\cdot 0.05541 + \\frac{123}{342} \\cdot 0.09317 \\cdot 0.0001931 \\approx 0.001241\\]\nBayes’ Rules:\n\\[\\begin{array}{rcccl}\n  f(y = A | x_{2} = 50, x_{3} = 195) & = & \\frac{\\frac{151}{342} \\cdot 0.0000212 \\cdot 0.04554}{0.0001931} & \\approx & 0.0003 \\\\\n  f(y = C | x_{2} = 50, x_{3} = 195) & = & \\frac{\\frac{68}{342} \\cdot 0.112 \\cdot 0.05541}{0.0001931} & \\approx & 0.9944 \\\\\n  f(y = G | x_{2} = 50, x_{3} = 195) & = & \\frac{\\frac{123}{342} \\cdot 0.09317 \\cdot 0.0001931}{0.0001931} & \\approx & 0.0052 \\\\\n\\end{array}\\]\nIn conclusion, our penguin is almost certainly a Chinstrap."
  },
  {
    "objectID": "posts/04_classification/SML_301_session_4.html",
    "href": "posts/04_classification/SML_301_session_4.html",
    "title": "Data Cleaning",
    "section": "",
    "text": "#%pip install palmerpenguins #https://github.com/mcnakhaee/palmerpenguins\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\n\nfrom palmerpenguins import load_penguins\nfrom sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\npenguins = load_penguins()\ntype(penguins)\npenguins['chinstrap_bool'] = np.where(penguins['species'] == 'Chinstrap', 1, 0)\npenguins.head()\n# remember to remove missing values before a machine learning algorithm\npenguins_subset = penguins[['chinstrap_bool', 'flipper_length_mm', 'bill_length_mm']].dropna()\npenguins_subset.head()"
  },
  {
    "objectID": "posts/04_classification/SML_301_session_4.html#one-predictor-variable",
    "href": "posts/04_classification/SML_301_session_4.html#one-predictor-variable",
    "title": "Data Cleaning",
    "section": "One predictor variable",
    "text": "One predictor variable\n\nX = penguins_subset[['flipper_length_mm']] #explanatory variable\ny = penguins_subset['chinstrap_bool'] #response variable (Boolean)\n\n\n#main code for logistic regression\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\n\n# make predictions\ny_pred = logreg.predict(X_test)"
  },
  {
    "objectID": "posts/04_classification/SML_301_session_4.html#confusion-matrix",
    "href": "posts/04_classification/SML_301_session_4.html#confusion-matrix",
    "title": "Data Cleaning",
    "section": "Confusion Matrix",
    "text": "Confusion Matrix\n\nconfusion_mat = confusion_matrix(y_test, y_pred)\nprint(confusion_mat)\n\n\n# metrics from a confusion matrix\nprint(classification_report(y_test, y_pred))"
  },
  {
    "objectID": "posts/04_classification/SML_301_session_4.html#preview-roc-curves",
    "href": "posts/04_classification/SML_301_session_4.html#preview-roc-curves",
    "title": "Data Cleaning",
    "section": "Preview: ROC Curves",
    "text": "Preview: ROC Curves\nROC curves (receiver operating characteristic) are very popular for helping judge the quality of a classification computation.\n\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()"
  },
  {
    "objectID": "posts/04_classification/SML_301_session_4.html#two-predictor-variables",
    "href": "posts/04_classification/SML_301_session_4.html#two-predictor-variables",
    "title": "Data Cleaning",
    "section": "Two predictor variables",
    "text": "Two predictor variables\n\nX = penguins_subset[['flipper_length_mm', 'bill_length_mm']] #explanatory variables\ny = penguins_subset['chinstrap_bool'] #response variable (Boolean)\n\n\n#main code for logistic regression\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\nlogreg = LogisticRegression()\nlogreg.fit(X_train, y_train)\n\n\n# make predictions\ny_pred = logreg.predict(X_test)\n\n\nconfusion_mat = confusion_matrix(y_test, y_pred)\nprint(confusion_mat)\n\n\n# metrics from a confusion matrix\nprint(classification_report(y_test, y_pred))\n\n\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()"
  },
  {
    "objectID": "posts/04_classification/SML_301_session_4.html#one-categorical-predictor",
    "href": "posts/04_classification/SML_301_session_4.html#one-categorical-predictor",
    "title": "Data Cleaning",
    "section": "One categorical predictor",
    "text": "One categorical predictor\n\nmean_weight = penguins['body_mass_g'].mean()\npenguins['above_average_weight'] = np.where(penguins['body_mass_g'] &gt; mean_weight, 1, 0)\npenguins_subset = penguins[['species', 'above_average_weight']].dropna()\npenguins_subset.head()\nX = penguins_subset[['above_average_weight']] #explanatory variable\ny = penguins_subset['species'] #response variable (Boolean)\n\n\n# main code for Naive Bayes\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\nNB_model = GaussianNB()\nNB_model.fit(X_train, y_train)\ny_pred = NB_model.predict(X_test)\n\n\n# make one prediction\nprint(NB_model.predict([[0]])) #here, \"0\" for \"below-average weight\"\n\n\nconfusion_mat = confusion_matrix(y_test, y_pred)\nsns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', cbar=False)\n\n\n# metrics from a confusion matrix\nprint(classification_report(y_test, y_pred))"
  },
  {
    "objectID": "posts/04_classification/SML_301_session_4.html#two-predictor-variables-1",
    "href": "posts/04_classification/SML_301_session_4.html#two-predictor-variables-1",
    "title": "Data Cleaning",
    "section": "Two predictor variables",
    "text": "Two predictor variables\n\npenguins_subset = penguins[['species', 'bill_length_mm', 'flipper_length_mm']].dropna()\npenguins_subset.head()\nX = penguins_subset[['bill_length_mm', 'flipper_length_mm']] #explanatory variables\ny = penguins_subset['species'] #response variable (Boolean)\n\n\n# main code for Naive Bayes\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=301)\nNB_model = GaussianNB()\nNB_model.fit(X_train, y_train)\ny_pred = NB_model.predict(X_test)\n\n\n# make one prediction\nprint(NB_model.predict([[50, 195]]))\n\n\nconfusion_mat = confusion_matrix(y_test, y_pred)\nsns.heatmap(confusion_mat, annot=True, fmt='d', cmap='Blues', cbar=False)\n\n\n# metrics from a confusion matrix\nprint(classification_report(y_test, y_pred))"
  },
  {
    "objectID": "posts/05_svm/05_svm.html",
    "href": "posts/05_svm/05_svm.html",
    "title": "5: Support Vector Machines",
    "section": "",
    "text": "Implement a binary classification model using a maximal margin classifier.\nImplement a binary classification model using a support vector classifier.\nImplement a binary classification model using a support vector machine (SVM).\nGeneralize SVM models to multi-class cases.\n\n\n\n\n\n\n\nsupport vector machines!\n\n\n\n\n\n\n\n\nMMC to SVMMermaid code\n\n\nSupport vector machine (SVM), an approach for classification developed in 1990. SVM is a generalizaion of classifiers methods, in particular:\n\nmaximal margin classifier (it requires that the classes be separable by a linear boundary).\nsupport vector classifier\nsupport vector machine: binary classification setting with two classes\n\n\n\n\n\n\n\n\n\n(optional for this course)\n\n# DiagrammR package\nmermaid(\"\ngraph TB\n  A[SVM&lt;br&gt;support vector machine&lt;br&gt;non-linear class boundaries]\n\n  B[MMC&lt;br&gt;maximal margin classifier&lt;br&gt;linear class boundaries] \n  B--&gt;C[SVC&lt;br&gt;support vector classifier&lt;br&gt;applied in a broader range of cases]\n  A--&gt;C\n\n\")"
  },
  {
    "objectID": "posts/05_svm/05_svm.html#learning-objectives",
    "href": "posts/05_svm/05_svm.html#learning-objectives",
    "title": "5: Support Vector Machines",
    "section": "",
    "text": "Implement a binary classification model using a maximal margin classifier.\nImplement a binary classification model using a support vector classifier.\nImplement a binary classification model using a support vector machine (SVM).\nGeneralize SVM models to multi-class cases.\n\n\n\n\n\n\n\nsupport vector machines!"
  },
  {
    "objectID": "posts/05_svm/05_svm.html#overview",
    "href": "posts/05_svm/05_svm.html#overview",
    "title": "5: Support Vector Machines",
    "section": "",
    "text": "MMC to SVMMermaid code\n\n\nSupport vector machine (SVM), an approach for classification developed in 1990. SVM is a generalizaion of classifiers methods, in particular:\n\nmaximal margin classifier (it requires that the classes be separable by a linear boundary).\nsupport vector classifier\nsupport vector machine: binary classification setting with two classes\n\n\n\n\n\n\n\n\n\n(optional for this course)\n\n# DiagrammR package\nmermaid(\"\ngraph TB\n  A[SVM&lt;br&gt;support vector machine&lt;br&gt;non-linear class boundaries]\n\n  B[MMC&lt;br&gt;maximal margin classifier&lt;br&gt;linear class boundaries] \n  B--&gt;C[SVC&lt;br&gt;support vector classifier&lt;br&gt;applied in a broader range of cases]\n  A--&gt;C\n\n\")"
  },
  {
    "objectID": "posts/05_svm/05_svm.html#separating-hyperplane",
    "href": "posts/05_svm/05_svm.html#separating-hyperplane",
    "title": "5: Support Vector Machines",
    "section": "Separating Hyperplane",
    "text": "Separating Hyperplane\n\nConsider a matrix X of dimensions \\(n*p\\), and a \\(y_{i} \\in \\{-1, 1\\}\\). We have a new observation, \\(x^*\\), which is a vector \\(x^* = (x^*_{1}...x^*_{p})^T\\) which we wish to classify to one of two groups.\nWe will use a separating hyperplane to classify the observation.\n\n\n\nWe can label the blue observations as \\(y_{i} = 1\\) and the pink observations as \\(y_{i} = -1\\).\nThus, a separating hyperplane has the property s.t. \\(\\beta_{0} + \\beta_{1}X_{i1} + \\beta_{2}X_{i2} ... + \\beta_{p}X_{ip} &gt; 0\\) if \\(y_{i} =1\\) and \\(\\beta_{0} + \\beta_{1}X_{i1} + \\beta_{2}X_{i2} ... + \\beta_{p}X_{ip} &lt; 0\\) if \\(y_{i} = -1\\).\nIn other words, a separating hyperplane has the property s.t. \\(y_{i}(\\beta_{0} + \\beta_{1}X_{i1} + \\beta_{2}X_{i2} ... + \\beta_{p}X_{ip}) &gt; 0\\) for all \\(i = 1...n\\).\nConsider also the magnitude of \\(f(x^*)\\). If it is far from zero, we are confident in its classification, whereas if it is close to 0, then \\(x^*\\) is located near the hyperplane, and we are less confident about its classification.\n\n\n\n\n\n\n\nConceptual Task 1B\n\n\n\n\n\n\nISLR, Chapter 9, Conceptual Task 1B\n\n\nOn the same plot, sketch the hyperplane \\(-2 + X_{1} + 2X_{2} = 0\\). Indicate the set of points for which \\(-2 + X_{1} + 2X_{2} &gt; 0\\), as well as the set of points for which \\(-2 + X_{1} + 2X_{2} &lt; 0\\).\n\n\nblue: \\(-2 + X_{1} + 2X_{2} &gt; 0\\)\nred: \\(-2 + X_{1} + 2X_{2} &lt; 0\\)"
  },
  {
    "objectID": "posts/05_svm/05_svm.html#maximal-margin-classifier",
    "href": "posts/05_svm/05_svm.html#maximal-margin-classifier",
    "title": "5: Support Vector Machines",
    "section": "Maximal Margin Classifier",
    "text": "Maximal Margin Classifier\n\n\nGenerally, if data can be perfectly separated using a hyperplane, an infinite amount of such hyperplanes exist.\nAn intuitive choice is the maximal margin hyperplane, which is the hyperplane that is farthest from the training data.\nWe compute the perpendicular distance from each training observation to the hyperplane. The smallest of these distances is known as the margin.\nThe maximal margin hyperplane is the hyperplane for which the margin is maximized. We can classify a test observation based on which side of the maximal margin hyperplane it lies on, and this is known as the maximal margin classifier.\nThe maximal margin classifier classifies \\(x^*\\) based on the sign of \\(f(x^*) = \\beta_{0} + \\beta_{1}x^*_{1} + ... + \\beta_{p}x^*_{p}\\).\n\n\n\nNote the 3 training observations that lie on the margin and are equidistant from the hyperplane. These are the support vectors (vectors in \\(p\\)-dimensional space; in this case \\(p=2\\)).\nThey support the hyperplane because if their location was changed, the hyperplane would change.\nThe maximal margin hyperplane depends on these observations, but not the others (unless the other observations were moved at or within the margin).\n\n\n\n\n\n\n\nConceptual Task 3\n\n\n\n\n\n\n\n  obs xvals yvals class_label\n1   1     3     4         Red\n2   2     2     2         Red\n3   3     4     4         Red\n4   4     1     4         Red\n5   5     2     1        Blue\n6   6     4     3        Blue\n7   7     4     1        Blue\n\n\n\nWe are given \\(n = 7\\) observations in \\(p = 2\\) dimensions. For each observation, there is an associated class label.\n\n\n\n\n\n\n\n\n\n\n\nSketch the optimal separating hyperplane, and provide the equation for this hyperplane\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nblue: \\(0.5 - X_{1} + X_{2} &lt; 0\\)\nred: \\(0.5 - X_{1} + X_{2} &gt; 0\\)\n\n\nmaximal margin in indicated by the dashed lines, with margin\n\n\\[M = \\frac{0.5}{\\sqrt{2}} \\approx 0.3536\\]\n\nIndicate the support vectors for the maximal margin classifier.\n\n\n\n\n\n\n\n\n\n\n\nArgue that a slight movement of the seventh observation would not affect the maximal margin hyperplane.\nSketch a hyperplane that is not the optimal separating hyperplane, and provide the equation for this hyperplane.\n\n\n\n\n\n\n\n\n\n\n\nDraw an additional observation on the plot so that the two classes are no longer separable by a hyperplane."
  },
  {
    "objectID": "posts/05_svm/05_svm.html#mathematics-of-the-mmc",
    "href": "posts/05_svm/05_svm.html#mathematics-of-the-mmc",
    "title": "5: Support Vector Machines",
    "section": "Mathematics of the MMC",
    "text": "Mathematics of the MMC\n\nConsider constructing an MMC based on the training observations \\(x_{1}...x_{n} \\in \\mathbb{R}^p\\). This is the solution to the optimization problem:\n\n\\[\\text{max}_{\\beta_{0}...\\beta_{p}, M} \\space M\\] \\[\\text{subject to } \\sum_{j=1}^{p}\\beta_{j}^2 = 1\\] \\[y_{i}(\\beta_{0} + \\beta_{1}X_{i1} + \\beta_{2}X_{i2} ... + \\beta_{p}X_{ip}) \\geq M \\quad \\forall i = 1...n\\]\n\n\\(M\\) is the margin, and the \\(\\beta\\) coeffients are chosen to maximize \\(M\\).\nThe constraint (3rd equation) ensures that each observation will be correctly classified, as long as M is positive.\n\n\n\nThe 2nd and 3rd equations ensure that each data point is on the correct side of the hyperplane and at least M-distance away from the hyperplane.\nThe perpendicular distance to the hyperplane is given by \\(y_{i}(\\beta_{0} + \\beta_{1}x_{i1} + \\beta_{2}x_{i2} ... + \\beta_{p}x_{ip})\\).\n\n\nBut what if our data is not separable by a linear hyperplane?\n\n\n\nIndividual data points greatly affect formation of the maximal margin classifier"
  },
  {
    "objectID": "posts/05_svm/05_svm.html#mathematics-of-the-svc",
    "href": "posts/05_svm/05_svm.html#mathematics-of-the-svc",
    "title": "5: Support Vector Machines",
    "section": "Mathematics of the SVC",
    "text": "Mathematics of the SVC\n\nThe SVC classifies a test observation based on which side of the hyperplane it lies.\n\n\\[\\text{max}_{\\beta_{0}...\\beta_{p}, \\epsilon_{1}...\\epsilon_{n}, M} \\space M\\] \\[\\text{subject to } \\sum_{j=1}^{p}\\beta_{j}^2 = 1\\] \\[y_{i}(\\beta_{0} + \\beta_{1}X_{i1} + \\beta_{2}X_{i2} ... + \\beta_{p}X_{ip}) \\geq M(1 - \\epsilon_{i})\\] \\[\\epsilon_{i} \\geq 0, \\quad \\sum_{i=1}^{n}\\epsilon_{i} \\leq C\\]\n\n\\(C\\) is a nonnegative tuning parameter, typically chosen through cross-validation, and can be thought of as the budget for margin violation by the observations.\nThe \\(\\epsilon_{i}\\) are slack variables that allow individual observations to be on the wrong side of the margin or hyperplane. The \\(\\epsilon_{i}\\) indicates where the \\(i^{\\text{th}}\\) observation is located with regards to the margin and hyperplane.\n\nIf \\(\\epsilon_{i} = 0\\), the observation is on the correct side of the margin.\nIf \\(\\epsilon_{i} &gt; 0\\), the observation is on the wrong side of margin\nIf \\(\\epsilon_{i} &gt; 1\\), the observation is on the wrong side of the hyperplane.\n\nSince \\(C\\) constrains the sum of the \\(\\epsilon_{i}\\), it determines the number and magnitude of violations to the margin. If \\(C=0\\), there is no margin for violation, thus all the \\(\\epsilon_{1},...,\\epsilon_{n} = 0\\).\nNote that if \\(C&gt;0\\), no more than \\(C\\) observations can be on wrong side of hyperplane, since in these cases \\(\\epsilon_{i} &gt; 1\\)."
  },
  {
    "objectID": "posts/05_svm/05_svm.html#tuning-parameter",
    "href": "posts/05_svm/05_svm.html#tuning-parameter",
    "title": "5: Support Vector Machines",
    "section": "Tuning Parameter",
    "text": "Tuning Parameter\n\n\nA property of the classifier is that only data points which lie on or violate the margin will affect the hyperplane. These data points are known as support vectors.\n\\(C\\) controls the bias-variance tradeoff of the classifier.\n\nWhen \\(C\\) is large: high bias, low variance\nWhen \\(C\\) is small: low bias, high variance\n\nThe property of the SVC solely being dependent on certain observations in classification differs from other classification methods such as LDA (depends on mean of all observations in each class, as well as each class’s covariance matrix using all observations).\nHowever, logistic regression is more similar to SVC in that it has low sensitivity to observations far from the decision boundary."
  },
  {
    "objectID": "posts/05_svm/05_svm.html#nonlinear-classification",
    "href": "posts/05_svm/05_svm.html#nonlinear-classification",
    "title": "5: Support Vector Machines",
    "section": "Nonlinear Classification",
    "text": "Nonlinear Classification\n\nMany decision boundaries are not linear.\nWe could fit an SVC to the data using \\(2p\\) features (in the case of \\(p\\) features and using a quadratic form).\n\n\\[X_{1}, X_{1}^{2}, \\quad X_{2}, X_{2}^{2}, \\quad\\cdots, \\quad X_{p}, X_{p}^{2}\\]\n\\[\\text{max}_{\\beta_{0},\\beta_{11},\\beta_{12},\\dots,\\beta_{p1},\\beta_{p2} \\epsilon_{1},\\dots,\\epsilon_{n}, M} \\space M\\] \\[\\text{subject to }  y_{i}\\left(\\beta_{0} + \\sum_{j=1}^{p} \\beta_{ji}x_{ji} + \\sum_{j=1}^{p} \\beta_{ji}x_{ji}^{2}\\right) \\geq M(1 - \\epsilon_{i})\\]\n\\[\\epsilon_{i} \\geq 0, \\quad \\sum_{i=1}^{n}\\epsilon_{i} \\leq C, \\quad \\sum_{j=1}^{p}\\sum_{k=1}^{2} \\beta_{jk}^{2} = 1\\]\n\nNote that in the enlarged feature space (here, with the quadratic terms), the decision boundary is linear. But in the original feature space, it is quadratic \\(q(x) = 0\\) (in this example), and generally the solutions are not linear.\nOne could also include interaction terms, higher degree polynomials, etc., and thus the feature space could enlarge quickly and entail unmanageable computations.\n\n\n\n\n\n\n\nConceptual Task 2\n\n\n\n\n\nWe now investigate a non-linear decision boundary.\n\nblue: \\((1 + X_{1})^{2} + (2 - X_{2})^{2} &gt; 4\\)\nred: \\((1 + X_{1})^{2} + (2 - X_{2})^{2} &lt; 4\\)\n\n\n\n\n\n\n\n\n\n\n\nTo what class is the observation (0, 0) classified? (−1, 1)? (2, 2)? (3, 8)?\n\n\nifelse(euclidean_distance(0, 0, -1, 2) &gt; 4, \"blue\", \"red\")\n\n[1] \"red\"\n\nifelse(euclidean_distance(-1, 1, -1, 2) &gt; 4, \"blue\", \"red\")\n\n[1] \"red\"\n\nifelse(euclidean_distance(2, 2, -1, 2) &gt; 4, \"blue\", \"red\")\n\n[1] \"red\"\n\nifelse(euclidean_distance(3, 8, -1, 2) &gt; 4, \"blue\", \"red\")\n\n[1] \"blue\"\n\n\n\nWhile the decision boundary\n\n\\[(1 + X_{1})^{2} + (2 - X_{2})^{2} = 4\\]\nis not linear in \\(X_{1}\\) and \\(X_{2}\\), it is linear in terms of \\(X_{1}\\), \\(X_{1}^{2}\\), \\(X_{2}\\), \\(X_{2}^{2}\\)\n\\[\\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\beta_{3}X_{1}^{2} + \\beta_{4}X_{2}^{2} = 0\\]\nwith \\(\\beta_{0} = 1\\), \\(\\beta_{1} = 2\\), \\(\\beta_{2} = -4\\), \\(\\beta_{3} = 1\\), and \\(\\beta_{4} = 1\\)."
  },
  {
    "objectID": "posts/05_svm/05_svm.html#radial-kernels",
    "href": "posts/05_svm/05_svm.html#radial-kernels",
    "title": "5: Support Vector Machines",
    "section": "Radial Kernels",
    "text": "Radial Kernels\n\n\n\nAKA: Gaussians, image credit: Manin Bocss\n\n\n\nThere are other options besides polynomial kernel functions, and a popular one is a radial kernel.\n\n\\[K(x, x_{i}) = \\text{exp}\\left(-\\gamma\\sum_{j=1}^p(x_{ij} - x_{i'j})^2\\right), \\quad \\gamma &gt; 0\\]\n\nFor a given test observations \\(x^*\\), if it is far from \\(x_{i}\\), then \\(K(x^*, x_{i})\\) will be small given the negative \\(\\gamma\\) and large \\(\\sum_{j=1}^p(x^*_{j} - x_{ij})^2)\\).\nThus, \\(x_{i}\\) will play little role in \\(f(x^*)\\).\nThe predicted class for \\(x^*\\) is based on the sign of \\(f(x^*)\\), so training observations far from a given test point play little part in determining the label for a test observation.\nThe radial kernel therefore exhibits local behavior with respect to other observations."
  },
  {
    "objectID": "posts/05_svm/05_svm.html#svm-with-radial-kernels",
    "href": "posts/05_svm/05_svm.html#svm-with-radial-kernels",
    "title": "5: Support Vector Machines",
    "section": "SVM with Radial Kernels",
    "text": "SVM with Radial Kernels\n\n\n\nimage credit: Manin Bocss\n\n\n\nThe advantage of using a kernel rather than simply enlarging feature space is computational, since it is only necessary to compute \\(\\binom{n}{2}\\) kernel functions.\nFor radial kernels, the feature space is implicit and infinite dimensional, so we could not do the computations in such a space anyways."
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html",
    "href": "posts/06_decision_trees/06_decision_trees.html",
    "title": "6: Decision Trees",
    "section": "",
    "text": "Start to form decision trees\nPartition decision space\nExplore Shannon entropy\n\n\n\n\n\n\n\ndecision tree"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#learning-objectives",
    "href": "posts/06_decision_trees/06_decision_trees.html#learning-objectives",
    "title": "6: Decision Trees",
    "section": "",
    "text": "Start to form decision trees\nPartition decision space\nExplore Shannon entropy\n\n\n\n\n\n\n\ndecision tree"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#first-choice",
    "href": "posts/06_decision_trees/06_decision_trees.html#first-choice",
    "title": "6: Decision Trees",
    "section": "First Choice",
    "text": "First Choice"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#next-choice",
    "href": "posts/06_decision_trees/06_decision_trees.html#next-choice",
    "title": "6: Decision Trees",
    "section": "Next Choice",
    "text": "Next Choice"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#cutoff",
    "href": "posts/06_decision_trees/06_decision_trees.html#cutoff",
    "title": "6: Decision Trees",
    "section": "Cutoff",
    "text": "Cutoff\nIf we cutoff the tree-making process here, we have trained the tree model as follows"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#data-split",
    "href": "posts/06_decision_trees/06_decision_trees.html#data-split",
    "title": "6: Decision Trees",
    "section": "Data Split",
    "text": "Data Split"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#metrics",
    "href": "posts/06_decision_trees/06_decision_trees.html#metrics",
    "title": "6: Decision Trees",
    "section": "Metrics",
    "text": "Metrics\n\n\n\n\n           Truth\nPrediction  Adelie Chinstrap Gentoo\n  Adelie       109         2      0\n  Chinstrap      2        43      0\n  Gentoo         0         4     89\n\n\n\n\nTraining accuracy: 0.9679\n\n\n\n\nTesting accuracy: 0.881"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#categorical-prediction-1",
    "href": "posts/06_decision_trees/06_decision_trees.html#categorical-prediction-1",
    "title": "6: Decision Trees",
    "section": "Categorical Prediction",
    "text": "Categorical Prediction"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#first-choice-1",
    "href": "posts/06_decision_trees/06_decision_trees.html#first-choice-1",
    "title": "6: Decision Trees",
    "section": "First Choice",
    "text": "First Choice"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#next-choice-1",
    "href": "posts/06_decision_trees/06_decision_trees.html#next-choice-1",
    "title": "6: Decision Trees",
    "section": "Next Choice",
    "text": "Next Choice"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#metrics-1",
    "href": "posts/06_decision_trees/06_decision_trees.html#metrics-1",
    "title": "6: Decision Trees",
    "section": "Metrics",
    "text": "Metrics\n\n\n\n\n           Truth\nPrediction  Adelie Chinstrap Gentoo\n  Adelie       107        49      0\n  Chinstrap      0         0      0\n  Gentoo         4         0     89\n\n\n\n\nTraining accuracy: 0.7871\n\n\n\n\nTesting accuracy: 0.75"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#entropy",
    "href": "posts/06_decision_trees/06_decision_trees.html#entropy",
    "title": "6: Decision Trees",
    "section": "Entropy",
    "text": "Entropy\nFrom information theory, we borrow the notion of Shannon entropy to get a sense of how well a choice can separate classes in the data.\n\\[E = -\\sum_{i=1}^{J} p_{i} \\log_{2} p_{i}\\]\n\n\\(J\\) groups in the categorical response variable\n\\(p_{i}\\): probability of being in group \\(i\\)\nlogarithm base does not matter (since we will simply be seeking a maximum)"
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#categorical-predictors",
    "href": "posts/06_decision_trees/06_decision_trees.html#categorical-predictors",
    "title": "6: Decision Trees",
    "section": "Categorical Predictors",
    "text": "Categorical Predictors\n\nIslandSexChoice\n\n\nIn the penguins data, we have a distribution in the island variable.\n\n\n\n   Biscoe     Dream Torgersen \n      163       123        47 \n\n\nAmong \\(n = 333\\) penguins in total, the entropy for this choice is\n\\[E = -\\left(\\frac{163}{333}\\right)\\log_{2} \\left(\\frac{163}{333}\\right) - \\left(\\frac{123}{333}\\right)\\log_{2} \\left(\\frac{123}{333}\\right) - \\left(\\frac{47}{333}\\right)\\log_{2} \\left(\\frac{47}{333}\\right)\\]\n\n\n[1] \"The entropy for this variable is: 1.4339\"\n\n\n\n\nIn the penguins data, we have a distribution in the sex variable.\n\n\n\nfemale   male \n   165    168 \n\n\nAmong \\(n = 333\\) penguins in total, the entropy for this choice is\n\\[E = -\\left(\\frac{165}{333}\\right)\\log_{2} \\left(\\frac{165}{333}\\right) - \\left(\\frac{168}{333}\\right)\\log_{2} \\left(\\frac{168}{333}\\right)\\]\n\n\n[1] \"The entropy for this variable is: 0.9999\"\n\n\n\n\nBetween these categorical variables, island presents more information entropy than sex, so island could be used before sex for the entire data set (i.e. the entropy comparison could change later under a smaller subset of data)."
  },
  {
    "objectID": "posts/06_decision_trees/06_decision_trees.html#numerical-predictors",
    "href": "posts/06_decision_trees/06_decision_trees.html#numerical-predictors",
    "title": "6: Decision Trees",
    "section": "Numerical Predictors",
    "text": "Numerical Predictors\n\nformulabill depthbill lengthbody massflipper length\n\n\nWe need to update our formula for Shannon entropy for a numerical variable. Here, I suggest computing the probabilities across a discretization of the numerical variable.\n\\[\\begin{array}{rcl}\n  E & = & -\\displaystyle\\text{max}_{z} \\sum_{i=1}^{J} P(X_{i} \\leq z)\\log_{2}P(X_{i} \\leq z) \\\\\n  ~ & ~ & - \\sum_{i=1}^{J} P(X_{i} &gt; z)\\log_{2}P(X_{i} &gt; z)\n\\end{array}\\]\n\\[z \\in \\mathbb{N}, \\quad \\text{min}(X) &lt; z &lt; \\text{max}(Z)\\]\nTo avoid taking logarithms of zero probabilities, we can apply a Laplace adjustment\n\\[P(X_{i} &lt; z) = \\frac{(\\text{count}_{i} &lt; z) + 1}{\\text{total count} + 1}\\]\n\n\n\n\n\n\nmax entropy: -1.53757237950003\n\n\nthreshold: 16\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmax entropy: -1.56651763573707\n\n\nthreshold: 42\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmax entropy: -1.54388648974619\n\n\nthreshold: 4800\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmax entropy: -1.36723424446796\n\n\nthreshold: 207"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html",
    "href": "posts/07_random_forests/07_random_forests.html",
    "title": "7: Random Forests",
    "section": "",
    "text": "Deploy many decision trees\nExplore ensemble learning:\n\nbagging\nboosting"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#learning-objectives",
    "href": "posts/07_random_forests/07_random_forests.html#learning-objectives",
    "title": "7: Random Forests",
    "section": "",
    "text": "Deploy many decision trees\nExplore ensemble learning:\n\nbagging\nboosting"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#bootstrapping",
    "href": "posts/07_random_forests/07_random_forests.html#bootstrapping",
    "title": "7: Random Forests",
    "section": "Bootstrapping",
    "text": "Bootstrapping\nBootstrapping is performed by resampling with replacement on the data.\n\n\n\n\n# A tibble: 10 × 9\n     pid species island    bill_length_mm bill_depth_mm flipper_length_mm\n   &lt;int&gt; &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n 1     1 Adelie  Torgersen           39.1          18.7               181\n 2     2 Adelie  Torgersen           39.5          17.4               186\n 3     3 Adelie  Torgersen           40.3          18                 195\n 4     4 Adelie  Torgersen           NA            NA                  NA\n 5     5 Adelie  Torgersen           36.7          19.3               193\n 6     6 Adelie  Torgersen           39.3          20.6               190\n 7     7 Adelie  Torgersen           38.9          17.8               181\n 8     8 Adelie  Torgersen           39.2          19.6               195\n 9     9 Adelie  Torgersen           34.1          18.1               193\n10    10 Adelie  Torgersen           42            20.2               190\n# ℹ 3 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\n\n\n# A tibble: 10 × 9\n     pid species   island    bill_length_mm bill_depth_mm flipper_length_mm\n   &lt;int&gt; &lt;fct&gt;     &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;\n 1   220 Gentoo    Biscoe              49.5          16.2               229\n 2   141 Adelie    Dream               40.2          17.1               193\n 3   261 Gentoo    Biscoe              43.3          14                 208\n 4   313 Chinstrap Dream               47.6          18.3               195\n 5   261 Gentoo    Biscoe              43.3          14                 208\n 6    47 Adelie    Dream               41.1          19                 182\n 7   282 Chinstrap Dream               45.2          17.8               198\n 8   308 Chinstrap Dream               54.2          20.8               201\n 9     9 Adelie    Torgersen           34.1          18.1               193\n10   127 Adelie    Torgersen           38.8          17.6               191\n# ℹ 3 more variables: body_mass_g &lt;int&gt;, sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\n\nBagging is using the notion of bootstrapping to aggregate the data."
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#bags",
    "href": "posts/07_random_forests/07_random_forests.html#bags",
    "title": "7: Random Forests",
    "section": "Bags",
    "text": "Bags"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#in-bag",
    "href": "posts/07_random_forests/07_random_forests.html#in-bag",
    "title": "7: Random Forests",
    "section": "In-Bag",
    "text": "In-Bag\n\n\n  [1]   3   5   7   9  10  11  12  13  14  15  16  22  23  25  26  28  30  32\n [19]  38  41  42  43  47  48  49  51  52  54  55  58  60  63  65  66  68  69\n [37]  70  72  73  75  77  79  80  81  83  84  85  86  87  88  91  94  95  97\n [55]  98  99 100 101 102 104 105 106 107 108 109 111 112 113 116 117 118 119\n [73] 121 122 125 127 128 129 130 131 132 133 134 138 139 140 141 142 143 146\n [91] 150 152 153 155 156 157 158 159 162 167 168 169 170 173 174 175 177 179\n[109] 181 182 183 184 185 186 187 189 192 193 196 199 200 201 202 203 204 206\n[127] 207 208 209 210 211 212 213 215 216 217 219 220 221 223 225 226 227 228\n[145] 229 231 233 235 236 237 238 239 240 241 242 243 244 246 247 250 251 252\n[163] 253 254 255 258 259 260 261 262 263 265 267 269 270 271 272 273 274 275\n[181] 277 278 282 283 284 285 286 287 288 289 292 294 295 296 297 298 300 301\n[199] 302 303 305 306 307 308 309 310 311 313 314 317 318 319 320 323 324 326\n[217] 327 328 329 330 331 332 333 334 335 337 338 339 340 343 344"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#out-of-bag",
    "href": "posts/07_random_forests/07_random_forests.html#out-of-bag",
    "title": "7: Random Forests",
    "section": "Out-of-Bag",
    "text": "Out-of-Bag\n\n\n  [1]   1   2   4   6   8  17  18  19  20  21  24  27  29  31  33  34  35  36\n [19]  37  39  40  44  45  46  50  53  56  57  59  61  62  64  67  71  74  76\n [37]  78  82  89  90  92  93  96 103 110 114 115 120 123 124 126 135 136 137\n [55] 144 145 147 148 149 151 154 160 161 163 164 165 166 171 172 176 178 180\n [73] 188 190 191 194 195 197 198 205 214 218 222 224 230 232 234 245 248 249\n [91] 256 257 264 266 268 276 279 280 281 290 291 293 299 304 312 315 316 321\n[109] 322 325 336 341 342"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#classfication-tasks",
    "href": "posts/07_random_forests/07_random_forests.html#classfication-tasks",
    "title": "7: Random Forests",
    "section": "Classfication Tasks",
    "text": "Classfication Tasks\nFor classification tasks, after making a random forest (say, 1000 trees), class labels are assigned by the majority of predictions.\n\n\n\n\n\n\nVariable Importance\n\n\n\n\n\nSince we have created many trees—each choice order determined by entropy—we can create a list of variable importance by reporting which explanatory variables appeared in a higher proportion of trees. This could aid in variable selection and interpretability."
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#adaboost",
    "href": "posts/07_random_forests/07_random_forests.html#adaboost",
    "title": "7: Random Forests",
    "section": "Adaboost",
    "text": "Adaboost\n\nA Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting (1997—published as abstract in 1995), Freund and Schapire"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#alexnet",
    "href": "posts/07_random_forests/07_random_forests.html#alexnet",
    "title": "7: Random Forests",
    "section": "AlexNet",
    "text": "AlexNet\n\nImageNet Classification with Deep Convolutional Neural Networks (2012)"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#dropout",
    "href": "posts/07_random_forests/07_random_forests.html#dropout",
    "title": "7: Random Forests",
    "section": "DropOut",
    "text": "DropOut\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting (2014), Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#gans",
    "href": "posts/07_random_forests/07_random_forests.html#gans",
    "title": "7: Random Forests",
    "section": "GANs",
    "text": "GANs\n\nGeneral Adversarial Nets (2014), Goodfellow et al."
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#tensorflow",
    "href": "posts/07_random_forests/07_random_forests.html#tensorflow",
    "title": "7: Random Forests",
    "section": "TensorFlow",
    "text": "TensorFlow\n\nTensorFlow: A system for large-scale machine learning (2016), Abadi et al."
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#word2vec",
    "href": "posts/07_random_forests/07_random_forests.html#word2vec",
    "title": "7: Random Forests",
    "section": "Word2Vec",
    "text": "Word2Vec\n\nEfficient Estimation of Word Representations in Vector Space (2013), Mikolov, Chen, Corrado, and Dean"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#stratified-samples",
    "href": "posts/07_random_forests/07_random_forests.html#stratified-samples",
    "title": "7: Random Forests",
    "section": "Stratified Samples",
    "text": "Stratified Samples\n\nFor stratified sampling, subsets maintain proportions of categorical data.\n\nFor example, 88 percent of people are right-handed. We assume population proportions\n\\[p = 0.88, \\quad 1 - p = 0.12\\]\nIf we employ a training-testing split, each should also have approximately 12 percent representation for left-handed people."
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#rescaling",
    "href": "posts/07_random_forests/07_random_forests.html#rescaling",
    "title": "7: Random Forests",
    "section": "Rescaling",
    "text": "Rescaling\n\nIf a sample data set exhibits different proportions, we can perform inverse probability weighting to try to correct for bias in the sample.\n\nFor example, if our tree model predicts 70 percent right-handed people, then we can apply some weights\n\non right-handed: weight = \\(\\frac{0.88}{0.70} \\approx 1.2571\\)\non left-handed: weight = \\(\\frac{0.12}{0.30} = 0.4\\)"
  },
  {
    "objectID": "posts/07_random_forests/07_random_forests.html#boosting-1",
    "href": "posts/07_random_forests/07_random_forests.html#boosting-1",
    "title": "7: Random Forests",
    "section": "Boosting",
    "text": "Boosting\nFor tree models, boosting resamples underrepresented data and applies larger weights to aim toward stratified sampling."
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html",
    "title": "8: Dimension Reduction",
    "section": "",
    "text": "Explore PCA and LDA"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#learning-objectives",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#learning-objectives",
    "title": "8: Dimension Reduction",
    "section": "",
    "text": "Explore PCA and LDA"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#correlation",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#correlation",
    "title": "8: Dimension Reduction",
    "section": "Correlation",
    "text": "Correlation"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#finding-vectors",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#finding-vectors",
    "title": "8: Dimension Reduction",
    "section": "Finding Vectors",
    "text": "Finding Vectors\n\nPCA Vectors\n\n\nStandard deviations (1, .., p=2):\n[1] 1.2860884 0.5881978\n\nRotation (n x k) = (2 x 2):\n                     PC1        PC2\nbill_length_mm 0.7071068  0.7071068\nbill_depth_mm  0.7071068 -0.7071068\n\n\n\n\nCenter\n\n\nbill_length_mm  bill_depth_mm \n      47.56807       14.99664 \n\n\n\n\nScale\n\n\nbill_length_mm  bill_depth_mm \n      3.106116       0.985998"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#new-basis",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#new-basis",
    "title": "8: Dimension Reduction",
    "section": "New Basis",
    "text": "New Basis"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-pairs-plot",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-pairs-plot",
    "title": "8: Dimension Reduction",
    "section": "PCA Pairs Plot",
    "text": "PCA Pairs Plot\n\npsych::pairs.panels(gentoo_pca$x)"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-bi-plot",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-bi-plot",
    "title": "8: Dimension Reduction",
    "section": "PCA Bi Plot",
    "text": "PCA Bi Plot\n\nggbiplot::ggbiplot(gentoo_pca,\n                   obs.scale = 1,\n                   var.scale = 1,\n                   varname.color = \"blue\") +\n  labs(title = \"First two principal components\",\n       subtitle = \"correlation: r = 0\",\n       caption = \"SML 301\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#correlations",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#correlations",
    "title": "8: Dimension Reduction",
    "section": "Correlations",
    "text": "Correlations"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#finding-vectors-1",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#finding-vectors-1",
    "title": "8: Dimension Reduction",
    "section": "Finding Vectors",
    "text": "Finding Vectors\n\nPCA Vectors\n\n\nStandard deviations (1, .., p=4):\n[1] 1.6556628 0.8832220 0.6030061 0.3392388\n\nRotation (n x k) = (4 x 4):\n                         PC1        PC2        PC3        PC4\nbill_depth_mm     -0.4025427 0.78620098 -0.4409902  0.1592956\nbill_length_mm     0.4522035 0.61548815  0.6214553 -0.1745843\nflipper_length_mm  0.5766988 0.01567957 -0.2136934  0.7883577\nbody_mass_g        0.5485343 0.05307086 -0.6112742 -0.5680118\n\n\n\n\nCenter\n\n\n    bill_depth_mm    bill_length_mm flipper_length_mm       body_mass_g \n         17.12048          43.93775         201.41365        4219.67871 \n\n\n\n\nScale\n\n\n    bill_depth_mm    bill_length_mm flipper_length_mm       body_mass_g \n         2.046068          5.369742         13.843945        797.965089"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-pairs-plot-1",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-pairs-plot-1",
    "title": "8: Dimension Reduction",
    "section": "PCA Pairs Plot",
    "text": "PCA Pairs Plot\n\npsych::pairs.panels(penguin_pca$x)"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-bi-plot-1",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-bi-plot-1",
    "title": "8: Dimension Reduction",
    "section": "PCA Bi Plot",
    "text": "PCA Bi Plot\n\nggbiplot::ggbiplot(penguin_pca,\n                   ellipse = TRUE, ellipse.prob = 0.95,\n                   groups = train_data$species,\n                   obs.scale = 1,\n                   var.scale = 1,\n                   varname.color = \"blue\") +\n  labs(title = \"First two principal components\",\n       subtitle = \"captures 87.4 percent of the variance\",\n       caption = \"SML 301\") +\n  theme_minimal()"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#regression-task",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#regression-task",
    "title": "8: Dimension Reduction",
    "section": "Regression Task",
    "text": "Regression Task\n\nresponse variable: body_mass_g\nexplanatory variables: bill_depth_mm, bill_length_mm, flipper_length_mm\n\n\n\n[1] \"MSE: 130265.339625507\""
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#dimensionality-reduction",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#dimensionality-reduction",
    "title": "8: Dimension Reduction",
    "section": "Dimensionality Reduction",
    "text": "Dimensionality Reduction"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-model",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#pca-model",
    "title": "8: Dimension Reduction",
    "section": "PCA Model",
    "text": "PCA Model\n\\[\\hat{y} = \\beta_{0} + \\beta_{1}P_{1} + \\beta_{2}P_{2}\\]\n\n\\(P_{1}\\): principal component 1\n\\(P_{2}\\): principal component 2\n\n\n\n\n\n\n\n\n\n\n\n\n[1] \"MSE: 212638.288324684\""
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#adaboost",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#adaboost",
    "title": "8: Dimension Reduction",
    "section": "Adaboost",
    "text": "Adaboost\n\nA Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting (1997—published as abstract in 1995), Freund and Schapire"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#alexnet",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#alexnet",
    "title": "8: Dimension Reduction",
    "section": "AlexNet",
    "text": "AlexNet\n\nImageNet Classification with Deep Convolutional Neural Networks (2012)"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#dropout",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#dropout",
    "title": "8: Dimension Reduction",
    "section": "DropOut",
    "text": "DropOut\n\nDropout: A Simple Way to Prevent Neural Networks from Overfitting (2014), Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#gans",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#gans",
    "title": "8: Dimension Reduction",
    "section": "GANs",
    "text": "GANs\n\nGeneral Adversarial Nets (2014), Goodfellow et al."
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#tensorflow",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#tensorflow",
    "title": "8: Dimension Reduction",
    "section": "TensorFlow",
    "text": "TensorFlow\n\nTensorFlow: A system for large-scale machine learning (2016), Abadi et al."
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#word2vec",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#word2vec",
    "title": "8: Dimension Reduction",
    "section": "Word2Vec",
    "text": "Word2Vec\n\nEfficient Estimation of Word Representations in Vector Space (2013), Mikolov, Chen, Corrado, and Dean"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#task",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#task",
    "title": "8: Dimension Reduction",
    "section": "Task",
    "text": "Task"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#classifier",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#classifier",
    "title": "8: Dimension Reduction",
    "section": "Classifier",
    "text": "Classifier\n\n\n\n\n\n\n\n\n\n\nPC1 captures variance of the entire data set"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#along-pc1",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#along-pc1",
    "title": "8: Dimension Reduction",
    "section": "Along PC1",
    "text": "Along PC1"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#covariance-revisited",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#covariance-revisited",
    "title": "8: Dimension Reduction",
    "section": "Covariance Revisited",
    "text": "Covariance Revisited\n\nNaive Bayes ignored covariance (assumed conditional independence)\ndiscriminant analyses (generative approach): fit multivariate Gaussians\nwant: dimensionality reduction\n\nFisher’s linear discriminant analysis (FLDA) is a hybrid of discriminative and generative techniques, but limited to\n\\[K \\leq C - 1 \\text{ dimensions}\\]\n\n\\(C\\): number of classes in response variable\n\\(D\\): number of dimensions in projected space"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#flda-ideas",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#flda-ideas",
    "title": "8: Dimension Reduction",
    "section": "FLDA Ideas",
    "text": "FLDA Ideas\n\n\\(S_{B}, S_{W}\\): scatter matrices (estimate covariance)\n\\(W\\): projection matrix from \\(D\\) to \\(K\\) dimensions\n\nObjective: maximize\n\\[J(W) = \\displaystyle\\frac{|W^{T}S_{B}W|}{|W^{T}S_{W}W|}\\]\n\neigenvalue scenario instead of gradient descent"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#projection",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#projection",
    "title": "8: Dimension Reduction",
    "section": "Projection",
    "text": "Projection"
  },
  {
    "objectID": "posts/08_dimension_reduction/08_dimension_reduction.html#comparison",
    "href": "posts/08_dimension_reduction/08_dimension_reduction.html#comparison",
    "title": "8: Dimension Reduction",
    "section": "Comparison",
    "text": "Comparison"
  },
  {
    "objectID": "posts/09_learning_rates/09_learning_rates.html",
    "href": "posts/09_learning_rates/09_learning_rates.html",
    "title": "9: Learning Rates",
    "section": "",
    "text": "Preview terminology for studies of artificial intelligence methods\n\nforward propagation\nback propagation\nlearning rates\nbatch sizes\n\n\n\n\n\n\n\nTanks!\n\n\n\nimage source: Wikipedia"
  },
  {
    "objectID": "posts/09_learning_rates/09_learning_rates.html#learning-objectives",
    "href": "posts/09_learning_rates/09_learning_rates.html#learning-objectives",
    "title": "9: Learning Rates",
    "section": "",
    "text": "Preview terminology for studies of artificial intelligence methods\n\nforward propagation\nback propagation\nlearning rates\nbatch sizes\n\n\n\n\n\n\n\nTanks!\n\n\n\nimage source: Wikipedia"
  },
  {
    "objectID": "posts/09_learning_rates/09_learning_rates.html#matrix-equation",
    "href": "posts/09_learning_rates/09_learning_rates.html#matrix-equation",
    "title": "9: Learning Rates",
    "section": "Matrix Equation",
    "text": "Matrix Equation\nIf we have \\(S = \\left[\\begin{array}{c} y(t) \\\\ v(t) \\end{array}\\right]\\), and\n\\[\\frac{dy}{dt} = v, \\quad \\frac{dv}{dt} = -g\\]\nthen\n\\[\\frac{dS}{dt} = \\left[\\begin{array}{rr} 0 & 1 \\\\ 0 & -\\frac{g}{v}\\end{array}\\right]S\\]"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html",
    "href": "posts/13_FCN/13_FCN.html",
    "title": "13: Fully Connected Networks",
    "section": "",
    "text": "Explore elementary calculations in neural networks\nIntroduce PyTorch code\n\n\n\n\n\n\n\nfully-connected network"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#learning-objectives",
    "href": "posts/13_FCN/13_FCN.html#learning-objectives",
    "title": "13: Fully Connected Networks",
    "section": "",
    "text": "Explore elementary calculations in neural networks\nIntroduce PyTorch code\n\n\n\n\n\n\n\nfully-connected network"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#motivation",
    "href": "posts/13_FCN/13_FCN.html#motivation",
    "title": "13: Fully Connected Networks",
    "section": "motivation",
    "text": "motivation\nFor 32-bit float number representation\n\n\n\nfloating-point representation\n\n\n\nrange: \\((1.1755 \\times 10^{-38}, 1.7014 \\times 10^{38})\\)\n\nAnticipating neural networks and performing many calculations, we want to avoid overflow or underflow errors.\n\n\n\n\n\n\nPreprocessing Numbers\n\n\n\nTo make the numerical inputs and outputs more manageable, we will employ\n\nmin-max normalization\nsoftmax\n\n\n\n\nsceneformularescaledbases\n\n\n\n\n\n\n\n\n\n\n\n\n\nWe want numerical inputs to be between 0 and 1, so we can employ min-max normalization:\n\\[\\text{scaled}(x) = \\frac{x - \\text{min}}{\\text{max} - \\text{min}}\\]"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#trained-model",
    "href": "posts/13_FCN/13_FCN.html#trained-model",
    "title": "13: Fully Connected Networks",
    "section": "Trained Model",
    "text": "Trained Model\n\n\n\n\n\n\n\nflowchart LR\n\ninput_1[flipper length]\ninput_2[body mass]\noutput_1[Adelie]\noutput_2[Chinstrap]\noutput_3[Gentoo]\n\ninput_1 -- -1.16A + 0.38 --&gt; output_1\ninput_1 -- 0.24A - 0.38 --&gt; output_2\ninput_1 -- 1.77A + 0.16 --&gt; output_3\ninput_2 -- -0.05B + 0.38 --&gt; output_1\ninput_2 -- 0.18B - 0.38 --&gt; output_2\ninput_2 -- 1.07B + 0.16 --&gt; output_3\n\n\n\n\n\n\n\n\n\n\ninput layer size: 2\noutput layer size: 3\nfully-connected network: every output is connected to every input by an edge\n\nhere: no hidden layer\nlater: LSTM, transformers, encoder-decorders\n\n\n\n\n\n\n\n\n\n\nWhere did the coefficients come from?\n\n\n\nWe will train the neural network and compute the weights and bias values soon! For now, let us see how the forward calculations work in this trained model.\n\n\n\n\n\n\n\n\nThese will be poor results\n\n\n\n\n\nThe examples in today’s session will have poor results (i.e. accuracy values close to 50 percent). This is because of\n\nsmall data sets\nmodels run for a limited number of epochs (iterations)"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#parameters",
    "href": "posts/13_FCN/13_FCN.html#parameters",
    "title": "13: Fully Connected Networks",
    "section": "Parameters",
    "text": "Parameters\n\n\n\n\n\n\n\nflowchart LR\n\ninput_1[flipper length]\ninput_2[body mass]\noutput_1[Adelie]\noutput_2[Chinstrap]\noutput_3[Gentoo]\n\ninput_1 -- -1.16A + 0.38 --&gt; output_1\ninput_1 -- 0.24A - 0.38 --&gt; output_2\ninput_1 -- 1.77A + 0.16 --&gt; output_3\ninput_2 -- -0.05B + 0.38 --&gt; output_1\ninput_2 -- 0.18B - 0.38 --&gt; output_2\ninput_2 -- 1.07B + 0.16 --&gt; output_3\n\n\n\n\n\n\n\n\n\nThis model has 9 parameters:\n\nweights\n\n\\[\\begin{array}{rcr}\n  w_{1,1} & \\approx & -1.16 \\\\\n  w_{1,2} & \\approx & 0.24 \\\\\n  w_{1,3} & \\approx & 1.77 \\\\\n  w_{2,1} & \\approx & -0.05 \\\\\n  w_{2,2} & \\approx & 0.18 \\\\\n  w_{2,3} & \\approx & 1.07 \\\\\n\\end{array}\\]\n\nbias\n\n\\[\\begin{array}{rcr}\n  b_{1} & \\approx & 0.76 \\\\\n  b_{2} & \\approx & -0.76 \\\\\n  b_{3} & \\approx & 0.32 \\\\\n\\end{array}\\]\n\n\n\n\n\n\n\n\nSplit Bias?\n\n\n\nEditor’s note: for the sake of simplifying the diagram, the bias values were split in half (two input variables). In practice, the bias values are added after the weight multiplications. This will be more apparent in the matrix computations later. Furthermore, the values going into the output nodes are also added together."
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#obvious-example",
    "href": "posts/13_FCN/13_FCN.html#obvious-example",
    "title": "13: Fully Connected Networks",
    "section": "Obvious Example",
    "text": "Obvious Example\nWhat will our model predict for a Gentoo penguin whose measurements (after min-max normalization) include a flipper length of 0.75 and a body mass of 0.75?\n\n\n\n\n\n\n\nflowchart LR\n\ninput_1[0.75]\ninput_2[0.75]\noutput_1[-0.1475]\noutput_2[-0.4450]\noutput_3[2.4500]\n\ninput_1 -- -1.16*0.75 + 0.38 --&gt; output_1\ninput_1 -- 0.24*0.75 - 0.38 --&gt; output_2\ninput_1 -- 1.77*0.75 + 0.16 --&gt; output_3\ninput_2 -- -0.05*0.75 + 0.38 --&gt; output_1\ninput_2 -- 0.18*0.75 - 0.38 --&gt; output_2\ninput_2 -- 1.07*0.75 + 0.16 --&gt; output_3\n\n\n\n\n\n\n\n\n\nSince the output value is the largest for the Gentoo label, we predict that such a penguin is of the Gentoo species."
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#tough-classification",
    "href": "posts/13_FCN/13_FCN.html#tough-classification",
    "title": "13: Fully Connected Networks",
    "section": "Tough Classification",
    "text": "Tough Classification\nWhat will our model predict for a penguin whose measurements (after min-max normalization) include a flipper length of 0.301 and a body mass of 0.301?\n\n\n\n\n\n\n\nflowchart LR\n\ninput_1[0.301]\ninput_2[0.301]\noutput_1[0.37579]\noutput_2[-0.63358]\noutput_3[1.17484]\n\ninput_1 -- -1.16*0.301 + 0.38 --&gt; output_1\ninput_1 -- 0.24*0.301 - 0.38 --&gt; output_2\ninput_1 -- 1.77*0.301 + 0.16 --&gt; output_3\ninput_2 -- -0.05*0.301 + 0.38 --&gt; output_1\ninput_2 -- 0.18*0.301 - 0.38 --&gt; output_2\ninput_2 -- 1.07*0.301 + 0.16 --&gt; output_3\n\n\n\n\n\n\n\n\n\nSince the output value is the largest for the Gentoo label, we predict that such a penguin is of the Gentoo species.\nHowever, the output values should have favored the Adelie and Chinstrap penguins here."
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#obvious-example-1",
    "href": "posts/13_FCN/13_FCN.html#obvious-example-1",
    "title": "13: Fully Connected Networks",
    "section": "Obvious Example",
    "text": "Obvious Example\nWhat will our model predict for a penguin whose measurements (after min-max normalization) include a flipper length of 0.75 and a body mass of 0.75?\n\n\n\n\n\n\n\nflowchart LR\n\ninput_1[0.75]\ninput_2[0.75]\noutput_1[-0.1475]\noutput_2[-0.4450]\noutput_3[2.4500]\n\ninput_1 -- -1.16*0.75 + 0.38 --&gt; output_1\ninput_1 -- 0.24*0.75 - 0.38 --&gt; output_2\ninput_1 -- 1.77*0.75 + 0.16 --&gt; output_3\ninput_2 -- -0.05*0.75 + 0.38 --&gt; output_1\ninput_2 -- 0.18*0.75 - 0.38 --&gt; output_2\ninput_2 -- 1.07*0.75 + 0.16 --&gt; output_3\n\n\n\n\n\n\n\n\n\n\\(\\frac{e^{-0.1475}}{e^{-0.1475} + e^{-0.4450} + e^{2.4500}} \\approx 0.0659\\) \\(\\frac{e^{-0.4450}}{e^{-0.1475} + e^{-0.4450} + e^{2.4500}} \\approx 0.0489\\) \\(\\frac{e^{2.4500}}{e^{-0.1475} + e^{-0.4450} + e^{2.4500}} \\approx 0.8851\\)"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#tough-classification-1",
    "href": "posts/13_FCN/13_FCN.html#tough-classification-1",
    "title": "13: Fully Connected Networks",
    "section": "Tough Classification",
    "text": "Tough Classification\nWhat will our model predict for a penguin whose measurements (after min-max normalization) include a flipper length of 0.301 and a body mass of 0.301?\n\n\n\n\n\n\n\nflowchart LR\n\ninput_1[0.301]\ninput_2[0.301]\noutput_1[0.37579]\noutput_2[-0.63358]\noutput_3[1.17484]\n\ninput_1 -- -1.16*0.301 + 0.38 --&gt; output_1\ninput_1 -- 0.24*0.301 - 0.38 --&gt; output_2\ninput_1 -- 1.77*0.301 + 0.16 --&gt; output_3\ninput_2 -- -0.05*0.301 + 0.38 --&gt; output_1\ninput_2 -- 0.18*0.301 - 0.38 --&gt; output_2\ninput_2 -- 1.07*0.301 + 0.16 --&gt; output_3\n\n\n\n\n\n\n\n\n\n\\[\\begin{array}{c|c|c}\n  \\text{signal} & \\text{exponent} & \\text{softmax} \\\\\n  \\hline\n  0.3758 & e^{0.3758} & 0.2787 \\\\\n  -0.6336 & e^{-0.6336} & 0.1016 \\\\\n  1.1748 & e^{1.1748} & 0.6197 \\\\\n\\end{array}\\]\n\n\n\n\n\n\n\n\nDoes the softmax output create a probability distribution?\n\n\n\n\n\nIt’s debatable.\nWhile the values from a softmax computation are positive sum up to one (up to a rounding error), it is debatable whether or not the softmax result is a probability distribution.\n\nNodes earlier in the network (especially in neural networks) can be permuted. While we might end up with the same distribution, the underlying weights might be quite different.\nWhat do these proportions represent? Later, if we use this softmax output as inputs for another module, then we can say something like “The output signal is about 28 percent Adelie, 10 percent Chinstrap, and 62 percent Gentoo.”\nAre these proportions unbiased estimators of population proportions?"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#derivative",
    "href": "posts/13_FCN/13_FCN.html#derivative",
    "title": "13: Fully Connected Networks",
    "section": "Derivative",
    "text": "Derivative\n\n\nSoftmax function \\[\\sigma({\\vec{x}})_{i} = \\frac{e^{x_{i}}}{\\sum_{i=1}^{n}e^{x_{i}}}\\]\n\n\n\nDerivative \\[\\frac{\\partial \\sigma_{k}}{\\partial x_{i}} = \\sigma_{k}(\\delta_{ik} - \\sigma_{i})\\] where \\[\\delta_{ik} = \\begin{cases} 1, & i = k \\\\ 0, & i \\neq k \\\\ \\end{cases}\\]"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#initialization",
    "href": "posts/13_FCN/13_FCN.html#initialization",
    "title": "13: Fully Connected Networks",
    "section": "Initialization",
    "text": "Initialization\nConsider a fully-connected network (FCN) where all of the weights have been initialized to the same uniform value of 0.2 and each bias has been initialized to be zero. What will our model predict for a Gentoo penguin whose measurements (after min-max normalization) include a flipper length of 0.75 and a body mass of 0.75?\n\n\n\n\n\n\n\nflowchart LR\n\ninput_1[0.75]\ninput_2[0.75]\noutput_1[0.3]\noutput_2[0.3]\noutput_3[0.3]\n\ninput_1 -- 0.2*0.75 + 0 --&gt; output_1\ninput_1 -- 0.2*0.75 + 0 --&gt; output_2\ninput_1 -- 0.2*0.75 + 0 --&gt; output_3\ninput_2 -- 0.2*0.75 + 0 --&gt; output_1\ninput_2 -- 0.2*0.75 + 0 --&gt; output_2\ninput_2 -- 0.2*0.75 + 0 --&gt; output_3\n\n\n\n\n\n\n\n\n\n\\[\\begin{array}{c|c|c}\n  \\text{predicted} & \\text{observed} & \\text{residual} \\\\\n  \\hline\n  0.3333 & 0 & 0.3333 \\\\\n  0.3333 & 0 & 0.3333 \\\\\n  0.3333 & 1 & -0.6667 \\\\\n\\end{array}\\]\nNote: this initialization assumes that each penguin species is equally likely."
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#partial-derivatives",
    "href": "posts/13_FCN/13_FCN.html#partial-derivatives",
    "title": "13: Fully Connected Networks",
    "section": "Partial Derivatives",
    "text": "Partial Derivatives\nHere, we will update weight \\(w_{2,3} = 0.2\\). The composition of the linear transformation, softmax, and SSR loss yields the following partial derivatives:\n\nlinear transformation:\n\n\\[\\frac{\\partial L}{\\partial w_{2,3}} = x_{2}\\]\n\nsoftmax:\n\n\\[\\frac{\\partial \\sigma_{3}}{\\partial L_{3}} = (\\sigma_{3})(1 - \\sigma_{3})\\]\n\nloss:\n\n\\[\\frac{\\partial\\text{SSR}}{\\partial{\\sigma_{3}}} = -2(\\text{observed}_{3} - \\text{predicted}_{3})\\]"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#chain-rule",
    "href": "posts/13_FCN/13_FCN.html#chain-rule",
    "title": "13: Fully Connected Networks",
    "section": "Chain Rule",
    "text": "Chain Rule\nPutting it all together, we can now compute the overall derviative through the chain rule:\n\\[\\begin{array}{rcl}\n\\frac{\\partial\\text{SSR}}{\\partial w_{2,3}} & = & \\frac{\\partial\\text{SSR}}{\\partial{\\sigma_{3}}} \\cdot \\frac{\\partial \\sigma_{3}}{\\partial L_{3}} \\cdot \\frac{\\partial L}{\\partial w_{2,3}} \\\\\n~ & = & -2(\\text{observed}_{3} - \\text{predicted}_{3}) \\cdot (\\sigma_{3})(1 - \\sigma_{3}) \\cdot x_{2} \\\\\n~ & = & -2(1 - 0.3333) \\cdot (0.3)(1 - 0.3) \\cdot (0.75) \\\\\n~ & \\approx & -0.2100 \\\\\n\\end{array}\\]\n\n\n\n\n\n\nWhy do we use the softmax?\n\n\n\n\n\nOne question that may appear here is, “Why do we use min-max normalization for the input layer but then use a softmax for the output layer?”\n\nmin-max normalization\n\npro: easier to calculate (more easily vectorized)\ncon: the derivative is simply just the number one (same if we used an argmax), so applying this normalization does not create information for us for back propogation\n\nsoftmax\n\npro: derivative values between 0 and 1\ncon: more intense calculation (especially for long vectors)\n\n\n\n\n\n\n\n\n\n\n\nWhy don’t we use the SSR?\n\n\n\n\n\nThe derivative values from the SSR are relatively small, and hence the learning is slow."
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#update",
    "href": "posts/13_FCN/13_FCN.html#update",
    "title": "13: Fully Connected Networks",
    "section": "Update",
    "text": "Update\nFinally, we can apply a step size\n\\[\\text{step size} = \\text{derivative} \\cdot \\text{learning rate}\\] If we had a learning rate of 0.1 (i.e. as a hyperparameter), then our step size here is\n\\[\\text{step size} = (-0.2100)(0.1) = -0.0210\\] Our new weight is\n\\[\\begin{array}{rcl}\n  \\text{new weight} & = & \\text{old weight} - \\text{step size} \\\\\n  ~ & = & 0.2 - (-0.0210) \\\\\n  ~ & = & 0.2210 \\\\\n\\end{array}\\]"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#feed-foward",
    "href": "posts/13_FCN/13_FCN.html#feed-foward",
    "title": "13: Fully Connected Networks",
    "section": "Feed Foward",
    "text": "Feed Foward\nApplying this new weight, our network now looks like this\n\n\n\n\n\n\n\nflowchart LR\n\ninput_1[0.75]\ninput_2[0.75]\noutput_1[0.3000]\noutput_2[0.3000]\noutput_3[0.3158]\n\ninput_1 -- 0.2*0.75 + 0 --&gt; output_1\ninput_1 -- 0.2*0.75 + 0 --&gt; output_2\ninput_1 -- 0.2*0.75 + 0 --&gt; output_3\ninput_2 -- 0.2*0.75 + 0 --&gt; output_1\ninput_2 -- 0.2*0.75 + 0 --&gt; output_2\ninput_2 -- 0.2210*0.75 + 0 --&gt; output_3\n\n\n\n\n\n\n\n\n\n\\[\\begin{array}{c|c|c}\n  \\text{predicted} & \\text{observed} & \\text{residual} \\\\\n  \\hline\n  0.3316 & 0 & 0.3316 \\\\\n  0.3316 & 0 & 0.3316 \\\\\n  0.3366 & 1 & -0.6637 \\\\\n\\end{array}\\]\nNow:\n\nthe prediction moved correctly toward “Gentoo”!\nthe residuals decreased!"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#tensors",
    "href": "posts/13_FCN/13_FCN.html#tensors",
    "title": "13: Fully Connected Networks",
    "section": "Tensors",
    "text": "Tensors\nWe will use tensors in Pytorch Lightning\n\n\n\n3D tensor\n\n\n\nimage source: MIT\n\n\nWhat are tensors?\nAt first, tensors (for machine learning) are multidimensional arrays.\n\na value is a 0D tensor\nan array is a 1D tensor\na matrix is a 2D tensor\n\n\n\nWhy do we use tensors?\n\naccelerated computations via graphical processing units (GPUs)\nautomatic differentiation\nhelps with parallelizable processes\n\n\n\n\nparallel processes\n\n\n\nimage source: Faisal Shahbaz"
  },
  {
    "objectID": "posts/13_FCN/13_FCN.html#object-oriented-programming",
    "href": "posts/13_FCN/13_FCN.html#object-oriented-programming",
    "title": "13: Fully Connected Networks",
    "section": "Object-Oriented Programming",
    "text": "Object-Oriented Programming\nFramework choice:\n\nKeras\nPyTorch\nScikit Learn\nTensorFlow\n\nWhy Pytorch?\n\nrecency bias (Derek studied these concepts with PyTorch)\nobject-oriented programming\n\nWhy Object-Oriented Programming?\nLater concepts are probably better understood as modular steps in a workflow, which lend themselves to object-oriented programming (OOP)\n\nExample 1Example 2Class Definition\n\n\nFor the penguins examples, we needed a fully-connected network whose input layer size was 2 and whose output layer size was 3\n\n\n\nexample 1\n\n\n\nPython code: model = FCN(2,3)\n\n\n\nFor the next example, we need a fully-connected network whose input layer size is 4 and whose output layer size is 2\n\n\n\nexample 2\n\n\n\nPython code: model = FCN(4,2)\n\n\n\n\nclass FCN(pl.LightningModule):\n  # Fully-Connected Network\n  # assumes no hidden layer (i.e. going directly into activation functions)\n\n    def __init__(self, input_layer_size, output_layer_size):\n        super().__init__()\n        self.input_layer_size = input_layer_size \n        self.output_layer_size = output_layer_size \n        self.fc1 = nn.Linear(input_layer_size, output_layer_size)\n        self.test_step_outputs = []\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return x\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        output = self(x)\n        loss = F.cross_entropy(output, y)\n        return {'loss':loss}\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        output = self(x)\n        loss = F.cross_entropy(output, y)\n        self.test_step_outputs.append(loss)\n        return {'loss':loss}\n\n    def on_test_epoch_end(self):\n        epoch_average = torch.stack(self.test_step_outputs).mean()\n        self.log(\"test_epoch_average\", epoch_average)\n        self.test_step_outputs.clear()\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n        return optimizer"
  },
  {
    "objectID": "posts/14_RNN/14_RNN.html",
    "href": "posts/14_RNN/14_RNN.html",
    "title": "14: Recurrent Neural Networks",
    "section": "",
    "text": "Discuss hidden layer size\nIntroduce the notion of memory for neural nets\n\n\n\n\n\n\n\nneural network"
  },
  {
    "objectID": "posts/14_RNN/14_RNN.html#learning-objectives",
    "href": "posts/14_RNN/14_RNN.html#learning-objectives",
    "title": "14: Recurrent Neural Networks",
    "section": "",
    "text": "Discuss hidden layer size\nIntroduce the notion of memory for neural nets\n\n\n\n\n\n\n\nneural network"
  },
  {
    "objectID": "posts/14_RNN/14_RNN.html#example-867-5309",
    "href": "posts/14_RNN/14_RNN.html#example-867-5309",
    "title": "14: Recurrent Neural Networks",
    "section": "Example: 867-5309",
    "text": "Example: 867-5309\nWe start with a sequence that has\n\\[\\{8, 6, 7, 5, 3, 0, 9, ...\\}\\] repeated over and over, and we hope that\n\ninput “8” leads to a prediction of “6”\ninput “6” leads to a prediction of “7”\ninput “7” leads to a prediction of “5”\ninput “5” leads to a prediction of “3”\ninput “3” leads to a prediction of “0”\ninput “0” leads to a prediction of “9”"
  },
  {
    "objectID": "posts/14_RNN/14_RNN.html#unfolding",
    "href": "posts/14_RNN/14_RNN.html#unfolding",
    "title": "14: Recurrent Neural Networks",
    "section": "Unfolding",
    "text": "Unfolding\n\n8\n\nDoes input “8” leads to a prediction of “6”?\n\n\n\n\n\n\nflowchart TD\n\ninput1[8]\n\nneuron1[ReLU]\n\noutput1[6.2494]\n\ninput1 -- 0.20x + 0.86 --&gt; neuron1\n\nneuron1 -- 0.91x - 0.25 --&gt; output1\n\n\n\n\n\n\n\nSSR:0.0622\n\n\n\n6\n\nDoes input “6” leads to a prediction of “7”?\n\n\n\n\n\n\nflowchart TD\n\ninput1[8]\ninput2[6]\n\nneuron1[ReLU]\nneuron2[ReLU]\n\noutput1[NA]\noutput2[5.2948]\n\ninput1 -- 0.20x + 0.86 --&gt; neuron1\ninput2 -- 0.20x + 0.86 --&gt; neuron2\n\nneuron1 -- 0.91x - 0.25 --&gt; output1\nneuron2 -- 0.91x - 0.25 --&gt; output2\n\nneuron1 -- -0.85x + 0.81 --&gt; neuron2\n\n\n\n\n\n\n\nSSR: 2.9077\n\n\n\n7\n\nDoes input “7” leads to a prediction of “5”?\n\n\n\n\n\n\nflowchart TD\n\ninput1[8]\ninput2[6]\ninput3[7]\n\nneuron1[ReLU]\nneuron2[ReLU]\nneuron3[ReLU]\n\noutput1[NA]\noutput2[NA]\noutput3[6.2882]\n\ninput1 -- 0.20x + 0.86 --&gt; neuron1\ninput2 -- 0.20x + 0.86 --&gt; neuron2\ninput3 -- 0.20x + 0.86 --&gt; neuron3\n\nneuron1 -- 0.91x - 0.25 --&gt; output1\nneuron2 -- 0.91x - 0.25 --&gt; output2\nneuron3 -- 0.91x - 0.25 --&gt; output3\n\nneuron1 -- -0.85x + 0.81 --&gt; neuron2\nneuron2 -- -0.85x + 0.81 --&gt; neuron3\n\n\n\n\n\n\n\nSSR: 1.6595\n\n\n\n5\n\nDoes input “5” leads to a prediction of “3”?\n\n\n\n\n\n\nflowchart TD\n\ninput1[8]\ninput2[6]\ninput3[7]\ninput4[5]\n\nneuron1[ReLU]\nneuron2[ReLU]\nneuron3[ReLU]\nneuron4[ReLU]\n\noutput1[NA]\noutput2[NA]\noutput3[NA]\noutput4[5.0798]\n\ninput1 -- 0.20x + 0.86 --&gt; neuron1\ninput2 -- 0.20x + 0.86 --&gt; neuron2\ninput3 -- 0.20x + 0.86 --&gt; neuron3\ninput4 -- 0.20x + 0.86 --&gt; neuron4\n\nneuron1 -- 0.91x - 0.25 --&gt; output1\nneuron2 -- 0.91x - 0.25 --&gt; output2\nneuron3 -- 0.91x - 0.25 --&gt; output3\nneuron4 -- 0.91x - 0.25 --&gt; output4\n\nneuron1 -- -0.85x + 0.81 --&gt; neuron2\nneuron2 -- -0.85x + 0.81 --&gt; neuron3\nneuron3 -- -0.85x + 0.81 --&gt; neuron4\n\n\n\n\n\n\n\nSSR: 4.3257\n\n\n\n3\n\nDoes input “3” leads to a prediction of “0”?\n\n\n\n\n\n\nflowchart TD\n\ninput1[8]\ninput2[6]\ninput3[7]\ninput4[5]\ninput5[3]\n\nneuron1[ReLU]\nneuron2[ReLU]\nneuron3[ReLU]\nneuron4[ReLU]\nneuron5[ReLU]\n\noutput1[NA]\noutput2[NA]\noutput3[NA]\noutput4[NA]\noutput5[5.7430]\n\ninput1 -- 0.20x + 0.86 --&gt; neuron1\ninput2 -- 0.20x + 0.86 --&gt; neuron2\ninput3 -- 0.20x + 0.86 --&gt; neuron3\ninput4 -- 0.20x + 0.86 --&gt; neuron4\ninput5 -- 0.20x + 0.86 --&gt; neuron5\n\nneuron1 -- 0.91x - 0.25 --&gt; output1\nneuron2 -- 0.91x - 0.25 --&gt; output2\nneuron3 -- 0.91x - 0.25 --&gt; output3\nneuron4 -- 0.91x - 0.25 --&gt; output4\nneuron5 -- 0.91x - 0.25 --&gt; output5\n\nneuron1 -- -0.85x + 0.81 --&gt; neuron2\nneuron2 -- -0.85x + 0.81 --&gt; neuron3\nneuron3 -- -0.85x + 0.81 --&gt; neuron4\nneuron4 -- -0.85x + 0.81 --&gt; neuron5\n\n\n\n\n\n\n\nSSR: 32.9815\n\n\n\n0\n\nDoes input “0” leads to a prediction of “9”?\n\n\n\n\n\n\nflowchart TD\n\ninput1[8]\ninput2[6]\ninput3[7]\ninput4[5]\ninput5[3]\ninput6[0]\n\nneuron1[ReLU]\nneuron2[ReLU]\nneuron3[ReLU]\nneuron4[ReLU]\nneuron5[ReLU]\nneuron6[ReLU]\n\noutput1[NA]\noutput2[NA]\noutput3[NA]\noutput4[NA]\noutput5[NA]\noutput6[4.6333]\n\ninput1 -- 0.20x + 0.86 --&gt; neuron1\ninput2 -- 0.20x + 0.86 --&gt; neuron2\ninput3 -- 0.20x + 0.86 --&gt; neuron3\ninput4 -- 0.20x + 0.86 --&gt; neuron4\ninput5 -- 0.20x + 0.86 --&gt; neuron5\ninput6 -- 0.20x + 0.86 --&gt; neuron6\n\nneuron1 -- 0.91x - 0.25 --&gt; output1\nneuron2 -- 0.91x - 0.25 --&gt; output2\nneuron3 -- 0.91x - 0.25 --&gt; output3\nneuron4 -- 0.91x - 0.25 --&gt; output4\nneuron5 -- 0.91x - 0.25 --&gt; output5\nneuron6 -- 0.91x - 0.25 --&gt; output6\n\nneuron1 -- -0.85x + 0.81 --&gt; neuron2\nneuron2 -- -0.85x + 0.81 --&gt; neuron3\nneuron3 -- -0.85x + 0.81 --&gt; neuron4\nneuron4 -- -0.85x + 0.81 --&gt; neuron5\nneuron5 -- -0.85x + 0.81 --&gt; neuron6\n\n\n\n\n\n\n\nSSR: 19.0682"
  },
  {
    "objectID": "posts/14_RNN/14_RNN.html#chain-rule",
    "href": "posts/14_RNN/14_RNN.html#chain-rule",
    "title": "14: Recurrent Neural Networks",
    "section": "Chain Rule",
    "text": "Chain Rule\nToward back propagation, the derivative based on output \\(k\\) given inputs \\(\\{1, 2, ..., k\\}\\) is\n\\[\\begin{array}{rcl}\n\\frac{\\partial\\text{SSR}}{\\partial x_{k}} & = & \\displaystyle\\sum_{a = 1}^{k}\n\\frac{\\partial\\text{SSR}}{\\partial L_{h,o}}\n\\left(\\displaystyle\\prod_{b=1}^{a-1}\n\\frac{\\partial L_{h,o}}{\\partial\\text{ReLU}}\\cdot\n\\frac{\\partial\\text{ReLU}}{\\partial L_{h,h}}\\cdot\n\\frac{\\partial L_{h,h}}{L_{i,h}}\n\\right)\n\\frac{\\partial L_{i,h}}{\\partial x_{k}} \\\\\n~ & = & \\displaystyle\\sum_{a = 1}^{k}\nw_{i,h}\n\\left(\\displaystyle\\prod_{b=1}^{a-1}\nw_{h,h}\\right)\nw_{h,0} \\\\\n\\end{array}\\]"
  },
  {
    "objectID": "posts/14_RNN/14_RNN.html#example-867-5309-1",
    "href": "posts/14_RNN/14_RNN.html#example-867-5309-1",
    "title": "14: Recurrent Neural Networks",
    "section": "Example: 867-5309",
    "text": "Example: 867-5309\nFor today’s example, the derviative is\n\\[\\frac{\\partial\\text{SSR}}{\\partial x_{k}} = \\sum_{a = 1}^{k}\n(0.20)\n\\left(\\prod_{b=1}^{a-1}\n(-0.85)\n\\right)\n(0.91)\\]\n\n\n\n\n\n\nGradient Propagation\n\n\n\n\nwe have vanishing gradients if \\(|w_{h,h}| &lt; 1\\)\nwe have exploding gradients if \\(|w_{h,h}| &gt; 1\\)"
  },
  {
    "objectID": "posts/18_parsing/18_Parsing.html",
    "href": "posts/18_parsing/18_Parsing.html",
    "title": "18: Parsing",
    "section": "",
    "text": "Continue word embedding\nExplore tokenization\nIntroduce computer vision\n\n\n\n\n\n\n\n301"
  },
  {
    "objectID": "posts/18_parsing/18_Parsing.html#learning-objectives",
    "href": "posts/18_parsing/18_Parsing.html#learning-objectives",
    "title": "18: Parsing",
    "section": "",
    "text": "Continue word embedding\nExplore tokenization\nIntroduce computer vision\n\n\n\n\n\n\n\n301"
  },
  {
    "objectID": "posts/18_parsing/18_Parsing.html#linear-relationships",
    "href": "posts/18_parsing/18_Parsing.html#linear-relationships",
    "title": "18: Parsing",
    "section": "Linear Relationships",
    "text": "Linear Relationships\n\n\n\\[w_{\\text{king}}   - w_{\\text{man}} + w_{\\text{woman}} \\approx w_{\\text{queen}}\\] * explore in this app!\n\n\n\n\n\n\nword vector space\n\n\n\nimage credit: plotly\n\n\n\n\n\n\nword vector spaces\n\n\n\nimage credit: Fabian Pfurtscheller"
  },
  {
    "objectID": "posts/18_parsing/18_Parsing.html#byte-pair-encoding",
    "href": "posts/18_parsing/18_Parsing.html#byte-pair-encoding",
    "title": "18: Parsing",
    "section": "Byte Pair Encoding",
    "text": "Byte Pair Encoding\nTo compress long text passages, we can employ byte pair encoding"
  },
  {
    "objectID": "posts/18_parsing/18_Parsing.html#bootstrapping",
    "href": "posts/18_parsing/18_Parsing.html#bootstrapping",
    "title": "18: Parsing",
    "section": "Bootstrapping",
    "text": "Bootstrapping\nIf we don’t have enough images to easily train a convolutional neural network, we can synthetically increase the number of image files by bootstrapping the original images with minor alterations such as\n\nrotations\nreflections\n\nand we might also want to resize the images while drafting a neural net workflow."
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html",
    "href": "posts/19_RL/19_reinforcement_learning.html",
    "title": "19: Reinforcement Learning",
    "section": "",
    "text": "Introduce reinforcement learning\nDiscuss Markov Decision Processes\n\n\n\n\n\n\n\nReinforcement Learning\n\n\n\nimage credit: Data Base Camp"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#learning-objectives",
    "href": "posts/19_RL/19_reinforcement_learning.html#learning-objectives",
    "title": "19: Reinforcement Learning",
    "section": "",
    "text": "Introduce reinforcement learning\nDiscuss Markov Decision Processes\n\n\n\n\n\n\n\nReinforcement Learning\n\n\n\nimage credit: Data Base Camp"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#neural-network",
    "href": "posts/19_RL/19_reinforcement_learning.html#neural-network",
    "title": "19: Reinforcement Learning",
    "section": "Neural Network",
    "text": "Neural Network\n\n\n\n\n\nflowchart LR\n\ninput[hunger]\nactivation[sigmoid]\noutput[residential college]\n\ninput -- wH + b --&gt; activation\nactivation --&gt; output\n\n\n\n\n\n\n\nlinear transformation: \\(L = wh + b\\) in the fully connected layer\noutput: probability of choosing to eat at your residential college (instead of Frist)\nlearning rate (hyperparameter): 0.301\n\n\n\n\n\n\n\nSigmoid instead of ReLU?\n\n\n\n\n\nHere, I am using the sigmoid activation function instead of the ReLU simply because it is easier in the slides presentation.\n\nsigmoid\n\n\\[A(x) = \\frac{1}{1 + e^{-x}} \\text{ with }\\frac{dA}{dx} = \\sigma(x)(1 - \\sigma(x))\\] * ReLU\n\\[f(x) = \\text{max}(x,0) \\text{ with } f'(x) = \\begin{cases} 1, & x &gt; 0 \\\\ 0, & x \\leq 0 \\end{cases}\\]"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#forward-propagation",
    "href": "posts/19_RL/19_reinforcement_learning.html#forward-propagation",
    "title": "19: Reinforcement Learning",
    "section": "Forward Propagation",
    "text": "Forward Propagation\nSuppose that you are not hungry (\\(H = 0\\)) but you still want to eat some dinner at this time.\n\ninitialized as \\(w = 20\\) and \\(b = 0\\)\nwe will train for the bias value\nwe don’t know the meal satisfaction in advance\n\n\n\n\n\n\nflowchart LR\n\ninput[H = 0]\nactivation[sigmoid]\noutput[residential college]\n\ninput -- 20H + 0 --&gt; activation\nactivation --&gt; output\n\n\n\n\n\n\nSo far, our distribution of choices is\n\n\\(P(\\text{residential college}) = A(0) = \\frac{1}{1 + e^{-0}} = 0.5\\)\n\\(P(\\text{Frist}) = 1 - P(\\text{residential college}) = 0.5\\)\n\nwhose \\([0,1]\\) probability space can be mapped as\n\n\\([0, 0.5)\\): go to Frist\n\\((0.5, 1.0]\\): go to your residential college\n\nNow, suppose that we used a random number generator and obtained 0.2025. Thus, we are visiting Frist."
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#cross-entropy",
    "href": "posts/19_RL/19_reinforcement_learning.html#cross-entropy",
    "title": "19: Reinforcement Learning",
    "section": "Cross Entropy",
    "text": "Cross Entropy\nWe will use cross entropy to measure the loss.\n\\[C_{\\text{res}} = -\\ln(P(\\text{res}))\\] \\[C_{\\text{Frist}} = -\\ln(1 - P(\\text{res}))\\]"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#chain-rule",
    "href": "posts/19_RL/19_reinforcement_learning.html#chain-rule",
    "title": "19: Reinforcement Learning",
    "section": "Chain Rule",
    "text": "Chain Rule\nToward using the output to train the bias, we examine the chain rule to apply the change in the cross entropy with respect to the bias.\n\\[\\begin{array}{rcl}\n\\frac{dC_{\\text{Frist}}}{db} & = & \\frac{dC_{\\text{Frist}}}{dP(\\text{res})} \\cdot \\frac{dP(\\text{res})}{dL} \\cdot \\frac{dL}{db} \\\\\n~ & = & \\frac{1}{1 - P(\\text{res})} \\cdot P(\\text{res}) \\cdot (1 - P(\\text{res})) \\cdot (1) \\\\\n~ & = & 0.5 \\\\\n\\end{array}\\]\n\n\n\n\n\n\nSigns\n\n\n\nIf we were training a simple neural network\n\nnegative derivative –&gt; decrease parameter\npositive derivative –&gt; increase parameter\n\n\n\n\n\n\n\n\n\nRewards\n\n\n\nHowever, we need to incorporate the possible rewards\n\\[\\text{updated derivative} = \\text{derivative}*\\text{reward}\\]"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#rewards-1",
    "href": "posts/19_RL/19_reinforcement_learning.html#rewards-1",
    "title": "19: Reinforcement Learning",
    "section": "Rewards",
    "text": "Rewards\nIn this scenario, let us assign the rewards as follows\n\nIf hunger = 0 and we choose Frist: reward = 1.0\n\nperhaps valued location over quantity of food\n\nIf hunger = 0 and we choose the residential college: reward = -1.0\n\n\n\n\n\n\n\nHow are reward amounts chosen?\n\n\n\n\n\nFor now, we note that reward amounts do not have to be \\(\\pm 1.0\\). Amounts can be weighted to give more priority to certain outcomes.\n\n\n\nThus, in our scenario here, our updated derivative is\n\\[\\begin{array}{rcl}\n\\text{updated derivative} & = & \\text{derivative}*\\text{reward} \\\\\n~ & = & (0.5)(1.0) \\\\\n~ & = & 0.5\n\\end{array}\\]"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#update",
    "href": "posts/19_RL/19_reinforcement_learning.html#update",
    "title": "19: Reinforcement Learning",
    "section": "Update",
    "text": "Update\n\\[\\begin{array}{rcl}\n\\text{step size} & = &\\text{learning rate}*\\text{updated derivative} \\\\\n~ & = & (0.301)(0.5) \\\\\n~ & = & 0.1505 \\\\\n\\end{array}\\]\n\\[\\begin{array}{rcl}\n\\text{updated bias} & = & \\text{old bias} - \\text{step size} \\\\\n~ & = & 0.0 - 0.1505 \\\\\n~ & = & -0.1505 \\\\\n\\end{array}\\]\n\n\n\n\n\nflowchart LR\n\ninput[H = 0]\nactivation[sigmoid]\noutput[residential college]\n\ninput -- 20H - 0.1505 --&gt; activation\nactivation --&gt; output\n\n\n\n\n\n\nNow, our distribution of choices is\n\n\\(P(\\text{residential college}) = A(-0.1505) = \\frac{1}{1 + e^{0.1505}} \\approx 0.4624\\)\n\\(P(\\text{Frist}) = 1 - P(\\text{residential college}) \\approx 0.5376\\)\n\nwhose \\([0,1]\\) probability space can be mapped as\n\n\\([0, 0.5376)\\): go to Frist\n\\((0.5376, 1.0]\\): go to your residential college"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#second-epoch",
    "href": "posts/19_RL/19_reinforcement_learning.html#second-epoch",
    "title": "19: Reinforcement Learning",
    "section": "Second Epoch",
    "text": "Second Epoch\n\nStartCERewardsUpdate\n\n\nNow, suppose that we used a random number generator and obtained 0.678. Thus, we are visiting your residential college.\n\n\\(P(\\text{residential college}) = A(-0.1505) = \\frac{1}{1 + e^{0.1505}} \\approx 0.4624\\)\n\\(P(\\text{Frist}) = 1 - P(\\text{residential college}) \\approx 0.5376\\)\n\n\n\n\\[\\begin{array}{rcl}\n\\frac{dC_{\\text{res}}}{db} & = & \\frac{dC_{\\text{res}}}{dP(\\text{res})} \\cdot \\frac{dP(\\text{res})}{dL} \\cdot \\frac{dL}{db} \\\\\n~ & = & \\frac{-1}{P(\\text{res})} \\cdot P(\\text{res}) \\cdot (1 - P(\\text{res})) \\cdot (1) \\\\\n~ & = & -0.5376 \\\\\n\\end{array}\\]\n\n\nBut eating at the residential college when you are not hungry was assigned a reward value of -1.0.\n\\[\\begin{array}{rcl}\n\\text{updated derivative} & = & \\text{derivative}*\\text{reward} \\\\\n~ & = & (-0.5376)(-1.0) \\\\\n~ & = & 0.5376\n\\end{array}\\]\n\n\n\\[\\begin{array}{rcl}\n\\text{step size} & = &\\text{learning rate}*\\text{updated derivative} \\\\\n~ & = & (0.301)(0.5376) \\\\\n~ & \\approx & 0.1618 \\\\\n\\end{array}\\]\n\\[\\begin{array}{rcl}\n\\text{updated bias} & = & \\text{old bias} - \\text{step size} \\\\\n~ & = & -0.1505 - 0.1618 \\\\\n~ & = & -0.3123 \\\\\n\\end{array}\\]\n\n\n\n\n\n\n\n\nflowchart LR\n\ninput[H = 0]\nactivation[sigmoid]\noutput[residential college]\n\ninput -- 20H - 0.3123 --&gt; activation\nactivation --&gt; output\n\n\n\n\n\n\nAfter the second epoch, our distribution of choices is\n\n\\(P(\\text{residential college}) = A(-0.3123) = \\frac{1}{1 + e^{0.3123}} \\approx 0.4226\\)\n\\(P(\\text{Frist}) = 1 - P(\\text{residential college}) \\approx 0.5774\\)\n\nwhose \\([0,1]\\) probability space can be mapped as\n\n\\([0, 0.5774)\\): go to Frist\n\\((0.5774, 1.0]\\): go to your residential college\n\nThat is, in situations without hunger, your chance of choosing dining at your residential college is decreasing."
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#many-epochs",
    "href": "posts/19_RL/19_reinforcement_learning.html#many-epochs",
    "title": "19: Reinforcement Learning",
    "section": "Many Epochs",
    "text": "Many Epochs\nAssuming that we can get data from many dinners (and/or many students), the neural network would be trained over\n\nmany epochs\nmany values for hunger (\\(H \\in [0,1]\\))\n\nand would perhaps converage toward\n\n\n\n\n\nflowchart LR\n\ninput[H]\nactivation[sigmoid]\noutput[residential college]\n\ninput -- 20H - 10 --&gt; activation\nactivation --&gt; output\n\n\n\n\n\n\n\\[\\begin{array}{rcl}\n  H \\in [0, 0.5) & \\rightarrow & \\text{prefer Frist} \\\\\n  H \\in (0.5, 1.0] & \\rightarrow & \\text{prefer residential college} \\\\\n\\end{array}\\]"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#return",
    "href": "posts/19_RL/19_reinforcement_learning.html#return",
    "title": "19: Reinforcement Learning",
    "section": "Return",
    "text": "Return\nThe return of a trajectory is the total of the rewards\n\\[r_{0} + \\gamma r_{1} + \\gamma^{2}r_{2} + \\gamma_{3}r_{3} + ... = \\displaystyle\\sum_{t = 0}^{T} \\gamma^{t}r_{t}\\]\nwhere \\(\\gamma \\in [0,1]\\) is the discount rate.\n\n\n\n\n\n\nGoal\n\n\n\nThe goal in reinforcement learning is to seek out a policy \\(\\pi\\) that maximizes the return.\n\n\nFrom a later moment in time (i.e. not the initial state), we can think of the return as\n\\[G_{t} = \\displaystyle\\sum_{k = t+1}^{T} \\gamma^{k - t - 1}R_{k}\\]\nand then the goal can be expressed as\n\\[\\text{max}_{\\pi} \\text{E}_{\\pi}[G_{t}]\\]"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#state-and-action-functions",
    "href": "posts/19_RL/19_reinforcement_learning.html#state-and-action-functions",
    "title": "19: Reinforcement Learning",
    "section": "State and Action Functions",
    "text": "State and Action Functions\n\n\n\n\n\n\nState Value Function\n\n\n\n\\[v_{\\pi}(s) = \\text{E}[G_{t}|S_{t} = s]\\]\nis the value of being at state \\(s\\), and is defined as the expected value of the return given that we are at state \\(s\\).\n\n\n\n\n\n\n\n\nAction Value Function\n\n\n\n\\[q_{\\pi}(s,a) = \\text{E}[G_{t}|S_{t} = s, A_{t} = a]\\]\nis the expected return given that we are at state \\(s\\) and take action \\(a\\)."
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#optimal-policy",
    "href": "posts/19_RL/19_reinforcement_learning.html#optimal-policy",
    "title": "19: Reinforcement Learning",
    "section": "Optimal Policy",
    "text": "Optimal Policy\nThere exists an optimal policy \\(\\pi_{*}\\) where\n\\[\\begin{array}{rclc}\n  v_{\\pi_{*}}(s) & \\geq & v_{\\pi}(s) & \\forall s \\forall \\pi \\\\\n  q_{\\pi_{*}}(s,a) & \\geq & q_{\\pi}(s,a) & \\forall s \\forall a \\forall \\pi \\\\\n\\end{array}\\]\nTo iterate toward an optimal policy, we try dynamic programming.\n\n\n\n\n\n\nDynamic Programming\n\n\n\n\n\nHere, dynamic programming will assume complete knowledge of the Markov decision process, where\n\nstate space \\(S\\) is finite\nstate space is discrete\ntemporal space is finite (i.e. \\(T &lt; \\infty\\))\n\nDynamic programming can rely on knowing distribution\n\\[P(s', r| s,a)\\]\n\n\n\nBellman optimality says that the agent must choose an action that has the maximum value. Computing total probabilities yields"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#forming-the-bellman-equations",
    "href": "posts/19_RL/19_reinforcement_learning.html#forming-the-bellman-equations",
    "title": "19: Reinforcement Learning",
    "section": "Forming the Bellman Equations",
    "text": "Forming the Bellman Equations\n\\[\\begin{array}{c|rcl}\n  (1) & v_{\\pi}(s) & = & \\displaystyle\\sum_{a\\in\\mathcal{A}(s)} \\pi(a|s)q_{\\pi}(s,a) \\\\\n  (2) & q_{\\pi}(s,a) & = & \\displaystyle\\sum_{\\begin{array}{c} s'\\in\\mathcal{S} \\\\ r\\in\\mathcal{R}\\end{array}} p(s',r|s,a)[r + \\gamma v_{\\pi}(s')]\n\\end{array}\\]\n\nIf we substitute (2) into (1), we can form the Bellman Equation for state values that relates any state value from any state value one step away:\n\n\\[v_{\\pi}(s) = \\displaystyle\\sum_{a\\in\\mathcal{A}(s)} \\pi(a|s)\\displaystyle\\sum_{\\begin{array}{c} s'\\in\\mathcal{S} \\\\ r\\in\\mathcal{R}\\end{array}} p(s',r|s,a)[r + \\gamma v_{\\pi}(s')]\\]\n\nIf we substitute (1) into (2), we can form the Bellman Equation for action values that relates any action value to any action value one step away:\n\n\\[q_{\\pi}(s,a) = \\displaystyle\\sum_{\\begin{array}{c} s'\\in\\mathcal{S} \\\\ r\\in\\mathcal{R}\\end{array}} p(s',r|s,a)\\left[r + \\gamma \\displaystyle\\sum_{a'\\in\\mathcal{A}(s')} \\pi(a'|s')q_{\\pi}(s',a')\\right] \\]\n\n\n\n\n\n\nBellman’s contribution\n\n\n\nFor a Markov decision process (MDP) where we know the distribution of possible states, the Bellman equations above all us to compute any state value or any action value from all of the other information.\n\n\n\n\n\n\n\n\nRecursion\n\n\n\n\n\nThe derivation of equation (2) above involves how the returns\n\\[G_{t} = R_{t+1} + \\gamma G_{t+1}\\] Then, the expected values are\n\\[\\begin{array}{rcl}\n\\text{E}[G_{t}|s,a] & = & \\text{E}[R_{t+1} + \\gamma G_{t+1}|s,a] \\\\\n~ & = & \\text{E}[R_{t+1} + \\gamma v_{\\pi}(S_{t+1})|s,a] \\\\\n\\end{array}\\]\nOne cannot say that distributions \\(G_{t+1} = v_{\\pi}(S_{t+1})\\), but we are allowed to equate the expected values!"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#definition",
    "href": "posts/19_RL/19_reinforcement_learning.html#definition",
    "title": "19: Reinforcement Learning",
    "section": "Definition",
    "text": "Definition\nIf we have the state value function \\(v_{\\pi}(s)\\), and assuming a deterministic policy (i.e. \\(a = \\pi(s)\\)), an optimal policy is defined as\n\\[\\pi_{*}(s) = \\text{argmax}_{a} q_{*}(s,a)\\] We define a new policy \\(\\pi'\\) as\n\\[\\pi'(s) = \\text{argmax}_{a} q_{\\pi}(s,a)\\]\nand due to the Policy Improvement Theorem, we are assured that\n\\[v_{\\pi'}(s) \\geq v_{\\pi}(s) \\quad \\forall s \\in \\mathcal{S}\\]"
  },
  {
    "objectID": "posts/19_RL/19_reinforcement_learning.html#gpi",
    "href": "posts/19_RL/19_reinforcement_learning.html#gpi",
    "title": "19: Reinforcement Learning",
    "section": "GPI",
    "text": "GPI\nFor Generalized Policy Iteration, we hope to converge to the optimal policy \\(\\pi_{*}\\) and optimal state value function \\(v_{*}\\).\n“Almost all reinforcement learning methods are well described as GPI” — Simon and Barto"
  },
  {
    "objectID": "posts/20_RL2/20_reinforcement_learning_Q.html",
    "href": "posts/20_RL2/20_reinforcement_learning_Q.html",
    "title": "20: Reinforcement Learning",
    "section": "",
    "text": "Explore the breadth of reinforcement learning\nIntroduce Q Learning\n\n\n\n\n\n\n\nReinforcement Learning\n\n\n\nimage credit: Data Base Camp"
  },
  {
    "objectID": "posts/20_RL2/20_reinforcement_learning_Q.html#learning-objectives",
    "href": "posts/20_RL2/20_reinforcement_learning_Q.html#learning-objectives",
    "title": "20: Reinforcement Learning",
    "section": "",
    "text": "Explore the breadth of reinforcement learning\nIntroduce Q Learning\n\n\n\n\n\n\n\nReinforcement Learning\n\n\n\nimage credit: Data Base Camp"
  },
  {
    "objectID": "posts/20_RL2/20_reinforcement_learning_Q.html#model-free",
    "href": "posts/20_RL2/20_reinforcement_learning_Q.html#model-free",
    "title": "20: Reinforcement Learning",
    "section": "Model-Free",
    "text": "Model-Free\n\n\n\n\n\n\nModel\n\n\n\nA model is a mechanism that an agent uses to predict the results of its actions\n\ne.g. estimating \\(p(s',r|s,a)\\)\n\n\n\n\n\n\n\n\n\nModel-Free\n\n\n\n\nModel-Based: methods that use a model to plan actions beforehand\nModel-Free: methods that learn action-to return associations\n\n\n\n\n\n\n\n\n\nMC is Model-Free\n\n\n\nMonte Carlo methods are model-free. As such, it may be more useful to estimate state-action values \\(q\\) rather than state values \\(v\\). Recall that\n\\[Q(s,a) = \\displaystyle\\sum_{\\begin{array}{c} s'\\in\\mathcal{S} \\\\ r\\in\\mathcal{R}\\end{array}} p(s',r|s,a)[r + \\gamma V(s')]\\]\nBut since we are no longer assuming knowledge of \\(p(s',r|s,a)\\), let us estimate the optimal state-action values \\(q_{*}(s,a)\\) directly."
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html",
    "href": "posts/21_GAN/21_GAN.html",
    "title": "21: Generative Adversarial Networks",
    "section": "",
    "text": "Introduce generative adversarial networks\n\n\n\n\n\n\n\nCycle GANs\n\n\n\nimage credit: Jun-Yan Zhu, et al.\n\n\n\n\n\n\n\nDefinitionDall-EStable Diffusion\n\n\n\n\n\n“Generative AI is a form of artificial intelligence that is designed to generate content, including text, images, video and music. It uses large language models and algorithms to analyze patterns in datasets to mimic the style or structure of specific types of content.”\nquote and image source\n\n\n\n\n\ngenerative AI\n\n\n\n\n\n\n\n\n\nJune 2022\n\n\nimage source\n\n\n\n\n\nAugust 2023\n\n\nimage source\n\n\n\n\n\n\n\nAppLionsTigersPenguins\n\n\n\n\n\n\n\nQuick Draw, by Google\n\n\n\n\n\nTry out Quick Draw!\n\nhttps://quickdraw.withgoogle.com/\napp will ask you to sketch 6 images\n\nand it will try to recognize your artwork\n\ncaution: there is sound\n\n\n\n\n\n\n\n\nQuick, Draw! Lions\n\n\n\n\n\n\n\nQuick, Draw! Tigers\n\n\n\n\n\n\n\nQuick, Draw! Penguins"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#learning-objectives",
    "href": "posts/21_GAN/21_GAN.html#learning-objectives",
    "title": "21: Generative Adversarial Networks",
    "section": "",
    "text": "Introduce generative adversarial networks\n\n\n\n\n\n\n\nCycle GANs\n\n\n\nimage credit: Jun-Yan Zhu, et al."
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#generative-ai",
    "href": "posts/21_GAN/21_GAN.html#generative-ai",
    "title": "21: Generative Adversarial Networks",
    "section": "",
    "text": "DefinitionDall-EStable Diffusion\n\n\n\n\n\n“Generative AI is a form of artificial intelligence that is designed to generate content, including text, images, video and music. It uses large language models and algorithms to analyze patterns in datasets to mimic the style or structure of specific types of content.”\nquote and image source\n\n\n\n\n\ngenerative AI\n\n\n\n\n\n\n\n\n\nJune 2022\n\n\nimage source\n\n\n\n\n\nAugust 2023\n\n\nimage source"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#activity-quick-draw",
    "href": "posts/21_GAN/21_GAN.html#activity-quick-draw",
    "title": "21: Generative Adversarial Networks",
    "section": "",
    "text": "AppLionsTigersPenguins\n\n\n\n\n\n\n\nQuick Draw, by Google\n\n\n\n\n\nTry out Quick Draw!\n\nhttps://quickdraw.withgoogle.com/\napp will ask you to sketch 6 images\n\nand it will try to recognize your artwork\n\ncaution: there is sound\n\n\n\n\n\n\n\n\nQuick, Draw! Lions\n\n\n\n\n\n\n\nQuick, Draw! Tigers\n\n\n\n\n\n\n\nQuick, Draw! Penguins"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#overview",
    "href": "posts/21_GAN/21_GAN.html#overview",
    "title": "21: Generative Adversarial Networks",
    "section": "Overview",
    "text": "Overview\n\n\n\nGANs overview\n\n\n\nimage source: Deep Learning Illustrated"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#discriminator",
    "href": "posts/21_GAN/21_GAN.html#discriminator",
    "title": "21: Generative Adversarial Networks",
    "section": "Discriminator",
    "text": "Discriminator\n\n\n\nTraining the discriminator\n\n\n\nimage source: Deep Learning Illustrated"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#generator",
    "href": "posts/21_GAN/21_GAN.html#generator",
    "title": "21: Generative Adversarial Networks",
    "section": "Generator",
    "text": "Generator\n\n\n\nTraining the generator\n\n\n\nimage source: Deep Learning Illustrated\n\n\n\n\n\n\n\nGAN Objectives\n\n\n\n\nthe goal of a generator is to create better fake images\nthe goal of a discriminator is to better classify fake images"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#adversarial-network",
    "href": "posts/21_GAN/21_GAN.html#adversarial-network",
    "title": "21: Generative Adversarial Networks",
    "section": "Adversarial Network",
    "text": "Adversarial Network\n\n\n\nAdversarial network\n\n\n\nimage source: Deep Learning Illustrated"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#initial-results",
    "href": "posts/21_GAN/21_GAN.html#initial-results",
    "title": "21: Generative Adversarial Networks",
    "section": "Initial Results",
    "text": "Initial Results\n\n\n\nGoodfellow, et al., 2014"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#activity-pix2pix-image-to-image",
    "href": "posts/21_GAN/21_GAN.html#activity-pix2pix-image-to-image",
    "title": "21: Generative Adversarial Networks",
    "section": "Activity: Pix2Pix Image-to-Image",
    "text": "Activity: Pix2Pix Image-to-Image\n\nAppex1ex2ex1\n\n\n\n\n\n\n\nimage-to-image\n\n\n\n\n\n\napp (link) by Christopher Hesse\nGitHub repo\n\n\n\n\n\n\n\n\nedges2cats\n\n\n\n\n\n\n\nfacades\n\n\n\n\n\n\n\nedges2handbags"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#activity-pix2pix-instruct",
    "href": "posts/21_GAN/21_GAN.html#activity-pix2pix-instruct",
    "title": "21: Generative Adversarial Networks",
    "section": "Activity: Pix2Pix Instruct",
    "text": "Activity: Pix2Pix Instruct\n\nAppex1ex2ex3\n\n\n\n\n\n\n\npix2pix\n\n\n\n\n\n\napp (link) by Tim Brooks\nGitHub repo\n\n\n\n\n\n\n\n\n\n\nNew Jersey flag\n\n\n\n\n\n\n\n\nconvert to grayscale\n\n\n\n\n\n\n\n\n\n\n\nNew Jersey flag\n\n\n\n\n\n\n\n\nadd more horses\n\n\n\n\n\n\n\n\n\n\n\nNew Jersey flag\n\n\n\n\n\n\n\n\nreplace humans with ramen"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#architecture",
    "href": "posts/21_GAN/21_GAN.html#architecture",
    "title": "21: Generative Adversarial Networks",
    "section": "Architecture",
    "text": "Architecture\n\n\n\nZhang, et al., 2016"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#scaling",
    "href": "posts/21_GAN/21_GAN.html#scaling",
    "title": "21: Generative Adversarial Networks",
    "section": "Scaling",
    "text": "Scaling\n\n\n\nZhang, et al., 2016"
  },
  {
    "objectID": "posts/21_GAN/21_GAN.html#architecture-1",
    "href": "posts/21_GAN/21_GAN.html#architecture-1",
    "title": "21: Generative Adversarial Networks",
    "section": "Architecture",
    "text": "Architecture\n\n\n\n\ncycle GAN architecture\n\n\n\nimages source: Bansal and Rathore\n\n\n\n\n\n\n\ncGAN Objective\n\n\n\nIn a cyclic GAN, the generator and discriminator converge toward a Nash equilibrium."
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html",
    "href": "posts/22_transformers/22_transformers.html",
    "title": "22: Transformers",
    "section": "",
    "text": "Revise understanding of long-term memory\nExplore text encoder-decoder modeling\n\n\n\n\n\n\n\nencoder-decoder\n\n\n\nimage credit: StatQuest\n\n\n\n\n\n\n\n\n\nDatenwissenschaft\n\n\n\n\n\n\n\n\nDeutsch\n\n\n\n\n\nI did ask a German person to check my translation. They kindly informed me that German data scientists tend to say “data science” instead of “Datenwissenschaft”.\nI opted for the large compound word to fermet discussion about the grammatical differences.\n\n\n\n\n\n\n\nExampleUnfoldedVanishing Gradients\n\n\n\n\n\n\n\nflowchart LR\n\ninput1[input]\n\nneuron1[neuron]\n\noutput1[output]\n\ninput1 --&gt; neuron1\nneuron1 --&gt; output1\nneuron1 --&gt; neuron1\n\n\n\n\n\n\n\n\n\n\n\nunfolded RNN\n\n\n\n\n\n\n\n\n\n\nGradient Propagation\n\n\n\n\nwe have vanishing gradients if \\(|w_{h,h}| &lt; 1\\)\nwe have exploding gradients if \\(|w_{h,h}| &gt; 1\\)"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#learning-objectives",
    "href": "posts/22_transformers/22_transformers.html#learning-objectives",
    "title": "22: Transformers",
    "section": "",
    "text": "Revise understanding of long-term memory\nExplore text encoder-decoder modeling\n\n\n\n\n\n\n\nencoder-decoder\n\n\n\nimage credit: StatQuest"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#main-example",
    "href": "posts/22_transformers/22_transformers.html#main-example",
    "title": "22: Transformers",
    "section": "",
    "text": "Datenwissenschaft\n\n\n\n\n\n\n\n\nDeutsch\n\n\n\n\n\nI did ask a German person to check my translation. They kindly informed me that German data scientists tend to say “data science” instead of “Datenwissenschaft”.\nI opted for the large compound word to fermet discussion about the grammatical differences."
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#recall-rnns",
    "href": "posts/22_transformers/22_transformers.html#recall-rnns",
    "title": "22: Transformers",
    "section": "",
    "text": "ExampleUnfoldedVanishing Gradients\n\n\n\n\n\n\n\nflowchart LR\n\ninput1[input]\n\nneuron1[neuron]\n\noutput1[output]\n\ninput1 --&gt; neuron1\nneuron1 --&gt; output1\nneuron1 --&gt; neuron1\n\n\n\n\n\n\n\n\n\n\n\nunfolded RNN\n\n\n\n\n\n\n\n\n\n\nGradient Propagation\n\n\n\n\nwe have vanishing gradients if \\(|w_{h,h}| &lt; 1\\)\nwe have exploding gradients if \\(|w_{h,h}| &gt; 1\\)"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#main-example-1",
    "href": "posts/22_transformers/22_transformers.html#main-example-1",
    "title": "22: Transformers",
    "section": "Main Example",
    "text": "Main Example\nLet us try running through our main example through a trained transformer\n\n\n\n\n\nDatenwissenschaft\n\n\n\n\n\n\n\n\nencoder-decoder\n\n\n\nimage credit: StatQuest"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#word-encoding",
    "href": "posts/22_transformers/22_transformers.html#word-encoding",
    "title": "22: Transformers",
    "section": "Word Encoding",
    "text": "Word Encoding\nWe start out with one-hot encoding of the input multiplied by the encoder weights:\n\\[\\begin{pmatrix} 1 & 0 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 1 & 0 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 1 & 0 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 1 & 0 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 1 & 0 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 1 & 0 \\\\ 0 & 0 & 0 & 0 & 0 & 0 & 1 \\end{pmatrix}\\begin{pmatrix} 0.34 & 0.13 \\\\ 0.23 & 0.23 \\\\ -1.12 & -0.19 \\\\ 2.21 & -0.64 \\\\ 0.46 & 0.27 \\\\ 0.53 & 0.81 \\\\ 1.11 & -1.69 \\end{pmatrix} = \\begin{pmatrix} 0.34 & 0.13 \\\\ 0.23 & 0.23 \\\\ -1.12 & -0.19 \\\\ 2.21 & -0.64 \\\\ 0.46 & 0.27 \\\\ 0.53 & 0.81 \\\\ 1.11 & -1.69 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#position-encoding-1",
    "href": "posts/22_transformers/22_transformers.html#position-encoding-1",
    "title": "22: Transformers",
    "section": "Position Encoding",
    "text": "Position Encoding\nNext, we get our position encoding values\n\n\\(n_{\\text{input}} = 7\\)\n\\(d_{\\text{model}} = 2\\)\n\n\\[\\begin{pmatrix} 0.84 & 0.54 \\\\ 0.91 & -0.42 \\\\ 0.14 & -0.99 \\\\ -0.76 & -0.65 \\\\ -0.96 & 0.28 \\\\ -0.28 & 0.96 \\\\ 0.66 & 0.75 \\end{pmatrix}\\]\nand then the word embedding plus position encoding is\n\\[\\begin{pmatrix} 0.34 & 0.13 \\\\ 0.23 & 0.23 \\\\ -1.12 & -0.19 \\\\ 2.21 & -0.64 \\\\ 0.46 & 0.27 \\\\ 0.53 & 0.81 \\\\ 1.11 & -1.69 \\end{pmatrix} + \\begin{pmatrix} 0.84 & 0.54 \\\\ 0.91 & -0.42 \\\\ 0.14 & -0.99 \\\\ -0.76 & -0.65 \\\\ -0.96 & 0.28 \\\\ -0.28 & 0.96 \\\\ 0.66 & 0.75 \\end{pmatrix} = \\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\\\ 1.77 & -0.94 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#self-attention",
    "href": "posts/22_transformers/22_transformers.html#self-attention",
    "title": "22: Transformers",
    "section": "Self-Attention",
    "text": "Self-Attention\n\nQueries\nWe find the queries by multiplying the encoded values by the transpose of the query weights:\n\\[\\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\\\ 1.77 & -0.94 \\end{pmatrix}\\begin{pmatrix} 0.07 & 0.64 \\\\ -0.70 & -0.60 \\end{pmatrix} = \\begin{pmatrix} -0.39 & 0.35 \\\\ 0.21 & 0.84 \\\\ 0.76 & 0.08 \\\\ 1 & 1.70 \\\\ -0.42 & -0.65 \\\\ -1.22 & -0.90 \\\\ 0.78 & 1.70 \\end{pmatrix}\\]\n\n\nKeys\nWe find the keys by multiplying the encoded values by the transpose of the key weights:\n\\[\\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\\\ 1.77 & -0.94 \\end{pmatrix}\\begin{pmatrix} 0.55 & -0.23 \\\\ 0.12 & 0.44 \\end{pmatrix} = \\begin{pmatrix} 0.73 & 0.02 \\\\ 0.60 & -0.35 \\\\ -0.68 & -0.29 \\\\ 0.64 & -0.90 \\\\ -0.21 & 0.36 \\\\ 0.35 & 0.72 \\\\ 0.86 & -0.82 \\end{pmatrix}\\]\n\n\nValues\nWe find the values by multiplying the encoded values by the transpose of the value weights:\n\\[\\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\\\ 1.77 & -0.94 \\end{pmatrix}\\begin{pmatrix} 0.11 & 0.08 \\\\ 0.57 & -0.22 \\end{pmatrix} = \\begin{pmatrix} 0.51 & -0.05 \\\\ 0.02 & 0.13 \\\\ -0.78 & 0.18 \\\\ -0.58 & 0.40 \\\\ 0.26 & -0.16 \\\\ 1.04 & -0.37 \\\\ -0.34 & 0.35 \\end{pmatrix}\\]\n\n\nSelf-Attention\nNow, self-attention is defined (in AI literature) as\n\\[\\text{Attention}(Q, K, V) = \\text{Softmax}\\left(\\frac{QK^{T}}{\\sqrt{d_{\\text{model}}}}\\right)V\\]\n\\[\\begin{pmatrix} 0.13 & 0.12 & 0.18 & 0.11 & 0.18 & 0.17 & 0.10 \\\\ 0.16 & 0.13 & 0.11 & 0.09 & 0.17 & 0.23 & 0.10 \\\\ 0.17 & 0.16 & 0.08 & 0.16 & 0.11 & 0.15 & 0.18 \\\\ 0.20 & 0.12 & 0.05 & 0.06 & 0.15 & 0.35 & 0.08 \\\\ 0.11 & 0.14 & 0.20 & 0.18 & 0.13 & 0.09 & 0.16 \\\\ 0.08 & 0.11 & 0.33 & 0.15 & 0.14 & 0.07 & 0.12 \\\\ 0.19 & 0.11 & 0.06 & 0.06 & 0.17 & 0.35 & 0.07 \\end{pmatrix}\\begin{pmatrix} 0.51 & -0.05 \\\\ 0.02 & 0.13 \\\\ -0.78 & 0.18 \\\\ -0.58 & 0.40 \\\\ 0.26 & -0.16 \\\\ 1.04 & -0.37 \\\\ -0.34 & 0.35 \\end{pmatrix}\\]\n\n\n\n\n\n\nSoftmax\n\n\n\nBefore multiplying by \\(V\\), the result of the softmax gives us a glimpse of how the machine views the relationship between the words. For example, in the last row for “science”, we see that “science” is most related to “data” in our input phrase.\n\n\n\\[\\text{Attention}(Q, K, V) = \\begin{pmatrix} 0.06 & 0.03 \\\\ 0.20 & -0.01 \\\\ 0.06 & 0.08 \\\\ 0.40 & -0.09 \\\\ -0.12 & 0.12 \\\\ -0.23 & 0.12 \\\\ 0.40 & -0.09 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#encoder-output",
    "href": "posts/22_transformers/22_transformers.html#encoder-output",
    "title": "22: Transformers",
    "section": "Encoder Output",
    "text": "Encoder Output\nFinally, the encoder output is the sum of the encoded values and the self-attention:\n\\[\\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\\\ 1.77 & -0.94 \\end{pmatrix} + \\begin{pmatrix} 0.06 & 0.03 \\\\ 0.20 & -0.01 \\\\ 0.06 & 0.08 \\\\ 0.40 & -0.09 \\\\ -0.12 & 0.12 \\\\ -0.23 & 0.12 \\\\ 0.40 & -0.09 \\end{pmatrix} = \\begin{pmatrix} 1.24 & 0.70 \\\\ 1.34 & -0.20 \\\\ -0.92 & -1.10 \\\\ 1.85 & -1.38 \\\\ -0.62 & 0.67 \\\\ 0.02 & 1.89 \\\\ 2.17 & -1.03 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#word-encoding-1",
    "href": "posts/22_transformers/22_transformers.html#word-encoding-1",
    "title": "22: Transformers",
    "section": "Word Encoding",
    "text": "Word Encoding\nWe start out with one-hot encoding of the input multiplied by the encoder weights:\n\\[\\begin{pmatrix} 1 & 0 & 0 & 0 & 0 & 0  \\\\ 0 & 1 & 0 & 0 & 0 & 0  \\\\ 0 & 0 & 1 & 0 & 0 & 0  \\\\ 0 & 0 & 0 & 1 & 0 & 0  \\\\ 0 & 0 & 0 & 0 & 1 & 0 & \\\\ 0 & 0 & 0 & 0 & 0 & 1  \\end{pmatrix}\\begin{pmatrix} 0.34 & 0.13 \\\\ 0.23 & 0.23 \\\\ -1.12 & -0.19 \\\\ 2.21 & -0.64 \\\\ 0.46 & 0.27 \\\\ 0.53 & 0.81 \\end{pmatrix} = \\begin{pmatrix} 0.34 & 0.13 \\\\ 0.23 & 0.23 \\\\ -1.12 & -0.19 \\\\ 2.21 & -0.64 \\\\ 0.46 & 0.27 \\\\ 0.53 & 0.81 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#position-encoding-2",
    "href": "posts/22_transformers/22_transformers.html#position-encoding-2",
    "title": "22: Transformers",
    "section": "Position Encoding",
    "text": "Position Encoding\nNext, we get our position encoding values\n\n\\(n_{\\text{output}} = 6\\)\n\\(d_{\\text{model}} = 2\\)\n\n\\[\\begin{pmatrix} 0.84 & 0.54 \\\\ 0.91 & -0.42 \\\\ 0.14 & -0.99 \\\\ -0.76 & -0.65 \\\\ -0.96 & 0.28 \\\\ -0.28 & 0.96 \\end{pmatrix}\\]\nand then the word embedding plus position encoding is\n\\[\\begin{pmatrix} 0.34 & 0.13 \\\\ 0.23 & 0.23 \\\\ -1.12 & -0.19 \\\\ 2.21 & -0.64 \\\\ 0.46 & 0.27 \\\\ 0.53 & 0.81 \\end{pmatrix} + \\begin{pmatrix} 0.84 & 0.54 \\\\ 0.91 & -0.42 \\\\ 0.14 & -0.99 \\\\ -0.76 & -0.65 \\\\ -0.96 & 0.28 \\\\ -0.28 & 0.96 \\end{pmatrix} = \\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#self-attention-2",
    "href": "posts/22_transformers/22_transformers.html#self-attention-2",
    "title": "22: Transformers",
    "section": "Self-Attention",
    "text": "Self-Attention\n\nQueries\nWe find the queries by multiplying the encoded values by the transpose of the query weights:\n\\[\\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\end{pmatrix}\\begin{pmatrix} -0.56 & -0.20 \\\\ -0.33 & -0.43 \\end{pmatrix} = \\begin{pmatrix} -0.88 & -0.52 \\\\ -0.58 & -0.15 \\\\ 0.94 & 0.70 \\\\ -0.39 & 0.26 \\\\ 0.10 & -0.14 \\\\ -0.72 & -0.81 \\end{pmatrix}\\]\n\n\nKeys\nWe find the keys by multiplying the encoded values by the transpose of the key weights:\n\\[\\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\end{pmatrix}\\begin{pmatrix} 0.07 & 0.64 \\\\ -0.70 & -0.60 \\end{pmatrix} = \\begin{pmatrix} -0.39 & 0.35 \\\\ 0.21 & 0.84 \\\\ 0.76 & 0.08 \\\\ 1 & 1.70 \\\\ -0.42 & -0.65 \\\\ -1.22 & -0.90 \\end{pmatrix}\\]\n\n\nValues\nWe find the values by multiplying the encoded values by the transpose of the value weights:\n\\[\\begin{pmatrix} 1.18 & 0.67 \\\\ 1.14 & -0.19 \\\\ -0.98 & -1.18 \\\\ 1.45 & -1.29 \\\\ \\frac{-1}{2} & 0.55 \\\\ \\frac{1}{4} & 1.77 \\end{pmatrix}\\begin{pmatrix} 0.55 & -0.23 \\\\ 0.12 & 0.44 \\end{pmatrix} = \\begin{pmatrix} 0.73 & 0.02 \\\\ 0.60 & -0.35 \\\\ -0.68 & -0.29 \\\\ 0.64 & -0.90 \\\\ -0.21 & 0.36 \\\\ 0.35 & 0.72 \\end{pmatrix}\\]\n\n\nMasked Self-Attention\nNow, masked self-attention is defined (in AI literature) as\n\\[\\text{Attention}(Q, K, V) = \\text{Softmax}\\left(\\frac{QK^{T}}{\\sqrt{d_{\\text{model}}}} + M\\right)V\\]\n\\[\\begin{pmatrix} 1 & 0 & 0 & 0 & 0 & 0 \\\\ 0.57 & 0.43 & 0 & 0 & 0 & 0 \\\\ 0.21 & 0.40 & 0.39 & 0 & 0 & 0 \\\\ 0.29 & 0.27 & 0.20 & \\frac{1}{4} & 0 & 0 \\\\ 0.19 & 0.19 & 0.21 & 0.19 & 0.21 & 0 \\\\ 0.14 & 0.08 & 0.09 & 0.03 & 0.24 & 0.43 \\end{pmatrix}\\begin{pmatrix} 0.73 & 0.02 \\\\ 0.60 & -0.35 \\\\ -0.68 & -0.29 \\\\ 0.64 & -0.90 \\\\ -0.21 & 0.36 \\\\ 0.35 & 0.72 \\end{pmatrix}\\]\n\n\n\n\n\n\nSoftmax\n\n\n\nBefore multiplying by \\(V\\), the result of the softmax gives us a glimpse of how the machine views the relationship between the words. For example, in the last row for \\(EOS\\) (“end of sequence”), we see that \\(EOS\\) is most related to \\(EOS\\) in our output phrase.\n\n\n\\[\\text{Attention}(Q, K, V) = \\begin{pmatrix} 0.73 & 0.02 \\\\ 0.60 & -0.35 \\\\ -0.68 & -0.29 \\\\ 0.64 & -0.90 \\\\ -0.21 & 0.36 \\\\ 0.35 & 0.72 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#decoder-output",
    "href": "posts/22_transformers/22_transformers.html#decoder-output",
    "title": "22: Transformers",
    "section": "Decoder Output",
    "text": "Decoder Output\nFinally, the decoder output is the sum of the encoded values and the self-attention:\n\\[\\begin{pmatrix} 0.34 & 0.13 \\\\ 0.23 & 0.23 \\\\ -1.12 & -0.19 \\\\ 2.21 & -0.64 \\\\ 0.46 & 0.27 \\\\ 0.53 & 0.81 \\end{pmatrix} + \\begin{pmatrix} 0.73 & 0.02 \\\\ 0.60 & -0.35 \\\\ -0.68 & -0.29 \\\\ 0.64 & -0.90 \\\\ -0.21 & 0.36 \\\\ 0.35 & 0.72 \\end{pmatrix} = \\begin{pmatrix} 1.91 & 0.69 \\\\ 1.82 & -0.32 \\\\ -0.85 & -1.43 \\\\ 1.84 & -1.66 \\\\ -0.31 & 0.33 \\\\ 0.45 & 2.09 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#self-attention-3",
    "href": "posts/22_transformers/22_transformers.html#self-attention-3",
    "title": "22: Transformers",
    "section": "Self-Attention",
    "text": "Self-Attention\n\nQueries\nWe find the queries by multiplying the decoder values by the transpose of the query weights:\n\\[\\begin{pmatrix} 1.91 & 0.69 \\\\ 1.82 & -0.32 \\\\ -0.85 & -1.43 \\\\ 1.84 & -1.66 \\\\ -0.31 & 0.33 \\\\ 0.45 & 2.09 \\end{pmatrix}\\begin{pmatrix} -0.56 & -0.20 \\\\ -0.33 & -0.43 \\end{pmatrix} = \\begin{pmatrix} -1.30 & -0.68 \\\\ -0.91 & -0.22 \\\\ 0.95 & 0.78 \\\\ -0.49 & 0.34 \\\\ 0.07 & -0.08 \\\\ -0.94 & -0.99 \\end{pmatrix}\\]\n\n\nKeys\nWe find the keys by multiplying the encoder values by the transpose of the key weights:\n\\[\\begin{pmatrix} 1.24 & 0.70 \\\\ 1.34 & -0.20 \\\\ -0.92 & -1.10 \\\\ 1.85 & -1.38 \\\\ -0.62 & 0.67 \\\\ 0.02 & 1.89 \\\\ 2.17 & -1.03 \\end{pmatrix}\\begin{pmatrix} 0.19 & 0.30 \\\\ -0.19 & 0.63 \\end{pmatrix} = \\begin{pmatrix} 0.23 & 1.01 \\\\ 0.41 & 0.34 \\\\ 0.11 & -1.16 \\\\ 0.67 & -0.49 \\\\ -0.12 & 0.12 \\\\ -0.31 & 1.45 \\end{pmatrix}\\]\n\n\nValues\nWe find the values by multiplying the encoder values by the transpose of the value weights:\n\\[\\begin{pmatrix} 1.24 & 0.70 \\\\ 1.34 & -0.20 \\\\ -0.92 & -1.10 \\\\ 1.85 & -1.38 \\\\ -0.62 & 0.67 \\\\ 0.02 & 1.89 \\\\ 2.17 & -1.03 \\end{pmatrix}\\begin{pmatrix} 0.41 & 0.41 \\\\ -0.31 & 0.13 \\end{pmatrix} = \\begin{pmatrix} 0.57 & 0.87 \\\\ 0.85 & 0.70 \\\\ 0.09 & -0.54 \\\\ 1.27 & 0.54 \\\\ -0.23 & -0.09 \\\\ -0.46 & 0.46 \\end{pmatrix}\\]\n\n\nSelf-Attention\nNow, self-attention is defined (in AI literature) as\n\\[\\text{Attention}(Q, K, V) = \\text{Softmax}\\left(\\frac{QK^{T}}{\\sqrt{d_{\\text{model}}}}\\right)V\\]\n\\[\\begin{pmatrix} 0.10 & 0.12 & 0.31 & 0.14 & 0.21 & 0.13 \\\\ 0.14 & 0.14 & 0.21 & 0.13 & 0.20 & 0.18 \\\\ \\frac{1}{4} & 0.19 & 0.07 & 0.15 & 0.12 & 0.22 \\\\ 0.19 & 0.15 & 0.12 & 0.11 & 0.17 & \\frac{1}{4} \\\\ 0.16 & 0.17 & 0.18 & 0.18 & 0.17 & 0.15 \\\\ 0.08 & 0.11 & 0.38 & 0.17 & 0.18 & 0.08 \\end{pmatrix}\\begin{pmatrix} 0.57 & 0.87 \\\\ 0.85 & 0.70 \\\\ 0.09 & -0.54 \\\\ 1.27 & 0.54 \\\\ -0.23 & -0.09 \\\\ -0.46 & 0.46 \\end{pmatrix}\\] \\[\\begin{pmatrix} 0.57 & 0.87 \\\\ 0.69 & 0.80 \\\\ 0.49 & \\frac{1}{4} \\\\ 0.72 & 0.47 \\\\ 0.48 & 0.27 \\\\ -0.07 & 0.31 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#encoder-decoder-output",
    "href": "posts/22_transformers/22_transformers.html#encoder-decoder-output",
    "title": "22: Transformers",
    "section": "Encoder-Decoder Output",
    "text": "Encoder-Decoder Output\nFinally, the encoder-decoder output is the sum of the decoder values and the self-attention:\n\\[\\begin{pmatrix} 1.91 & 0.69 \\\\ 1.82 & -0.32 \\\\ -0.85 & -1.43 \\\\ 1.84 & -1.66 \\\\ -0.31 & 0.33 \\\\ 0.45 & 2.09 \\end{pmatrix} + \\begin{pmatrix} 0.57 & 0.87 \\\\ 0.69 & 0.80 \\\\ 0.49 & \\frac{1}{4} \\\\ 0.72 & 0.47 \\\\ 0.48 & 0.27 \\\\ -0.07 & 0.31 \\end{pmatrix} = \\begin{pmatrix} \\frac{7}{4} & 1.54 \\\\ 1.83 & 0.61 \\\\ -0.49 & -0.93 \\\\ 2.17 & -0.82 \\\\ -0.02 & 0.82 \\\\ 0.18 & 2.08 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#weights",
    "href": "posts/22_transformers/22_transformers.html#weights",
    "title": "22: Transformers",
    "section": "Weights",
    "text": "Weights\nFor the fully-connected layer at the end of the transformer, we multiply the output of the encoder-decoder by the weights of the dense layer:\n\\[\\begin{pmatrix} \\frac{7}{4} & 1.54 \\\\ 1.83 & 0.61 \\\\ -0.49 & -0.93 \\\\ 2.17 & -0.82 \\\\ -0.02 & 0.82 \\\\ 0.18 & 2.08 \\end{pmatrix}\\begin{pmatrix} 0.36 & -0.70 & -0.54 & 0.20 & 0.22 & 0.55 \\\\ -0.43 & -0.27 & 0.58 & 0.29 & -0.01 & \\frac{-1}{2} \\end{pmatrix}\\] \\[\\begin{pmatrix} -0.03 & -1.64 & -0.05 & 0.80 & 0.37 & 0.19 \\\\ 0.40 & -1.44 & -0.63 & 0.54 & 0.40 & 0.70 \\\\ 0.22 & 0.59 & -0.27 & -0.37 & -0.10 & 0.20 \\\\ 1.14 & -1.30 & -1.65 & 0.20 & 0.49 & 1.61 \\\\ -0.36 & -0.21 & 0.49 & 0.23 & -0.01 & -0.42 \\\\ -0.83 & -0.69 & 1.11 & 0.64 & 0.02 & -0.94 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#bias",
    "href": "posts/22_transformers/22_transformers.html#bias",
    "title": "22: Transformers",
    "section": "Bias",
    "text": "Bias\nWe add the bias values to each column of the previous result:\n\\[\\begin{pmatrix} 0.01 & -2.12 & 0.17 & 0.56 & 0.59 & 0.04 \\\\ 0.44 & -1.92 & -0.41 & 0.30 & 0.62 & 0.55 \\\\ 0.26 & 0.11 & -0.05 & -0.61 & 0.12 & 0.05 \\\\ 1.18 & -1.78 & -1.43 & -0.04 & 0.71 & 1.46 \\\\ -0.32 & -0.69 & 0.71 & -0.01 & 0.21 & -0.57 \\\\ -0.79 & -1.17 & 1.33 & 0.40 & 0.24 & -1.09 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/22_transformers/22_transformers.html#softmax-2",
    "href": "posts/22_transformers/22_transformers.html#softmax-2",
    "title": "22: Transformers",
    "section": "Softmax",
    "text": "Softmax\nFinally, we apply a softmax rowwise.\n\\[\\begin{pmatrix} 0.15 & 0.02 & 0.17 & \\frac{1}{4} & 0.26 & 0.15 \\\\ 0.21 & 0.02 & 0.09 & 0.19 & \\frac{1}{4} & 0.24 \\\\ 0.21 & 0.18 & 0.16 & 0.09 & 0.19 & 0.17 \\\\ 0.30 & 0.02 & 0.02 & 0.09 & 0.19 & 0.39 \\\\ 0.12 & 0.08 & 0.34 & 0.16 & 0.20 & 0.09 \\\\ 0.06 & 0.04 & 0.49 & 0.20 & 0.17 & 0.04 \\end{pmatrix}\\]"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html",
    "href": "posts/23_LLMs/23_LLMs.html",
    "title": "23: LLMs",
    "section": "",
    "text": "Discuss encoder-only models\nDiscuss decoder-only models\nGive example of semester project\n\n\n\n\n\n\n\n301"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html#learning-objectives",
    "href": "posts/23_LLMs/23_LLMs.html#learning-objectives",
    "title": "23: LLMs",
    "section": "",
    "text": "Discuss encoder-only models\nDiscuss decoder-only models\nGive example of semester project\n\n\n\n\n\n\n\n301"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html#transformers",
    "href": "posts/23_LLMs/23_LLMs.html#transformers",
    "title": "23: LLMs",
    "section": "Transformers",
    "text": "Transformers\n\nEncoder-only: BERT\n\n\nbidirectional encoder representations from transformers\n\n\nDecoder-only: GPT\n\n\ngenerative pre-trained transformer"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html#encoders-vs-decoders",
    "href": "posts/23_LLMs/23_LLMs.html#encoders-vs-decoders",
    "title": "23: LLMs",
    "section": "Encoders vs Decoders",
    "text": "Encoders vs Decoders\n\n\n\nBERT vs GPT\n\n\n\nimage source: Ronak Verma"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html#applications",
    "href": "posts/23_LLMs/23_LLMs.html#applications",
    "title": "23: LLMs",
    "section": "Applications",
    "text": "Applications\n\nBERT\n\ntext classification\ndata labeling\nrecommender\nsentiment analysis\n\nGPT\n\ncontent generation\nconversational chatbots"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html#introduction",
    "href": "posts/23_LLMs/23_LLMs.html#introduction",
    "title": "23: LLMs",
    "section": "Introduction",
    "text": "Introduction\n\n\n\nWe hope to build a CNN to classify pictures in terms of susceptibility to color blindness\nTrained model on Ishihara data set\nRan model on novel images from the Princeton Art Museum\n\n\n\n\n\n\n\n301\n\n\n\n\n\nData Description\n\n\n\nKaggle data set by Dupeljan\nsynethetic set of 1400 Ishihara blind test cards\ndigits 0 to 9\nGoogle fonts\nfor exploring dichromacy:\n\nprotanopia\ndeuteranopia\ntritanopia\n\n\n\n\n\n\n\n\ncolor vision deficiency\n\n\n\nimage source: Male, et al., 2022\n\n\n\n\n\nLiterature Search\n\ncGANsNIRLineGAN\n\n\n\n\n\nConditional Adversarial Networks\n\nPhillip Isola, et al.\n“… learn the mapping from input image to output image, but also learn a loss function to train this mapping”\n\n\n\n\n\n\n\nIsola et al., 2018\n\n\n\n\n\n\n\n\n\nThe Potential of Diffusion-Based Near-Infrared Image Colorization\n\nBorsetelmann, et al., 2024\n“… utilizing diffusion models for the colorization of NIR images”\n\n\n\n\n\n\n\nBorsetelmann, et al., 2024\n\n\n\n\n\n\n\n\n\nLineGAN: An image colourisation method combined with a line art network\n\nDahua Lv, Yuanyuan Pu, Rencan Nie\n“LineGAN learns the corresponding colour mapping from datasets, improving the accuracy of image colourisation”\n\n\n\n\n\n\n\nLv, et al., 2022"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html#methods",
    "href": "posts/23_LLMs/23_LLMs.html#methods",
    "title": "23: LLMs",
    "section": "Methods",
    "text": "Methods\n\nExploratory Data Analysis\n\n\n\n1400 images\n531x531 pixels\n\n3 channels (RGB)\n\n45 Google fonts\npartition:\n\ntraining: 70%\ntesting: 30%\n\nstrata:\n\ntype 1: 25%\ntype 2: 25%\ntype 3: 50%\n\n\n\n\n\n\nscript.ipynb\nishihara_train_test/\n\ntraining_data/\n\ntype_1/\ntype_2/\ntype_3/\n\ntesting_data/\n\ntype_1/\ntype_2/\ntype_3/\n\n\n\n\n\n\n\n\n\n\n\nTabular Data?\n\n\n\n\n\nIf you are working with tabular data (such as a CSV file), your EDA is more conventional, and you should provide explorations such as bar graphs, histograms, and/or scatterplots along with counts and/or correlations.\n\n\n\n\n\nCNN\n\n\n\nconvolutional neural network\n\n\n\n30,000 parameters!\nimage source: NN-SVG"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html#discussion",
    "href": "posts/23_LLMs/23_LLMs.html#discussion",
    "title": "23: LLMs",
    "section": "Discussion",
    "text": "Discussion\n\nHyperparameters\n\nDeep LearningLearning RateMomentum\n\n\n\n\n\ninput: 3x32x32\n2 convolution layers\n\neach with max-pool\n\ndense layers of 400, 64, 32\noutput: 3 class labels\n\n\n\n\n\nWe increased the hidden layer sizes and the number of hidden layers in hopes of reducing the classification error.\n\n\n\n\n\nWe chose a learning rate of 0.05 based on work done on the CIFAR-10 data set.\nTODO: elaborate on larger or smaller learning rate\n\n\n\n\nWe chose a momentum of 0.9 based on the PyTorch Lightning documentation for the SGD optimizer\nTODO: elaborate on larger or smaller momentum\n\n\n\n\n\n\nResults\n\n\n\nsample of predictions\n\n\n\nclassification test error: 50%\n\nbeat random guessing (33%)\ndid not outperform majority classifier (50%)\n\n\n\n\nFuture Directions\n\nbetter data\n\nincrease data set by factor of 10\nrecenter, resize, rotations, shears\n\nmodel architecture\n\nmore hidden layers\nvary filter sizes\n\nhyperparameter search\nvalidate results\nregression model\n\ngoal: image’s susceptibility to color vision deficiency"
  },
  {
    "objectID": "posts/23_LLMs/23_LLMs.html#conclusion",
    "href": "posts/23_LLMs/23_LLMs.html#conclusion",
    "title": "23: LLMs",
    "section": "Conclusion",
    "text": "Conclusion\nTODO: summarize discussion and results\n\nCitations\n\nBorstelmann, A., Haucke, T., & Steinhage, V. (2024). “The Potential of Diffusion-Based Near-Infrared Image Colorization. Sensors”, 24(5), 1565. https://doi.org/10.3390/s24051565\nDupeljian (2021). Ishihara blind test cards. Retrieved February 2025 from https://www.kaggle.com/datasets/dupeljan/ishihara-blind-test-cards/data.\nIsola, Phillip, et al. ‘Image-to-Image Translation with Conditional Adversarial Networks’. CoRR, vol. abs/1611.07004, 2016.\nLeNail, (2019). NN-SVG: Publication-Ready Neural Network Architecture Schematics. Journal of Open Source Software, 4(33), 747, https://doi.org/10.21105/joss.00747\nLv, Dahua et al. “LineGAN: An image colourisation method combined with a line art network.” IET Computer Vision vol. 16,5, pages 403-417. 08 Mar. 2022, doi:10.1049/cvi2.12096\nMale, Shiva Ram et al. “Color vision devices for color vision deficiency patients: A systematic review and meta-analysis.” Health science reports vol. 5,5 e842. 22 Sep. 2022, doi:10.1002/hsr2.842"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html",
    "href": "posts/24_MLLMs/24_MLLMs.html",
    "title": "24: Multimodal Models",
    "section": "",
    "text": "Introduce generative adversarial networks\nIntroduce multimodal models\nFinish!\n\n\n\n\n\n\n\nCycle GANs\n\n\n\nimage credit: Jun-Yan Zhu, et al.\n\n\n\n\n\n\n\nDefinitionDall-EStable Diffusion\n\n\n\n\n\n“Generative AI is a form of artificial intelligence that is designed to generate content, including text, images, video and music. It uses large language models and algorithms to analyze patterns in datasets to mimic the style or structure of specific types of content.”\nquote and image source\n\n\n\n\n\ngenerative AI\n\n\n\n\n\n\n\n\n\nJune 2022\n\n\nimage source\n\n\n\n\n\nAugust 2023\n\n\nimage source"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#learning-objectives",
    "href": "posts/24_MLLMs/24_MLLMs.html#learning-objectives",
    "title": "24: Multimodal Models",
    "section": "",
    "text": "Introduce generative adversarial networks\nIntroduce multimodal models\nFinish!\n\n\n\n\n\n\n\nCycle GANs\n\n\n\nimage credit: Jun-Yan Zhu, et al."
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#generative-ai",
    "href": "posts/24_MLLMs/24_MLLMs.html#generative-ai",
    "title": "24: Multimodal Models",
    "section": "",
    "text": "DefinitionDall-EStable Diffusion\n\n\n\n\n\n“Generative AI is a form of artificial intelligence that is designed to generate content, including text, images, video and music. It uses large language models and algorithms to analyze patterns in datasets to mimic the style or structure of specific types of content.”\nquote and image source\n\n\n\n\n\ngenerative AI\n\n\n\n\n\n\n\n\n\nJune 2022\n\n\nimage source\n\n\n\n\n\nAugust 2023\n\n\nimage source"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#overview",
    "href": "posts/24_MLLMs/24_MLLMs.html#overview",
    "title": "24: Multimodal Models",
    "section": "Overview",
    "text": "Overview\n\n\n\nGANs overview\n\n\n\nimage source: Deep Learning Illustrated"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#discriminator",
    "href": "posts/24_MLLMs/24_MLLMs.html#discriminator",
    "title": "24: Multimodal Models",
    "section": "Discriminator",
    "text": "Discriminator\n\n\n\nTraining the discriminator\n\n\n\nimage source: Deep Learning Illustrated"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#generator",
    "href": "posts/24_MLLMs/24_MLLMs.html#generator",
    "title": "24: Multimodal Models",
    "section": "Generator",
    "text": "Generator\n\n\n\nTraining the generator\n\n\n\nimage source: Deep Learning Illustrated\n\n\n\n\n\n\n\nGAN Objectives\n\n\n\n\nthe goal of a generator is to create better fake images\nthe goal of a discriminator is to better classify fake images"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#adversarial-network",
    "href": "posts/24_MLLMs/24_MLLMs.html#adversarial-network",
    "title": "24: Multimodal Models",
    "section": "Adversarial Network",
    "text": "Adversarial Network\n\n\n\nAdversarial network\n\n\n\nimage source: Deep Learning Illustrated"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#initial-results",
    "href": "posts/24_MLLMs/24_MLLMs.html#initial-results",
    "title": "24: Multimodal Models",
    "section": "Initial Results",
    "text": "Initial Results\n\n\n\nGoodfellow, et al., 2014"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#activity-pix2pix-image-to-image",
    "href": "posts/24_MLLMs/24_MLLMs.html#activity-pix2pix-image-to-image",
    "title": "24: Multimodal Models",
    "section": "Activity: Pix2Pix Image-to-Image",
    "text": "Activity: Pix2Pix Image-to-Image\n\nAppex1ex2ex1\n\n\n\n\n\n\n\nimage-to-image\n\n\n\n\n\n\napp (link) by Christopher Hesse\nGitHub repo\n\n\n\n\n\n\n\n\nedges2cats\n\n\n\n\n\n\n\nfacades\n\n\n\n\n\n\n\nedges2handbags"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#activity-pix2pix-instruct",
    "href": "posts/24_MLLMs/24_MLLMs.html#activity-pix2pix-instruct",
    "title": "24: Multimodal Models",
    "section": "Activity: Pix2Pix Instruct",
    "text": "Activity: Pix2Pix Instruct\n\nAppex1ex2ex3\n\n\n\n\n\n\n\npix2pix\n\n\n\n\n\n\napp (link) by Tim Brooks\nGitHub repo\n\n\n\n\n\n\n\n\n\n\nNew Jersey flag\n\n\n\n\n\n\n\n\nconvert to grayscale\n\n\n\n\n\n\n\n\n\n\n\nNew Jersey flag\n\n\n\n\n\n\n\n\nadd more horses\n\n\n\n\n\n\n\n\n\n\n\nNew Jersey flag\n\n\n\n\n\n\n\n\nreplace humans with ramen"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#architecture",
    "href": "posts/24_MLLMs/24_MLLMs.html#architecture",
    "title": "24: Multimodal Models",
    "section": "Architecture",
    "text": "Architecture\n\n\n\nZhang, et al., 2016"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#scaling",
    "href": "posts/24_MLLMs/24_MLLMs.html#scaling",
    "title": "24: Multimodal Models",
    "section": "Scaling",
    "text": "Scaling\n\n\n\nZhang, et al., 2016"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#architecture-1",
    "href": "posts/24_MLLMs/24_MLLMs.html#architecture-1",
    "title": "24: Multimodal Models",
    "section": "Architecture",
    "text": "Architecture\n\n\n\n\ncycle GAN architecture\n\n\n\nimages source: Bansal and Rathore\n\n\n\n\n\n\n\ncGAN Objective\n\n\n\nIn a cyclic GAN, the generator and discriminator converge toward a Nash equilibrium."
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#vq-vae",
    "href": "posts/24_MLLMs/24_MLLMs.html#vq-vae",
    "title": "24: Multimodal Models",
    "section": "VQ-VAE",
    "text": "VQ-VAE\nVector quantized variational autoencoders (VQ-VAE) utilize an discrete embedding space\n\nfor example: 32x32 embedding space of vectors\n\n\n\n\nVQ-VAE\n\n\n\nimage source"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#text",
    "href": "posts/24_MLLMs/24_MLLMs.html#text",
    "title": "24: Multimodal Models",
    "section": "Text",
    "text": "Text\n\n\n\ntokenization of text\n\n\n\nimage source: Murilo Gustineli"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#images",
    "href": "posts/24_MLLMs/24_MLLMs.html#images",
    "title": "24: Multimodal Models",
    "section": "Images",
    "text": "Images\n\nVectorizationPositional Encoding\n\n\n\n\n\n\n\ntokenization of images\n\n\n\n\n\n\nimages are partitioned into patches\neach patch is flattened into a vector\nimage source: Shusen Wang\n\n\n\n\n\n\n\n\npositional encoding of patches\n\n\n\nimage source: Shusen Wang"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#audio",
    "href": "posts/24_MLLMs/24_MLLMs.html#audio",
    "title": "24: Multimodal Models",
    "section": "Audio",
    "text": "Audio\n\nAbstractionMusicFourierTrends\n\n\n\n\n\naudio abstraction\n\n\n\nimage source: Valerio Velardo\n\n\n\n\nbeat\ntimbre\npitch\nharmony\n…\nsource: Valerio Velardo\n\n\n\n\n\n\nsignal domain\n\n\n\nimage source: Valerio Velardo\n\n\n\n\ndigital signal processing \\(\\rightarrow\\) rule-based systems\ntraditional ML \\(\\rightarrow\\) feature engineering\ndeep learning \\(\\rightarrow\\) automatic feature engineering\nsource: Valerio Velardo"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#clip",
    "href": "posts/24_MLLMs/24_MLLMs.html#clip",
    "title": "24: Multimodal Models",
    "section": "CLIP",
    "text": "CLIP\nContrastive Language Image Pre-Training\n\n\n\nCLIP architecture\n\n\n\nimage source: Chip Huyen"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#vision-neurons",
    "href": "posts/24_MLLMs/24_MLLMs.html#vision-neurons",
    "title": "24: Multimodal Models",
    "section": "Vision Neurons",
    "text": "Vision Neurons\n\n\n\nvision neurons\n\n\n\n\n\nvision neurons\n\n\n\nimage source: dstill.pub"
  },
  {
    "objectID": "posts/24_MLLMs/24_MLLMs.html#audio-example",
    "href": "posts/24_MLLMs/24_MLLMs.html#audio-example",
    "title": "24: Multimodal Models",
    "section": "Audio Example",
    "text": "Audio Example\nVideo game streamer Jesse Cox tried out a generative AI program that was specifically built to create music and lyrics. Here is a theme song for constipation medicine"
  },
  {
    "objectID": "code/Hello_World.html",
    "href": "code/Hello_World.html",
    "title": "SML 301 Slides",
    "section": "",
    "text": "print(\"Hello World!\")\n\nHello World!"
  },
  {
    "objectID": "code/01_introduction.html",
    "href": "code/01_introduction.html",
    "title": "SML 301: Data Intelligence",
    "section": "",
    "text": "In these code chunks, we will briefly talk about\n\ninstalling libraries\nregression and classification\nsample statistics\n\n\n# If need be, install the following packages\n#%pip install numpy\n#%pip install pandas\n#%pip install sklearn"
  },
  {
    "objectID": "code/01_introduction.html#lecture-1-introduction",
    "href": "code/01_introduction.html#lecture-1-introduction",
    "title": "SML 301: Data Intelligence",
    "section": "",
    "text": "In these code chunks, we will briefly talk about\n\ninstalling libraries\nregression and classification\nsample statistics\n\n\n# If need be, install the following packages\n#%pip install numpy\n#%pip install pandas\n#%pip install sklearn"
  },
  {
    "objectID": "code/01_introduction.html#python-tutorial",
    "href": "code/01_introduction.html#python-tutorial",
    "title": "SML 301: Data Intelligence",
    "section": "Python tutorial",
    "text": "Python tutorial\nTo the best of your present knowledge, what do each of the following lines of Python code do? What is the code output (if applicable)?\n\nsection 2.3.3 of Introduction to Statistical Learning in Python\n\nLeave a comment by each line of code in the following code chunk. The first one has been done already.\n\nimport numpy as np #import numpy library and alias as np\nx = np.array([3, 4, 5])\ny = np.array([4, 9, 7])\nx + y\n\nx = np.array([[1, 2], [3, 4]])\nx.ndim\nx.shape\n\nx.dtype\nnp.array([[1, 2], [3.0, 4]]).dtype\n\nx = np.array([1, 2, 3, 4])\nx.sum()\nx**2\nx**0.5\n\n\n# Load libraries\nimport pandas as pd\n\nfrom sklearn import datasets\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\nfrom sklearn.datasets import make_regression\nfrom sklearn.preprocessing import StandardScaler"
  },
  {
    "objectID": "code/01_introduction.html#regression",
    "href": "code/01_introduction.html#regression",
    "title": "SML 301: Data Intelligence",
    "section": "Regression",
    "text": "Regression\nThe following code comes from the Python Cookbook\n\nfeatures, target = make_regression(n_samples = 100,\n                                  n_features = 3,\n                                  n_informative = 2,\n                                  n_targets = 1,\n                                  noise = 0.2,\n                                  coef = False,\n                                  random_state = 301)\n\nregression_model = LinearRegression()\nmodel = regression_model.fit(features, target)\n\n# regression: predicts a number\nmodel.predict(features)[0]"
  },
  {
    "objectID": "code/01_introduction.html#classification",
    "href": "code/01_introduction.html#classification",
    "title": "SML 301: Data Intelligence",
    "section": "Classification",
    "text": "Classification\nThe following code comes from the Python Cookbook\n\niris = datasets.load_iris()\nfeatures = iris.data[:100, :]\ntarget = iris.target[:100]\n\nscaler = StandardScaler()\nfeatures_standardized = scaler.fit_transform(features)\n\nlogistic_model = LogisticRegression(random_state = 301)\nmodel = logistic_model.fit(features_standardized, target)\n\n# classification: predict a label\nnew_observation = [[0.5, 0.5, 0.5, 0.5]]\nmodel.predict(new_observation)\n#model.predict_proba(new_observation)"
  },
  {
    "objectID": "code/01_introduction.html#sample-statistics",
    "href": "code/01_introduction.html#sample-statistics",
    "title": "SML 301: Data Intelligence",
    "section": "Sample Statistics,",
    "text": "Sample Statistics,\nLet us try to summarize how long some SML 301 assignments take\n\nsurvey_data = pd.read_csv(\"https://raw.githubusercontent.com/dsollberger/sml301slides/refs/heads/main/data/SML301_durations.csv\")\nsurvey_data.head()\n\n\n# How long, in minutes, did the shortest precept assignment take?\nsurvey_data.shortest_precept.describe()\n\n\n# How long, in minutes, did the longest precept assignment take?\nsurvey_data.longest_precept.describe()\n\n\n# How long, in hours, did the midsemester project take?\nsurvey_data.midsemester_project.describe()"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html",
    "href": "posts/02_linear_regression/02_regression.html",
    "title": "3: Regression",
    "section": "",
    "text": "Goal: Foray into regression\nObjective: Implement various linear regression models"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#start",
    "href": "posts/02_linear_regression/02_regression.html#start",
    "title": "3: Regression",
    "section": "",
    "text": "Goal: Foray into regression\nObjective: Implement various linear regression models"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#scatterplot",
    "href": "posts/02_linear_regression/02_regression.html#scatterplot",
    "title": "3: Regression",
    "section": "Scatterplot",
    "text": "Scatterplot\nExample: Can we predict the bill_length of a penguin whose body_mass is 5 kg?"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#best-fit-line",
    "href": "posts/02_linear_regression/02_regression.html#best-fit-line",
    "title": "3: Regression",
    "section": "Best-Fit Line",
    "text": "Best-Fit Line\n\n\n\n\n\n\n\n\n\n\nlin_fit &lt;- lm(bill_length_mm ~ body_mass_g, data = penguins)\ny_pred &lt;- predict(lin_fit, newdata = data.frame(body_mass_g = 5000))"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#prediction",
    "href": "posts/02_linear_regression/02_regression.html#prediction",
    "title": "3: Regression",
    "section": "Prediction",
    "text": "Prediction"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#commentary",
    "href": "posts/02_linear_regression/02_regression.html#commentary",
    "title": "3: Regression",
    "section": "Commentary",
    "text": "Commentary\n\n\n\nHow reliable is the prediction?\nHow reliable is the [linear] model?\nCan we deploy a different model?\nDo we have all of the data, or just a sample?\n\nDoes this prediction apply to all similar penguins?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDCP1\n\n\n\n\n\nDCP1"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#residuals-1",
    "href": "posts/02_linear_regression/02_regression.html#residuals-1",
    "title": "3: Regression",
    "section": "Residuals",
    "text": "Residuals\nA residual is the difference between a predicted value and its true value."
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#method-of-least-squares",
    "href": "posts/02_linear_regression/02_regression.html#method-of-least-squares",
    "title": "3: Regression",
    "section": "Method of Least Squares",
    "text": "Method of Least Squares\nIdea: The best-fit line is where the sum-of-squared residuals is minimized.\n\\[E(a,b) = \\sum_{i=1}^{n} (y_{i} - a - bx_{i})^{2}\\]\nClaim: \\[a = \\frac{ (\\sum y_{i})(\\sum x_{i}^{2}) - (\\sum x_{i})(\\sum x_{i}y_{i}) }{ n\\sum x_{i}^{2} - (\\sum x_{i})^{2} }, \\quad b = \\frac{ n\\sum x_{i}y_{i} - (\\sum x_{i})(\\sum y_{i}) }{ n\\sum x_{i}^{2} - (\\sum x_{i})^{2} }\\]\n\n\n\n\n\n\n(optional) Proof\n\n\n\n\n\nSearch for a critical point by setting the partial derivatives (along with the Chain Rule) equal to zero.\n\\[0 = \\frac{\\partial E}{\\partial a} = -2\\sum_{i = 1}^{n} (y_{i} - a - bx_{i}) = 2an + 2b\\sum_{i = 1}^{n}x_{i} - 2\\sum_{i = 1}^{n} y_{i}\\] \\[0 = \\frac{\\partial E}{\\partial b} = -2\\sum_{i = 1}^{n} (y_{i} - a - bx_{i})x_{i} = 2a\\sum_{i = 1}^{n}x_{i} + 2b\\sum_{i = 1}^{n}x_{i}^{2} - 2\\sum_{i = 1}^{n} x_{i}y_{i}\\]\nCreate a matrix system of equations.\n\\[\\left[  \\begin{array}{cc}\n  n & \\sum_{i = 1}^{n}x_{i} \\\\\n  \\sum_{i = 1}^{n}x_{i} & \\sum_{i = 1}^{n}x_{i}^{2} \\\\\n  \\end{array}\\right]\n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right]\n  =\n  \\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right]\n  \\]\nEmploy a matrix inverse.\n$$\n\\[\\begin{array}{rcl}\n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = &\n  \\left[  \\begin{array}{cc}\n  n & \\sum_{i = 1}^{n}x_{i} \\\\\n  \\sum_{i = 1}^{n}x_{i} & \\sum_{i = 1}^{n}x_{i}^{2} \\\\\n  \\end{array}\\right]^{-1}\\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right] \\\\\n  \n  ~ & ~ & ~ \\\\\n  \n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = & \\frac{1}{n\\sum x_{i}^{2} - (\\sum x_{i})^{2}} \\left[  \\begin{array}{cc}\n  \\sum_{i = 1}^{n}x_{i}^{2} & -\\sum_{i = 1}^{n}x_{i} \\\\\n  -\\sum_{i = 1}^{n}x_{i} & n \\\\\n  \\end{array}\\right]  \\left[  \\begin{array}{c}  \\sum_{i = 1}^{n} y_{i} \\\\ \\sum_{i = 1}^{n} x_{i}y_{i} \\end{array}\\right] \\\\\n  \n  ~ & ~ & ~ \\\\\n  \n  \\left[  \\begin{array}{c}  a \\\\ b \\end{array}\\right] & = & \\frac{1}{n\\sum x_{i}^{2} - (\\sum x_{i})^{2}}\n  \\left[  \\begin{array}{c}  (\\sum y_{i})(\\sum x_{i}^{2}) - (\\sum x_{i})(\\sum x_{i}y_{i}) \\\\  n\\sum x_{i}y_{i} - (\\sum x_{i})(\\sum y_{i}) \\end{array}\\right] \\\\\n\\end{array}\\]\n$$"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#polynomial-regression",
    "href": "posts/02_linear_regression/02_regression.html#polynomial-regression",
    "title": "3: Regression",
    "section": "Polynomial Regression",
    "text": "Polynomial Regression\n\\(d = 2: \\hat{y} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{1}^{2}\\)\n\\(d = 3: \\hat{y} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{1}^{2} + \\beta_{3}X_{1}^{3}\\)\n\n\n\n\n\n\nDegree is a hyperparameter\n\n\n\nFor polynomial regression, the degree \\(d\\) is a hyperparameter.\n\nparameters: \\(\\beta_{0}, \\beta_{1}, \\beta_{2}, ...\\)\nhyperparametr: \\(d\\)"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#ridge-regression",
    "href": "posts/02_linear_regression/02_regression.html#ridge-regression",
    "title": "3: Regression",
    "section": "Ridge Regression",
    "text": "Ridge Regression"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#ridge-regression-1",
    "href": "posts/02_linear_regression/02_regression.html#ridge-regression-1",
    "title": "3: Regression",
    "section": "Ridge Regression",
    "text": "Ridge Regression\n\\(\\hat{y} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\alpha\\sum_{i = 1}^{2} \\beta_{i}^{2}\\)\nwhere \\(\\alpha &gt; 0\\) is the penalization coefficient.\n\nridge regression is also called L2 penalization"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#lasso-regression",
    "href": "posts/02_linear_regression/02_regression.html#lasso-regression",
    "title": "3: Regression",
    "section": "LASSO Regression",
    "text": "LASSO Regression\n\\(\\hat{y} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\alpha\\sum_{i = 1}^{2} |\\beta_{i}|\\)\nwhere \\(\\alpha &gt; 0\\) is the penalization coefficient.\n\nLASSO regression (least absolute shrinkage and selection operator) is also called L1 penalization"
  },
  {
    "objectID": "posts/02_linear_regression/02_regression.html#elastic-net",
    "href": "posts/02_linear_regression/02_regression.html#elastic-net",
    "title": "3: Regression",
    "section": "Elastic Net",
    "text": "Elastic Net\nFor these penalized linear models, we proceed to elastic net, which is a linear combination of the previous ridge and LASSO ideas.\n\\(\\hat{y} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\alpha[L\\sum_{i = 1}^{2} \\beta_{i}^{2}+ (1-L)\\sum_{i = 1}^{2} |\\beta_{i}|]\\)\n\n\\(\\alpha\\): penalization coefficient\n\\(L\\): \\(L1\\) ratio"
  },
  {
    "objectID": "code/02_linear_regression.html",
    "href": "code/02_linear_regression.html",
    "title": "SML 301",
    "section": "",
    "text": "linear regression\nmodel diagnostics\ntrain-test split\npolynomial regression\nmultilinear regression\npenalization\n\nRemember to “Save Copy to Drive” to use your own cloud space.\n\n# install packages (if need be)\n# %pip install palmerpenguins\n\n\n# load libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom palmerpenguins import load_penguins\nfrom scipy import stats\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Princeton colors\n# orange on white: #e77500\n# orange on black: #f58025\n\n# load data\npenguins = load_penguins()\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "code/02_linear_regression.html#session-2-linear-regression",
    "href": "code/02_linear_regression.html#session-2-linear-regression",
    "title": "SML 301",
    "section": "",
    "text": "linear regression\nmodel diagnostics\ntrain-test split\npolynomial regression\nmultilinear regression\npenalization\n\nRemember to “Save Copy to Drive” to use your own cloud space.\n\n# install packages (if need be)\n# %pip install palmerpenguins\n\n\n# load libraries\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom palmerpenguins import load_penguins\nfrom scipy import stats\nfrom sklearn import linear_model\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import PolynomialFeatures\n\n# Princeton colors\n# orange on white: #e77500\n# orange on black: #f58025\n\n# load data\npenguins = load_penguins()\npenguins.head()\n\n\n\n\n\n\n\n\nspecies\nisland\nbill_length_mm\nbill_depth_mm\nflipper_length_mm\nbody_mass_g\nsex\nyear\n\n\n\n\n0\nAdelie\nTorgersen\n39.1\n18.7\n181.0\n3750.0\nmale\n2007\n\n\n1\nAdelie\nTorgersen\n39.5\n17.4\n186.0\n3800.0\nfemale\n2007\n\n\n2\nAdelie\nTorgersen\n40.3\n18.0\n195.0\n3250.0\nfemale\n2007\n\n\n3\nAdelie\nTorgersen\nNaN\nNaN\nNaN\nNaN\nNaN\n2007\n\n\n4\nAdelie\nTorgersen\n36.7\n19.3\n193.0\n3450.0\nfemale\n2007"
  },
  {
    "objectID": "code/02_linear_regression.html#scatterplot",
    "href": "code/02_linear_regression.html#scatterplot",
    "title": "SML 301",
    "section": "Scatterplot",
    "text": "Scatterplot\nA scatterplot shows two numerical variables, and we then add code to plot a best-fit line for linear regression.\nIn this first example, we try to predict a penguin’s bill length based on its body mass.\n\npenguins_subset = penguins[[\"bill_length_mm\", \"body_mass_g\"]] #subset with just the variables that we need\npenguins_subset = penguins_subset.dropna()                    #then remove missing data\nX = penguins_subset[\"body_mass_g\"]\ny = penguins_subset[\"bill_length_mm\"]\n\n\n# https://python-graph-gallery.com/scatterplot-with-regression-fit-in-matplotlib/\n# # Initialize layout\nfig, ax = plt.subplots(figsize=(7, 7))\n\n# Add scatterplot\nax.scatter(X, y, s=50, alpha=0.5, edgecolors=\"#000000\")\n\n# Add best-fit line\nb, a = np.polyfit(X, y, deg = 1)\nxseq = np.linspace(min(X), max(X), num = 301)\nax.plot(xseq, a + b*xseq, color = \"#e77500\", lw = 3)\n\n# Label plot\nax.set_title(\"Linear Regression\")\nax.set_xlabel(\"bill length (mm)\")\nax.set_ylabel(\"body mass (g)\")\n\nText(0, 0.5, 'body mass (g)')\n\n\n\n\n\n\n\n\n\n\npenguins_subset = penguins[[\"bill_length_mm\", \"body_mass_g\"]] #subset with just the variables that we need\npenguins_subset = penguins_subset.dropna()                    #then remove missing data\nX = penguins_subset[[\"body_mass_g\"]]                          #later: needs to be a 2D array\ny = penguins_subset[\"bill_length_mm\"]\n\n# linear regression modeling (via scikit-learn)\nmodel = LinearRegression().fit(X, y)\n\nLinear regression math model:\n\\(y = \\beta_{0} + \\beta_{1}X_{1}\\)\n\n# show model coefficients\nprint(\"beta_0:\", model.intercept_)\nprint(\"beta_1:\", model.coef_)\n\nbeta_0: 26.898872423598547\nbeta_1: [0.00405142]"
  },
  {
    "objectID": "code/02_linear_regression.html#ridge-regression",
    "href": "code/02_linear_regression.html#ridge-regression",
    "title": "SML 301",
    "section": "Ridge Regression",
    "text": "Ridge Regression\n\\(\\hat{y} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\alpha\\sum_{i = 1}^{2} \\beta_{i}^{2}\\)\nwhere \\(\\alpha &gt; 0\\) is the penalization coefficient.\n\nridge regression is also called L2 penalization\n\n\nridge_grid = RidgeCV(alphas = [0.001, 0.01, 0.1, 1.0, 10.0, 100, 1000])\nmodel = ridge_grid.fit(X_train, y_train)\n\n# show model coefficients\nprint(\"alpha:\", model.alpha_)\nprint(\"beta_0:\", model.intercept_)\nprint(\"betas:\", model.coef_)\n\ny_pred = model.predict(X_test)\nmodel_MSE = mean_squared_error(y_test, y_pred)\nprint(f'test MSE: {model_MSE:.4f}')\n\nalpha: 100.0\nbeta_0: -3.244404996952511\nbetas: [0.0004543  0.22526271]\ntest MSE: 16.4630"
  },
  {
    "objectID": "code/02_linear_regression.html#lasso-regression",
    "href": "code/02_linear_regression.html#lasso-regression",
    "title": "SML 301",
    "section": "LASSO Regression",
    "text": "LASSO Regression\n\\(\\hat{y} = \\beta_{0} + \\beta_{1}X_{1} + \\beta_{2}X_{2} + \\alpha\\sum_{i = 1}^{2} |\\beta_{i}|\\)\nwhere \\(\\alpha &gt; 0\\) is the penalization coefficient.\n\nLASSO regression (least absolute shrinkage and selection operator) is also called L1 penalization\n\n\nlasso_grid = LassoCV(alphas = [0.001, 0.01, 0.1, 1.0, 10.0, 100, 1000])\nmodel = lasso_grid.fit(X_train, y_train)\n\n# show model coefficients\nprint(\"alpha:\", model.alpha_)\nprint(\"beta_0:\", model.intercept_)\nprint(\"betas:\", model.coef_)\n\ny_pred = model.predict(X_test)\nmodel_MSE = mean_squared_error(y_test, y_pred)\nprint(f'test MSE: {model_MSE:.4f}')\n\nalpha: 0.1\nbeta_0: -3.225590182288883\nbetas: [0.00045654 0.22512234]\ntest MSE: 16.4627"
  }
]