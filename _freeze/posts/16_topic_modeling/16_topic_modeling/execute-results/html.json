{
  "hash": "ebc5f89cd8db918c39cb205a73496774",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"16: Topic Modeling\"\nauthor: \"Derek Sollberger\"\ndate: \"2025-11-03\"\nformat:\n  html:\n    toc: true\n---\n\n\n\n\n# Session 16: Topic Modeling\n\n## Learning objectives:\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n- Review convolutions\n- Discuss Bots++\n- Introduce topic modeling\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n![topic modeling](datamapplot.png)\n\n* image source: [Maarten Grootendorst](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models)\n\n:::\n\n::::\n\n# Review: Convolutions\n\n## Math\n\n> discrete convolution\n\n$$(f * g)[n] = \\displaystyle\\sum_{m = -\\infty}^{\\infty} f[m]g[n-m]$$\n\n> continuous convolution\n\n$$(f * g)(t) = \\displaystyle\\int_{-\\infty}^{\\infty} f(\\tau)g(t-\\tau) \\, d\\tau$$\n\n## Spatial Convolution\n\n![spatial convolution](convolution_animation.gif)\n\n* image source: [spatial-lang.org](https://spatial-lang.org/conv)\n\n## Max Pool\n\n![max pool](cnn_max_pool.png)\n\n* image source: [Dhanush Kumar](https://medium.com/@danushidk507/max-pooling-ef545993b6e4)\n\n## Edge Detection\n\n> first derivative\n\n$$f'(x) = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}$$\n\n> second derivative\n\n$$\\begin{array}{rcl}\n  f''(x) & \\approx & \\frac{\\frac{f(x + h) - f(x)}{h} - \\frac{f(x) - f(x-h)}{h}}{h} \\\\\n  ~ & = & \\frac{f(x + h) - 2f(x) + f(x - h)}{h^{2}} \\\\\n\\end{array}$$\n\n![edge detection](Edge-detection-filters-in-edge-detection-layers.png)\n\n* image source: [Jaemin Jeong, et al](https://www.researchgate.net/publication/348490048_Filter_combination_learning_for_CNN_model_compression)\n\n::: {.callout-warning}\n## DCP1\n:::\n\n# BERT\n\n## Transformers\n\n* Encoder-only: BERT\n\n> bidirectional encoder representations from transformers\n\n* Decoder-only: GPT\n\n> generative pre-trained transformer\n\n## Encoders vs Decoders\n\n![BERT vs GPT](BERT_vs_GPT.png)\n\n* image source: [Ronak Verma](https://www.linkedin.com/pulse/bert-vs-gpt-which-better-llm-model-ronak-verma-xeixc/)\n\n## Applications\n\n* BERT\n\n    * text classification\n    * data labeling\n    * recommender\n    * sentiment analysis\n    \n* GPT\n\n    * content generation\n    * conversational chatbots\n\n::: {.callout-warning}\n## DCP2\n:::\n\n# BERTopic\n\n![BERTopic modularity](BERTopic_modularity.png)\n\n* image source: [Maarten Grootenhorst](https://maartengr.github.io/BERTopic/algorithm/algorithm.html#visual-overview)\n\n# Bots++\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n> Bots++ is an AI-powered chatbot designed to enhance student engagement and streamline communication in Canvas courses. By integrating Bots++ into your course site, students can ask questions about course content and receive accurate, instructor-curated responses in real time. This tool helps reduce repetitive inquiries, supports students in navigating course materials, and fosters a more interactive learning environment.\n\n---[Canvas at Yale](https://help.canvas.yale.edu/a/1909054-ed-discussions-adding-an-ai-chatbot-with-bots)\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n![Ed Discussion example](Bots_pp_example.png)\n\n* image source: Princeton McGraw Center\n:::\n\n::::\n\n::: {.callout-warning}\n## DCP3\n:::\n\n# Derek's AI Projects\n\n::::: {.panel-tabset}\n\n## project 1\n\n### Longitudinal Sentiment Analysis\n\n![Hamilton, et al](Hamilton_topics.png)\n\n## project 2\n\n### Abstract Topic Modeling\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n![BERTopic](BERT_topic.png)\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"30%\"}\norganize topics from abstracts from\n\n* Journal of Data Science Education\n* Journal of Biology Education\n\nImage credit: [Ashwin Rachha](https://medium.com/@ashwin_rachha/topic-modeling-with-quantized-large-language-models-llms-a-comprehensive-guide-9331c6936073)\n\n:::\n\n::::\n\n## project 3\n\n### Home Economics\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n![receipt bookkeeping](receipts.png)\n\n* image source: [Recycle This Pittsburgh](https://recyclethispgh.com/item/paper-receipts/)\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n* scan grocery receipts\n* OCR\n* AI text decoding\n* code expense report\n\n:::\n\n::::\n\n## project 4\n\n### Foreign Language Tutor\n\n:::: {.columns}\n\n::: {.column width=\"50%\"}\n![proficiency levels](German_language_levels.png)\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"40%\"}\nLLM prompting. \"I am at the A2 level in German.  Help me advance to B1.\"\n\n* organize vocabulary words\n* create lesson plans\n* make quizzes\n\nImage credit: [Smarter German](https://smartergerman.com/blog/german-language-levels/)\n:::\n\n::::\n\n## project 5\n\n### Color Sensitivity\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n#### Setup\n\n- We hope to build a CNN to classify pictures in terms of susceptibility to color blindness\n- Trained model on Ishihara data set\n- Run model on novel images from the Princeton Art Museum\n\n![301](ishihara_example_301.png)\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n#### Future Directions\n\n* better data\n\n    * increase data set by factor of 10\n    * recenter, resize, rotations, shears\n\n* model architecture\n\n    * more hidden layers\n    * 3D convolutions\n    * vary filter sizes\n    \n* hyperparameter search\n\n* validate results\n\n* regression model\n\n    * goal: image's susceptibility to color vision deficiency\n:::\n\n::::\n\n:::::\n\n::: {.callout-warning}\n## DCP3\n:::\n\n::: {.callout-tip collapse=\"true\"}\n# Job Searches\n\nIf you are applying for jobs/internships, I (Derek) am willing to volunteer as a job reference.\n\nExamples:\n\n* SML 201 (Fall 2024)\n\n    * undergrad student internship in Germany\n    \n        * bioinformatics\n    \n* SML 301 (Spring 2025)\n\n    * alum ML engineer at NYC AI think-tank\n    \n        * medical AI\n\n:::\n\n\n\n\n\n# Quo Vadimus?\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n* due this Friday (Nov 7):\n\n    - Precept 8 (1 hour)\n    - Literature review:\n        - Multipass: LR (1 of 2) (20 minutes)\n        - Multipass: LR (2 of 2) (20 minutes)\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n\nOur SML 301 lecture session for **Monday, November 24** will be remote (Zoom).\n\n* guest speaker from AI industry\n\n:::\n\n::::\n\n\n# Footnotes\n\n::: {.callout-note collapse=\"true\"}\n\n## (optional) Additional Resources and References\n\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Session Info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.5.1 (2025-06-13 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.5.1       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.50        jsonlite_2.0.0    xfun_0.52        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.4   \n```\n\n\n:::\n:::\n\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n:::\n\n::::\n\n::::: {.panel-tabset}\n\n\n\n:::::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}