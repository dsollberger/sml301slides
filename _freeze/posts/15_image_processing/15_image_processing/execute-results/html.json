{
  "hash": "2d7eb1ad7e1566785af588a2e16f16f5",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"15: Image Processing\"\nauthor: \"Derek Sollberger\"\ndate: \"2025-10-29\"\nformat:\n  html:\n    toc: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n# Session 15: Image Processing\n\n## Learning objectives:\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n- Review calculations in neural networks\n- Explore image processing\n- Introduce image augmentation\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n![image processing](princeton_tiger_nobg.png)\n:::\n\n::::\n\n# Preprocessing: Min-Max Normalization\n\n## motivation\n\nFor 32-bit float number representation\n\n![floating-point representation](Float_example.svg.png)\n\n* range: $(1.1755 \\times 10^{-38}, 1.7014 \\times 10^{38})$\n\nAnticipating neural networks and performing many calculations, we want to avoid overflow or underflow errors.\n\n::: {.callout-tip}\n\n## Preprocessing Numbers\n\nTo make the numerical inputs and outputs more manageable, we will employ\n\n* min-max normalization\n* softmax\n\n:::\n\n::::: {.panel-tabset}\n\n## scene\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](15_image_processing_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n## formula\n\nWe want numerical inputs to be between 0 and 1, so we can employ **min-max normalization**:\n\n$$\\text{scaled}(x) = \\frac{x - \\text{min}}{\\text{max} - \\text{min}}$$\n\n\n\n::: {.cell}\n\n:::\n\n\n\n## rescaled\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](15_image_processing_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n\n## bases\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](15_image_processing_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n:::::\n\n# Forward Propogation\n\n## Trained Model\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n```{mermaid}\nflowchart LR\n\ninput_1[flipper length]\ninput_2[body mass]\noutput_1[Adelie]\noutput_2[Chinstrap]\noutput_3[Gentoo]\n\ninput_1 -- -1.16A + 0.38 --> output_1\ninput_1 -- 0.24A - 0.38 --> output_2\ninput_1 -- 1.77A + 0.16 --> output_3\ninput_2 -- -0.05B + 0.38 --> output_1\ninput_2 -- 0.18B - 0.38 --> output_2\ninput_2 -- 1.07B + 0.16 --> output_3\n```\n\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n* input layer size: 2\n* output layer size: 3\n* **fully-connected network**: every output is connected to every input by an edge\n\n    * here: no hidden layer\n    * later: LSTM, transformers, encoder-decorders\n:::\n\n::::\n\n::: {.callout-tip}\n## Where did the coefficients come from?\n\nWe will train the neural network and compute the weights and bias values soon!  For now, let us see how the forward calculations work in this trained model.\n:::\n\n::: {.callout-warning collapse=\"true\"}\n\n## These will be poor results\n\nThe examples in today's session will have poor results (i.e. accuracy values close to 50 percent).  This is because of\n\n* small data sets\n* models run for a limited number of epochs (iterations)\n\n:::\n\n## Parameters\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n```{mermaid}\nflowchart LR\n\ninput_1[flipper length]\ninput_2[body mass]\noutput_1[Adelie]\noutput_2[Chinstrap]\noutput_3[Gentoo]\n\ninput_1 -- -1.16A + 0.38 --> output_1\ninput_1 -- 0.24A - 0.38 --> output_2\ninput_1 -- 1.77A + 0.16 --> output_3\ninput_2 -- -0.05B + 0.38 --> output_1\ninput_2 -- 0.18B - 0.38 --> output_2\ninput_2 -- 1.07B + 0.16 --> output_3\n```\n\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\nThis model has 9 parameters:\n\n* weights\n\n$$\\begin{array}{rcr}\n  w_{1,1} & \\approx & -1.16 \\\\\n  w_{1,2} & \\approx & 0.24 \\\\\n  w_{1,3} & \\approx & 1.77 \\\\\n  w_{2,1} & \\approx & -0.05 \\\\\n  w_{2,2} & \\approx & 0.18 \\\\\n  w_{2,3} & \\approx & 1.07 \\\\\n\\end{array}$$\n\n* bias\n\n$$\\begin{array}{rcr}\n  b_{1} & \\approx & 0.76 \\\\\n  b_{2} & \\approx & -0.76 \\\\\n  b_{3} & \\approx & 0.32 \\\\\n\\end{array}$$\n\n:::\n\n::::\n\n::: {.callout-tip}\n## Split Bias?\n\nEditor's note: for the sake of simplifying the diagram, the bias values were split in half (two input variables).  In practice, the bias values are added after the weight multiplications.  This will be more apparent in the matrix computations later.  Furthermore, the values going into the output nodes are also added together.\n:::\n\n## Obvious Example\n\nWhat will our model predict for a Gentoo penguin whose measurements (after min-max normalization) include a flipper length of 0.75 and a body mass of 0.75?\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n```{mermaid}\nflowchart LR\n\ninput_1[0.75]\ninput_2[0.75]\noutput_1[-0.1475]\noutput_2[-0.4450]\noutput_3[2.4500]\n\ninput_1 -- -1.16*0.75 + 0.38 --> output_1\ninput_1 -- 0.24*0.75 - 0.38 --> output_2\ninput_1 -- 1.77*0.75 + 0.16 --> output_3\ninput_2 -- -0.05*0.75 + 0.38 --> output_1\ninput_2 -- 0.18*0.75 - 0.38 --> output_2\ninput_2 -- 1.07*0.75 + 0.16 --> output_3\n```\n\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\nSince the output value is the largest for the Gentoo label, we predict that such a penguin is of the Gentoo species.\n:::\n\n::::\n\n\n## Tough Classification\n\nWhat will our model predict for a penguin whose measurements (after min-max normalization) include a flipper length of 0.301 and a body mass of 0.301?\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n```{mermaid}\nflowchart LR\n\ninput_1[0.301]\ninput_2[0.301]\noutput_1[0.37579]\noutput_2[-0.63358]\noutput_3[1.17484]\n\ninput_1 -- -1.16*0.301 + 0.38 --> output_1\ninput_1 -- 0.24*0.301 - 0.38 --> output_2\ninput_1 -- 1.77*0.301 + 0.16 --> output_3\ninput_2 -- -0.05*0.301 + 0.38 --> output_1\ninput_2 -- 0.18*0.301 - 0.38 --> output_2\ninput_2 -- 1.07*0.301 + 0.16 --> output_3\n```\n\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\nSince the output value is the largest for the Gentoo label, we predict that such a penguin is of the Gentoo species.\n\nHowever, the output values should have favored the Adelie and Chinstrap penguins here.\n:::\n\n::::\n\n\n# Activation Functions\n\n::::: {.panel-tabset}\n\n## motivation\n\n* Can you name a function whose domain is all real numbers but its range is restricted to $(0,1)$?\n\n* Can you name a function whose domain is all real numbers but its range is restricted to $(-1,1)$?\n\n## sigmoid\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n![sigmoid function](activation_sigmoid.png)\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"60%\"}\n\n$$f(x) = \\frac{1}{1 + e^{-x}}$$\n\n* domain: $(-\\infty, \\infty)$\n* range: $(0,1)$\n\nderivative:\n\n$$f'(x) = f(x)[1 - f(x)]$$\n\n* 2 function calls\n* one multiplication, one subtraction\n\n:::\n\n::::\n\n## tanh\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n![hyperbolic tangent](activation_tanh.png)\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"60%\"}\n\n$$f(x) = \\tanh(x) = \\frac{e^{x} - e^{-x}}{e^{x} + e^{-x}}$$\n\n* domain: $(-\\infty, \\infty)$\n* range: $(-1,1)$\n\nderivative:\n\n$$f'(x) = 1 - \\tanh^{2}(x)$$\n\n* 2 function calls\n* one multiplication, one subtraction\n\n:::\n\n::::\n\n## ReLU\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n![rectified linear unit](activation_ReLU.png)\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"60%\"}\n\n$$f(x) = \\begin{cases}x, & x \\geq 0 \\\\ 0, & x < 0\\end{cases}$$\n\n* domain: $(-\\infty, \\infty)$\n* range: $(0,\\infty)$\n\nderivative:\n\n$$f'(x) = \\begin{cases}1, & x > 0 \\\\ 0, & x < 0\\end{cases}$$\n\n:::\n\n::::\n\n\n:::::\n\n\n# Bias\n\n::::: {.panel-tabset}\n\n## scene\n\nSuppose that the high temperature observations at Princeton (in degrees Fahrenheit) are usually between 16 and 90 degrees and that, relatively speaking, local people consider it to be a \"warm day\" if the temperature is at least 60 degrees (\"cold day\" otherwise):\n\n$$f(H) = \\begin{cases}\n  \\text{warm day}, & H \\geq 60 \\\\\n  \\text{cold day}, & H < 60 \\\\\n\\end{cases}$$\n\n## bias\n\nWe can shift the values by a **bias**.  For example, if we use a bias value of $b = 60$, then\n\n$$f(H-60) = \\begin{cases}\n  \\text{warm day}, & H-60 \\geq 0 \\\\\n  \\text{cold day}, & H-60 < 0 \\\\\n\\end{cases}$$\n\nputs the decision boundary at a value of zero in the new units.\n\n## ReLU\n\n:::: {.columns}\n\n::: {.column width=\"30%\"}\n![rectified linear unit](activation_ReLU.png)\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"60%\"}\n\n$$f(x) = \\begin{cases}x, & x \\geq 0 \\\\ 0, & x < 0\\end{cases}$$\n\n* domain: $(-\\infty, \\infty)$\n* range: $(0,\\infty)$\n\nderivative:\n\n$$f'(x) = \\begin{cases}1, & x > 0 \\\\ 0, & x < 0\\end{cases}$$\n\n:::\n\n::::\n\n## float\n\n![floating-point representation](Float_example.svg.png)\n\nA TPU (tensor processing unit) would only have to check one bit!\n\n:::::\n\n\n# Post-Processing: Softmax\n\nAnother way to normalize a vector of numerical observations is to employ the **softmax**\n\n$$\\text{Softmax}(\\vec{x})_{i} = \\frac{e^{x_{i}}}{\\sum_{i=1}^{n}e^{x_{i}}}$$\n\n## Obvious Example\n\nWhat will our model predict for a penguin whose measurements (after min-max normalization) include a flipper length of 0.75 and a body mass of 0.75?\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n```{mermaid}\nflowchart LR\n\ninput_1[0.75]\ninput_2[0.75]\noutput_1[-0.1475]\noutput_2[-0.4450]\noutput_3[2.4500]\n\ninput_1 -- -1.16*0.75 + 0.38 --> output_1\ninput_1 -- 0.24*0.75 - 0.38 --> output_2\ninput_1 -- 1.77*0.75 + 0.16 --> output_3\ninput_2 -- -0.05*0.75 + 0.38 --> output_1\ninput_2 -- 0.18*0.75 - 0.38 --> output_2\ninput_2 -- 1.07*0.75 + 0.16 --> output_3\n```\n\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n$\\frac{e^{-0.1475}}{e^{-0.1475} + e^{-0.4450} + e^{2.4500}} \\approx 0.0659$\n$\\frac{e^{-0.4450}}{e^{-0.1475} + e^{-0.4450} + e^{2.4500}} \\approx 0.0489$\n$\\frac{e^{2.4500}}{e^{-0.1475} + e^{-0.4450} + e^{2.4500}} \\approx 0.8851$\n:::\n\n::::\n\n## Tough Classification\n\nWhat will our model predict for a penguin whose measurements (after min-max normalization) include a flipper length of 0.301 and a body mass of 0.301?\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\n\n```{mermaid}\nflowchart LR\n\ninput_1[0.301]\ninput_2[0.301]\noutput_1[0.37579]\noutput_2[-0.63358]\noutput_3[1.17484]\n\ninput_1 -- -1.16*0.301 + 0.38 --> output_1\ninput_1 -- 0.24*0.301 - 0.38 --> output_2\ninput_1 -- 1.77*0.301 + 0.16 --> output_3\ninput_2 -- -0.05*0.301 + 0.38 --> output_1\ninput_2 -- 0.18*0.301 - 0.38 --> output_2\ninput_2 -- 1.07*0.301 + 0.16 --> output_3\n```\n\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n$$\\begin{array}{c|c|c}\n  \\text{signal} & \\text{exponent} & \\text{softmax} \\\\\n  \\hline\n  0.3758 & e^{0.3758} & 0.2787 \\\\\n  -0.6336 & e^{-0.6336} & 0.1016 \\\\\n  1.1748 & e^{1.1748} & 0.6197 \\\\\n\\end{array}$$\n:::\n\n::::\n\n::: {.callout-caution collapse=\"true\"}\n## Does the softmax output create a probability distribution?\n\nIt's debatable.\n\nWhile the values from a softmax computation are positive sum up to one (up to a rounding error), it is debatable whether or not the softmax result is a probability distribution.\n\n* Nodes earlier in the network (especially in neural networks) can be permuted.  While we might end up with the same distribution, the underlying weights might be quite different.\n* What do these proportions represent?  Later, if we use this softmax output as inputs for another *module*, then we can say something like \"The output signal is about 28 percent Adelie, 10 percent Chinstrap, and 62 percent Gentoo.\"\n* Are these proportions *unbiased estimators* of population proportions?\n\n:::\n\n## Derivative\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\nSoftmax function\n$$\\sigma({\\vec{x}})_{i} = \\frac{e^{x_{i}}}{\\sum_{i=1}^{n}e^{x_{i}}}$$\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\nDerivative\n$$\\frac{\\partial \\sigma_{k}}{\\partial x_{i}} = \\sigma_{k}(\\delta_{ik} - \\sigma_{i})$$\nwhere\n$$\\delta_{ik} = \\begin{cases} 1, & i = k \\\\ 0, & i \\neq k \\\\ \\end{cases}$$\n:::\n\n::::\n\n\n# Loss\n\nToward training and backprogation, for a classification task, we could use the **sum-of-squared residuals** (SSR) to calculate the **loss**. \n\n$$\\text{SSR} = \\sum_{i=1}^{n}(\\text{observed}_{i} - \\text{predicted}_{i})^{2}$$\n\n\n# Back Propogation\n\nHere, we will see how backpropogation works to update *one weight* in our network.\n\n## Initialization\n\nConsider a fully-connected network (FCN) where all of the weights have been initialized to the same uniform value of 0.2 and each bias has been initialized to be zero. What will our model predict for a Gentoo penguin whose measurements (after min-max normalization) include a flipper length of 0.75 and a body mass of 0.75?\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n\n```{mermaid}\nflowchart LR\n\ninput_1[0.75]\ninput_2[0.75]\noutput_1[0.3]\noutput_2[0.3]\noutput_3[0.3]\n\ninput_1 -- 0.2*0.75 + 0 --> output_1\ninput_1 -- 0.2*0.75 + 0 --> output_2\ninput_1 -- 0.2*0.75 + 0 --> output_3\ninput_2 -- 0.2*0.75 + 0 --> output_1\ninput_2 -- 0.2*0.75 + 0 --> output_2\ninput_2 -- 0.2*0.75 + 0 --> output_3\n```\n\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n$$\\begin{array}{c|c|c}\n  \\text{predicted} & \\text{observed} & \\text{residual} \\\\\n  \\hline\n  0.3333 & 0 & 0.3333 \\\\\n  0.3333 & 0 & 0.3333 \\\\\n  0.3333 & 1 & -0.6667 \\\\\n\\end{array}$$\n\nNote: this initialization assumes that each penguin species is equally likely.\n:::\n\n::::\n\n## Partial Derivatives\n\nHere, we will update weight $w_{2,3} = 0.2$. The composition of the linear transformation, softmax, and SSR loss yields the following partial derivatives:\n\n* linear transformation:\n\n$$\\frac{\\partial L}{\\partial w_{2,3}} = x_{2}$$\n\n* softmax:\n\n$$\\frac{\\partial \\sigma_{3}}{\\partial L_{3}} = (\\sigma_{3})(1 - \\sigma_{3})$$\n\n* loss:\n\n$$\\frac{\\partial\\text{SSR}}{\\partial{\\sigma_{3}}} = -2(\\text{observed}_{3} - \\text{predicted}_{3})$$\n\n## Chain Rule\n\nPutting it all together, we can now compute the overall derviative through the chain rule:\n\n$$\\begin{array}{rcl}\n\\frac{\\partial\\text{SSR}}{\\partial w_{2,3}} & = & \\frac{\\partial\\text{SSR}}{\\partial{\\sigma_{3}}} \\cdot \\frac{\\partial \\sigma_{3}}{\\partial L_{3}} \\cdot \\frac{\\partial L}{\\partial w_{2,3}} \\\\\n~ & = & -2(\\text{observed}_{3} - \\text{predicted}_{3}) \\cdot (\\sigma_{3})(1 - \\sigma_{3}) \\cdot x_{2} \\\\\n~ & = & -2(1 - 0.3333) \\cdot (0.3)(1 - 0.3) \\cdot (0.75) \\\\\n~ & \\approx & -0.2100 \\\\\n\\end{array}$$\n\n::: {.callout-note collapse=\"true\"}\n## Why do we use the softmax?\n\nOne question that may appear here is, \"Why do we use min-max normalization for the input layer but then use a softmax for the output layer?\"\n\n* min-max normalization\n\n    * pro: easier to calculate (more easily vectorized)\n    * con: the derivative is simply just the number one (same if we used an argmax), so applying this normalization does not create information for us for back propogation\n    \n* softmax\n\n    * pro: derivative values between 0 and 1\n    * con: more intense calculation (especially for long vectors)\n:::\n\n::: {.callout-warning collapse=\"true\"}\n## Why don't we use the SSR?\n\nThe derivative values from the SSR are relatively small, and hence the learning is slow.\n:::\n\n## Update\n\nFinally, we can apply a step size\n\n$$\\text{step size} = \\text{derivative} \\cdot \\text{learning rate}$$\nIf we had a learning rate of 0.1 (i.e. as a hyperparameter), then our step size here is\n\n$$\\text{step size} = (-0.2100)(0.1) = -0.0210$$\nOur new weight is\n\n$$\\begin{array}{rcl}\n  \\text{new weight} & = & \\text{old weight} - \\text{step size} \\\\\n  ~ & = & 0.2 - (-0.0210) \\\\\n  ~ & = & 0.2210 \\\\\n\\end{array}$$\n\n## Feed Foward\n\nApplying this new weight, our network now looks like this\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n\n\n```{mermaid}\nflowchart LR\n\ninput_1[0.75]\ninput_2[0.75]\noutput_1[0.3000]\noutput_2[0.3000]\noutput_3[0.3158]\n\ninput_1 -- 0.2*0.75 + 0 --> output_1\ninput_1 -- 0.2*0.75 + 0 --> output_2\ninput_1 -- 0.2*0.75 + 0 --> output_3\ninput_2 -- 0.2*0.75 + 0 --> output_1\ninput_2 -- 0.2*0.75 + 0 --> output_2\ninput_2 -- 0.2210*0.75 + 0 --> output_3\n```\n\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n$$\\begin{array}{c|c|c}\n  \\text{predicted} & \\text{observed} & \\text{residual} \\\\\n  \\hline\n  0.3316 & 0 & 0.3316 \\\\\n  0.3316 & 0 & 0.3316 \\\\\n  0.3366 & 1 & -0.6637 \\\\\n\\end{array}$$\n\nNow:\n\n* the prediction moved correctly toward \"Gentoo\"!\n* the residuals decreased!\n:::\n\n::::\n\n# Python Code\n\n## Tensors\n\nWe will use tensors in Pytorch Lightning\n\n![3D tensor](tensor_picture.png)\n\n* image source: [MIT](https://news.mit.edu/2017/faster-big-data-analysis-tensor-algebra-1031)\n\n### What are tensors?\n\nAt first, **tensors** (for machine learning) are multidimensional arrays.\n\n* a value is a 0D tensor\n* an array is a 1D tensor\n* a matrix is a 2D tensor\n\n### Why do we use tensors?\n\n* accelerated computations via graphical processing units (GPUs)\n* automatic differentiation\n* helps with parallelizable processes\n\n![parallel processes](parallel_process.png)\n\n* image source: [Faisal Shahbaz](https://medium.datadriveninvestor.com/python-multiprocessing-pool-vs-process-comparative-analysis-6c03c5b54eec)\n\n## Object-Oriented Programming\n\nFramework choice:\n\n* Keras\n* PyTorch\n* Scikit Learn\n* TensorFlow\n\nWhy Pytorch?\n\n* recency bias (Derek studied these concepts with PyTorch)\n* **object-oriented programming**\n\nWhy Object-Oriented Programming?\n\nLater concepts are probably better understood as *modular* steps in a workflow, which lend themselves to object-oriented programming (OOP)\n\n::::: {.panel-tabset}\n\n## Example 1\n\nFor the penguins examples, we needed a fully-connected network whose input layer size was 2 and whose output layer size was 3\n\n![example 1](FCN_2_3.png)\n\n* Python code: `model = FCN(2,3)`\n\n## Example 2\n\nFor the next example, we need a fully-connected network whose input layer size is 4 and whose output layer size is 2\n\n![example 2](FCN_4_2.png)\n\n* Python code: `model = FCN(4,2)`\n\n## Class Definition\n\n\n\n::: {.cell}\n\n```{.python .cell-code}\nclass FCN(pl.LightningModule):\n  # Fully-Connected Network\n  # assumes no hidden layer (i.e. going directly into activation functions)\n\n    def __init__(self, input_layer_size, output_layer_size):\n        super().__init__()\n        self.input_layer_size = input_layer_size \n        self.output_layer_size = output_layer_size \n        self.fc1 = nn.Linear(input_layer_size, output_layer_size)\n        self.test_step_outputs = []\n\n    def forward(self, x):\n        x = F.relu(self.fc1(x))\n        return x\n\n    def training_step(self, batch, batch_idx):\n        x, y = batch\n        output = self(x)\n        loss = F.cross_entropy(output, y)\n        return {'loss':loss}\n\n    def test_step(self, batch, batch_idx):\n        x, y = batch\n        output = self(x)\n        loss = F.cross_entropy(output, y)\n        self.test_step_outputs.append(loss)\n        return {'loss':loss}\n\n    def on_test_epoch_end(self):\n        epoch_average = torch.stack(self.test_step_outputs).mean()\n        self.log(\"test_epoch_average\", epoch_average)\n        self.test_step_outputs.clear()\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.SGD(self.parameters(), lr=lr)\n        return optimizer\n```\n:::\n\n\n\n:::::\n\n::: {.callout-warning}\n## DCP1\n:::\n\n# Image Processing\n\n![image processing techniques](data_augmentation_techniques.png)\n\n* image source: [A Simple Framework for Contrastive Learning of Visual Representations, Chen et al., ICML 2020](https://arxiv.org/abs/2002.05709)\n\n![image processing](princeton_tiger_nobg.png)\n\n* image source: [Princeton Sports](https://tigerlife.princeton.edu/sports)\n\n# Saliency Maps\n\n![saliency maps](saliency_maps.png)\n\n* image source: [Walter, et al](https://www.themoonlight.io/en/review/now-you-see-me-a-framework-for-obtaining-class-relevant-saliency-maps)\n\n::: {.callout-warning}\n## DCP2\n:::\n\n\n# Ethics Segment: Voices\n\n::::: {.panel-tabset}\n\n## Scene\n\nIn 2025, New Era unveiled their lineup of fusion caps for baseball franchises.\n\n![New Era 2025 Hats](new_era_hats.png)\n\n## Cases\n\nSome hats (such as this one from 2024) raised some concerns\n\n![New Era 2024 Athletics](new_era_hats_athletics.png)\n\n## Fallout\n\nThe company had to recall many of its products.\n\n![New Era 2025 fall out](new_era_hats_fallout.png)\n\n* image credit: [Sports Illustrated](https://www.si.com/mlb/texas-rangers-new-era-hat-pulled-vulgarity)\n\n:::::\n\n::: {.callout-warning}\n## DCP3\n:::\n\n# ImageNet\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n![The Worlds I See](worlds_I_see.png)\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n* Dr Fei Fei Li\n* Princeton Class of 1999\n* Pre-Read Selection for Class of 2028\n\n> Biederman's number: \"30,000 unique concepts might provide a complete foundation for understanding the visual world\"\n\n* ImageNet competition\n* AlexNet: solved by convolutional neural networks in 2012\n\n:::\n\n::::\n\n## Image Augmentation\n\n* rotation\n* translation\n* reflections\n* etc.\n\n![image augmentation](image_augmentation.png)\n\n* image source: [Arun Gandhi](https://nanonets.com/blog/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2/)\n\n# Quo Vadimus?\n\n:::: {.columns}\n\n::: {.column width=\"40%\"}\n* due this Friday (Oct 31):\n\n    - Precept 7 (1 hour)\n    - Multipass: xLSTM (20 minutes)\n    - Literature Search (10 minutes)\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"50%\"}\n\nOur SML 301 lecture session for **Monday, November 24** will be remote (Zoom).\n\n* guest speaker from AI industry\n\n:::\n\n::::\n\n\n# Footnotes\n\n::: {.callout-note collapse=\"true\"}\n\n## (optional) Additional Resources and References\n\n* [Pytorch history](https://alexmoltzau.medium.com/pytorch-governance-and-history-2e5889b79dc1) by Alex Moltzau\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Session Info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.5.1 (2025-06-13 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n [1] lubridate_1.9.4      forcats_1.0.0        stringr_1.5.1       \n [4] dplyr_1.1.4          purrr_1.1.0          readr_2.1.5         \n [7] tidyr_1.3.1          tibble_3.3.0         ggplot2_4.0.0       \n[10] tidyverse_2.0.0      patchwork_1.3.1      palmerpenguins_0.1.1\n[13] ggtext_0.1.2        \n\nloaded via a namespace (and not attached):\n [1] Matrix_1.7-3       gtable_0.3.6       jsonlite_2.0.0     compiler_4.5.1    \n [5] tidyselect_1.2.1   Rcpp_1.1.0         xml2_1.3.8         png_0.1-8         \n [9] scales_1.4.0       yaml_2.3.10        fastmap_1.2.0      lattice_0.22-7    \n[13] reticulate_1.43.0  R6_2.6.1           labeling_0.4.3     generics_0.1.4    \n[17] knitr_1.50         htmlwidgets_1.6.4  tzdb_0.5.0         pillar_1.11.0     \n[21] RColorBrewer_1.1-3 rlang_1.1.6        stringi_1.8.7      xfun_0.52         \n[25] S7_0.2.0           timechange_0.3.0   cli_3.6.5          withr_3.0.2       \n[29] magrittr_2.0.3     digest_0.6.37      grid_4.5.1         gridtext_0.1.5    \n[33] rstudioapi_0.17.1  hms_1.1.3          lifecycle_1.0.4    vctrs_0.6.5       \n[37] evaluate_1.0.4     glue_1.8.0         farver_2.1.2       rmarkdown_2.29    \n[41] tools_4.5.1        pkgconfig_2.0.3    htmltools_0.5.8.1 \n```\n\n\n:::\n:::\n\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n:::\n\n::::\n\n::::: {.panel-tabset}\n\n\n\n:::::",
    "supporting": [
      "15_image_processing_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}