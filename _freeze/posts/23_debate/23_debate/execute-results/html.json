{
  "hash": "fda5967d1f59604445fe0ca83027b9f2",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"23: Debate\"\nauthor: \"Derek Sollberger\"\ndate: \"2024-12-01\"\nformat:\n  html:\n    toc: true\n---\n\n\n\n\n# 23: Teaching Controversial Topics\n\n## Learning Objectives\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n- view results of prompt engineering\n- discuss governmental regulation in AI\n- participate in agile ethics\n:::\n\n::: {.column width=\"10%\"}\n\n:::\n\n::: {.column width=\"45%\"}\n![AI in Ethics](ai_ethics_flyer.png)\n\n* image source: [Princeton Dialogue on AI and Ethics](https://aiethics.princeton.edu/events/)\n:::\n\n::::\n\n# Scene\n\nI am in a teaching group called `Teaching Controversial Topics`, and with them I want to draft a case study from the realm of artificial intelligence. For this teaching group, I am hoping to produce\n\n* 20-minute classroom activity for the SML 301 students\n* a blog post for me\n\nDr Sarah-Jane Leslie suggested that I look into either \"privacy/copyright issues around training data for LLMs\" or \"the role of government regulation in AI development\".  Especially drawn to the latter, idea I have then been picturing a classroom debate about government regulation in AI.  I think that this would appeal to my audience of mostly engineering majors. Over the summer in the AI4ALL summer camp, Dr Steven Kelts led a great ethics debate with the students, and I am hoping to emulate that by partitioning the SML 301 students into 4 roles such as\n\n1. congressional staffers\n2. business lobbyists\n3. data privacy NGO\n4. legal advisors\n\n::: {.callout-warning}\n## Disclosure on AI Use\n\nDespite thinking about this project for the past 4 months (inspired by the BIOME25 conference), I admit that I am assembling these materials merely a couple of weeks before my proposed launch date.  I hardly have experience in debate, much less in setting up one.  Thus, one can imagine that I too would want AI assistance to complete this task.\n\nMy students and I have recently covered materials about AI---particularly prompt engineering and retrieval augmented generation---so I am indeed inclined to try to justify AI usage here as careful examination of LLM results.\n:::\n\n\n# Prompt Engineering\n\nMy students, perhaps as a reflection of the learning environment that I create, are a quiet group of people.  In fact, I set up an anonymous Slido poll each week to receive questions rather than having the students raise their hands.  With that in mind, asking them to vocalize a debate will be quite a shift in expectations.  \n\nTo mitigate that aberrant request, I want to give each student a one-page **character sheet** to on-board them into the roles (stated above). I hope that each character sheet provides several possible talking points to encourage and guide the debate.\n\nEven after I read some materials (below in the \"RAG\" section), I find that I myself am not a writer of debates.  Thus, I shall employ **prompt engineering** to create the bullet-point lists of talking points.  The idea of debate roles lends itself well for the prompt engineering tool.\n\nFollowing materials found in Chapter 6 of [Hands-On Large Language Models](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models) (by Jay Alammar and Maarten Grootendorst), we can construct an LLM prompt with parts like ...\n\n::: {.callout-tip}\n## Persona\n\n[We will provide this below]\n:::\n\n::: {.callout-note}\n## Instruction\n\nProvide possible debate points and *support a stance*.\n:::\n\n::: {.callout-tip}\n## Context\n\nThe list should *express several key points* that can help a debate team and quickly state important information for the scene.\n:::\n\n::: {.callout-note}\n## Format\n\nCreate a bullet-point overview that summarizes the *debate stance* and also provide a concise paragraph that initiates the debate.\n:::\n\n::: {.callout-tip}\n## Audience\n\nWe are at a USA government meeting with a subcommitee of Congress.  We are hoping to inform our Congress members about the issues about *governmental regulation in artificial intelligence*.\n:::\n\n::: {.callout-note}\n## Tone\n\nThe tone should be informative and professional.\n:::\n\n::: {.callout-tip}\n## Data\n\n[https://en.wikipedia.org/wiki/Regulation_of_AI_in_the_United_States](https://en.wikipedia.org/wiki/Regulation_of_AI_in_the_United_States)\n:::\n\nContinuing with the materials found in Chapter 6 of [Hands-On Large Language Models](https://github.com/HandsOnLLM/Hands-On-Large-Language-Models), I used the [Phi-3-mini-4k-instruct](https://huggingface.co/microsoft/Phi-3-mini-4k-instruct) LLM (made by Microsoft) and its tokenizer to process these prompts.\n\n\n# Roles\n\nWe are now ready to see the participants! Here I apply the prompt engineering (structured above) with each of the 4 personas. We hope to have the AI create the rest of the character sheets\n\n::::: {.panel-tabset}\n\n## staffer\n\n::: {.callout-note}\n### persona\n\nYou are a Congressional staffer and college graduate. You have been asked to provide a historical perspective of the issue.\n:::\n\n### character sheet\n\n The United States has been actively engaging in the regulation of artificial intelligence (AI) to ensure the technology's development aligns with national interests, public safety, and ethical standards. The regulatory landscape for AI in the U.S. has evolved through various executive orders, legislative proposals, and state-level initiatives, reflecting a complex interplay between innovation, security, and societal impact.\n\n**Executive Orders and Federal Actions:**\n\n- **2016-2019:** The National Science and Technology Council's report on \"Preparing for the Future of Artificial Intelligence\" laid the groundwork for a balanced approach to AI development, emphasizing the importance of ethical considerations and the potential risks associated with AI technologies.\n- **2019:** The White House Office of Science and Technology Policy (OSTP) issued a draft guidance on the regulation of AI applications, proposing a framework that includes ethical principles and risk assessment methodologies to ensure AI technologies are developed responsibly.\n- **2020:** The National Security Commission on Artificial Intelligence (NSCAI) was established to provide strategic recommendations for AI development in national security contexts, highlighting the importance of AI in maintaining U.S. technological leadership.\n- **2021:** The Biden administration's Executive Order on \"Preventing Weaponization of AI\" aimed to mitigate the risks of AI being used for harmful purposes, emphasizing the need for international cooperation and responsible AI development.\n- **2022:** The National Artificial Intelligence Initiative Office (NAIIO) was created to coordinate federal efforts in AI research and development, focusing on advancing AI technologies that benefit the public and national security.\n- **2023:** The Office of Science and Technology Policy (OSTP) released the \"AI Risk Management Framework (RMF)\" to guide federal agencies in assessing and managing the risks associated with AI applications.\n- **2023:** The National Artificial Intelligence Research and Development Strategic Plan outlined a comprehensive approach to A\n\n## lobbyist\n\n::: {.callout-note}\n### persona\n\nYou are a business lobbyist who seeks to discourage further government regulation in artificial intelligence.  You seek to build upon anti-regulation sentiment.\n:::\n\n### character sheet\n\n* The United States government has been actively engaged in shaping the future of artificial intelligence (AI) through a series of legislative and regulatory efforts aimed at fostering innovation while addressing the potential risks associated with AI technologies. These efforts reflect a balanced approach to AI governance, recognizing the transformative potential of AI across various sectors while also acknowledging the need for safeguards to protect public interests and ensure ethical AI development.\n\n* In the early stages of AI regulation, the National Science and Technology Council (NSTC) in 2018 laid the groundwork for a national AI strategy, emphasizing the importance of research and development in AI technologies. This was followed by the National Artificial Intelligence Research and Development Strategic Plan in 2019, which outlined a vision for the U.S. to lead in AI innovation and application. The Department of Defense (DoD) also played a pivotal role in AI regulation by establishing the National Security Commission on Artificial Intelligence (NSCAI) in 2019, tasked with ensuring the U.S. maintains a competitive edge in AI for national security purposes.\n\n* The Food and Drug Administration (FDA) has been instrumental in addressing the intersection of AI and healthcare, particularly in the regulation of AI applications in medical devices. This includes the development of frameworks to ensure the safety and efficacy of AI-driven diagnostic tools and treatments.\n\n* The Office of Science and Technology Policy (OSTP) has been at the forefront of AI governance, issuing guidelines for the responsible development and deployment of AI technologies. These guidelines emphasize the importance of transparency, accountability, and ethical considerations in AI systems.\n\n* In response to the evolving AI landscape, the National Artificial Intelligence Initiative Office (NAIIO) was established to coordinate federal AI efforts, focusing on research, development, and the responsible use of AI technologies.\n\n* The National AI Initiative (NAII) and the National Artificial Intelligence Research and Development Strategic Plan have been key in setting strategic priorities for AI research and\n\n## NGO\n\n::: {.callout-note}\n### persona\n\nYou are a volunteer at a non-governmental organization (NGO) that raises awareness about data privacy and the corpuses that are used in the training of large language models.\n:::\n\n### character sheet\n\n1. **Regulatory Framework**: The U.S. government's approach to AI regulation has been a mix of federal and state-level initiatives. The National Artificial Intelligence Initiative Office (NAIIO) and the National Artificial Intelligence Research Resource (NAIRR) are federal efforts aimed at advancing AI research and development. However, the Trump administration's Executive Order #14179 and the proposed \"TAKE IT DOWN Act\" reflect a deregulatory stance, emphasizing innovation over risk mitigation. This contrasts with the Biden administration's Executive Order, which seeks to establish a comprehensive AI regulatory framework. The debate should consider the balance between fostering innovation and ensuring public safety and ethical standards.\n\n2. **AI in Healthcare**: The Food and Drug Administration (FDA) has a role in regulating AI applications in healthcare, such as the approval process for AI-driven medical devices. The FDA's involvement ensures that AI applications in healthcare meet safety and efficacy standards, protecting patients from potential harm. This regulatory oversight is crucial in maintaining public trust in AI technologies, especially in sensitive areas like healthcare.\n\n3. **AI and Privacy**: The Biden administration's AI Bill of Rights emphasizes the importance of privacy and data security in AI applications. This includes the requirement for AI systems to be transparent about their use of personal data and the implementation of watermarking to inform users about AI-generated content. These measures are essential in protecting individuals' privacy rights and ensuring that AI technologies are used ethically and responsibly.\n\n4. **State and Local Government Interventions**: The New York City Bias Audit Law and California's Safe and Secure Innovation for Frontier Artificial Intelligence Models Act represent state and local efforts to address AI-related risks and biases. These initiatives highlight the importance of local governance in complementing federal efforts to regulate AI. The debate should consider the effectiveness of these local measures in mitigating AI risks and promoting ethical AI development\n\n## legal\n\n::: {.callout-note}\n### persona\n\nYou are a paralegal at a law firm that has been tasked with explaining the legal subtleties in the current American laws about artificial intelligence.\n:::\n\n### character sheet\n\n**Pro-Regulation Stance:**\n\n1. **Safety and Ethical Concerns:** The rapid advancement of AI technologies, particularly in areas like facial recognition and deepfakes, raises significant safety and ethical concerns. The potential for AI to perpetuate and amplify existing biases, discriminate against marginalized groups, and infringe on privacy rights necessitates a regulatory framework to ensure these technologies are developed and deployed responsibly.\n\n2. **Need for Oversight:** The National Security Commission on Artificial Intelligence's report highlights the importance of establishing a federal agency to oversee AI development, ensuring it aligns with national security and ethical standards. This oversight is crucial to prevent the misuse of AI in ways that could harm individuals or national security.\n\n3. **Public Safety and Trust:** The Executive Order on AI emphasizes the need for AI to advance equity and civil rights, addressing concerns about job quality and labor disruptions. By mandating transparency and accountability in AI systems, the government can foster public trust and ensure AI technologies contribute positively to society.\n\n4. **International Leadership:** The Biden administration's Executive Order and the proposed AI Action Plan demonstrate a commitment to securing U.S. global AI dominance through responsible innovation. This approach not only positions the U.S. as a leader in AI but also ensures that AI advancements are aligned with democratic values and human rights.\n\n**Anti-Regulation Stance:**\n\n1. **Innovation and Competitiveness:** Critics argue that stringent regulations could stifle innovation and hinder the U.S.'s competitive edge in the global AI market. The tech industry often views regulations as barriers to growth, potentially slowing down the development of beneficial AI applications.\n\n2. **State and Local Initiatives:** The diverse approaches taken by states, such as New York's Bias Audit Law and Utah's AI Policy Act, demonstrate a\n\n:::::\n\n\n# RAG\n\nSo far, I have found neat resources that include\n\n* [a brief in the Princeton Legal Journal](https://legaljournal.princeton.edu/regulating-artificial-intelligence-antitrust-and-anti-discrimination-policy/) (Feb 2025)\n* [Congress report](https://www.congress.gov/crs-product/R48555) (June 2025)\n* [article](https://www.whitecase.com/insight-our-thinking/ai-watch-global-regulatory-tracker-united-states) by \"Energy Legal Services Provider\" White & Case (Sept 2025)\n* [state legislation tracker](https://www.ncsl.org/technology-and-communication/artificial-intelligence-2025-legislation) by the NCSL (National Conference of State Legislatures, updated July 2025)\n* [journal report](https://cyber.fsi.stanford.edu/content/regulating-under-uncertainty-governance-options-generative-ai) from the Stanford Cyber Policy Center (updated Sept 2025)\n\n::: {.callout-note collapse=\"true\"}\n## TODO\n\nTake on a **retrieval-augmented generation** (RAG) mindset by either having each persona ask for more debate points from the specialized literature (i.e. more specialized than just the Wikipedia article) or simply augment the data first and then perform the prompt engineering again.\n:::\n\n\n\n# Footnotes\n\n::: {.callout-note collapse=\"true\"}\n\n## (optional) Additional Resources and References\n\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Session Info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.5.1 (2025-06-13 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n  LAPACK version 3.12.1\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n [1] htmlwidgets_1.6.4 compiler_4.5.1    fastmap_1.2.0     cli_3.6.5        \n [5] tools_4.5.1       htmltools_0.5.8.1 rstudioapi_0.17.1 yaml_2.3.10      \n [9] rmarkdown_2.29    knitr_1.50        jsonlite_2.0.0    xfun_0.52        \n[13] digest_0.6.37     rlang_1.1.6       evaluate_1.0.4   \n```\n\n\n:::\n:::\n\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n:::\n\n::::\n\n::::: {.panel-tabset}\n\n\n\n:::::",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}