{
  "hash": "f02d45cb1a4f402640faf15f67f0db06",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"4: Classification\"\nauthor: \"Derek Sollberger\"\ndate: \"2025-02-05\"\nformat:\n  html:\n    toc: true\n---\n\n::: {.cell}\n\n:::\n\n\n\n# Session 4: Classification\n\n## Start\n\n:::: {.columns}\n\n::: {.column width=\"60%\"}\n* **Goal**: Start to discuss classification methods\n\n* **Objective**: Explore logistic regression and Naive Bayes classifiers\n:::\n\n::: {.column width=\"40%\"}\nAs we get started, try to install the `palmerpenguins` package in your Python software\n:::\n\n::::\n\n# Logistic Regression\n\nClassification of $y \\in \\{0,1\\}$\n\n$$p(y|x,\\theta) = \\text{Ber}(y | \\sigma(w^{T}x + b))$$\n\n* logit $a$: $w^{T}x + b$\n* sigmoid: \n\n$$\\sigma(a) = \\frac{1}{1 + e^{-a}} = p(y = 1 | x,\\theta)$$\n\n## Palmer Penguins Example\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_classification_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n\n<details>\n<summary>R Code</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\nadelie_color = \"#fb7504\"\nchinstrap_color = \"#c65ccc\"\ngentoo_color = \"#067476\"\n\npenguin_class_df <- penguins |>\n  na.omit() |>\n  mutate(chinstrap_bool = ifelse(species == \"Chinstrap\", 1, 0)) |>\n  mutate(across(chinstrap_bool, as.factor)) #https://stackoverflow.com/questions/33180058/coerce-multiple-columns-to-factors-at-once\n\npenguin_class_df |>\nggplot(aes(x = flipper_length_mm, y = bill_length_mm, \n           color = chinstrap_bool)) + \n  geom_point(size = 3) + \n  labs(title = \"Classification Task\",\n       subtitle = \"Finding the <span style = 'color:#c65ccc'>Chinstrap</span> penguins among n = 333 penguins\",\n       caption = \"SML 301\") +\n  scale_color_manual(values = c(\"gray70\", chinstrap_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n:::\n\n\n</details>\n\n### Generalized Linear Models\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlogistic_model <- stats::glm(chinstrap_bool ~ flipper_length_mm + bill_length_mm,\n                      data = penguin_class_df,\n                      family = binomial) #makes logistic regression\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_classification_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n<details>\n<summary>R code</summary>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# https://stats.stackexchange.com/questions/6206/how-to-plot-decision-boundary-in-r-for-logistic-regression-model\nbeta_0 <- coef(logistic_model)[1]\nbeta_1 <- coef(logistic_model)[2]\nbeta_2 <- coef(logistic_model)[3]\nboundary_slope <- -1.0 * beta_1 / beta_2\nboundary_intercept <- -1.0 * beta_0 / beta_2\n\npenguin_pred_df <- penguin_class_df |>\n  mutate(species_pred = ifelse(\n    bill_length_mm > boundary_intercept + boundary_slope * flipper_length_mm,\n    1,0)) |>\n  mutate(across(species_pred, as.factor))\n\npenguin_pred_df |>\nggplot(aes(x = flipper_length_mm, y = bill_length_mm, \n           color = species_pred)) + \n  geom_point(size = 3) + \n  geom_abline(intercept = boundary_intercept,\n              slope = boundary_slope,\n              color = adelie_color,\n              linewidth = 2,\n              linetype = 2) +\n  labs(title = \"<span style = 'color:#fb7504'>Decision Boundary</span>\",\n       subtitle = \"where logit a = 0\",\n       caption = \"SML 301\") +\n  scale_color_manual(values = c(\"gray70\", chinstrap_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n:::\n\n\n</details>\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguin_pred_df |>\n  janitor::tabyl(chinstrap_bool, species_pred) |>\n  janitor::adorn_totals(c(\"row\", \"col\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n chinstrap_bool   0  1 Total\n              0 258  7   265\n              1   8 60    68\n          Total 266 67   333\n```\n\n\n:::\n:::\n\n\n\n* [accuracy](https://en.wikipedia.org/wiki/Sensitivity_and_specificity): 0.9550\n* [sensitivity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity): 0.8824\n* [specificity](https://en.wikipedia.org/wiki/Sensitivity_and_specificity): 0.9736\n\n\n# Activity: Literature Conclusions\n\nWe will look at the concluding paragraphs for some of the most influential papers in the history of machine learning:\n\n## Adaboost\n\n* A Decision-Theoretic Generalization of on-Line Learning and an Application to Boosting (1997—published as abstract in 1995), Freund and Schapire\n\n## AlexNet\n\n* ImageNet Classification with Deep Convolutional Neural Networks (2012)\n\n## DropOut\n\n* Dropout: A Simple Way to Prevent Neural Networks from Overfitting (2014), Srivastava, Hinton, Krizhevsky, Sutskever, and Salakhutdinov\n\n## GANs\n\n* General Adversarial Nets (2014), Goodfellow et al.\n\n## TensorFlow\n\n* TensorFlow: A system for large-scale machine learning (2016), Abadi et al.\n\n## Word2Vec\n\n* Efficient Estimation of Word Representations in Vector Space (2013), Mikolov, Chen, Corrado, and Dean\n\n\n# Naive Bayes\n\n## Data: Palmer Penguins\n\nThere exist multiple penguin species throughout Antarctica, including the *Adelie*, *Chinstrap*, and *Gentoo*. When encountering one of these penguins on an Antarctic trip, we might *classify* its species\n\n$$Y = \\begin{cases} A & \\text{Adelie} \\\\ C & \\text{Chinstrap} \\\\ G & \\text{Gentoo} \\end{cases}$$\n\n![three species](lter_penguins.png)\t\n\nExample comes from chapter 14 of *Bayes Rules!*\n\n![Bayes Rules! textbook](bayes_rules_textbook.png)\t\n\n\n\n\n$X_{1}$ categorical variable: whether the penguin weighs more than the average 4200 grams\n\n$$X_{1} = \\begin{cases} 1 & \\text{above-average weight} \\\\ 0 & \\text{below-average weight} \\end{cases}$$\n\n![AKA culmen length and depth](culmen_depth.png)\n\nNumerical variables:\n\n$$\\begin{array}{rcl}\n  X_{2} & = & \\text{bill length (mm)} \\\\\n  X_{3} & = & \\text{flipper length (mm)} \\\\\n\\end{array}$$\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndata(penguins_bayes)\npenguins <- penguins_bayes\n\nadelie_color = \"#fb7504\"\nchinstrap_color = \"#c65ccc\"\ngentoo_color = \"#067476\"\n\npenguins |>\n  tabyl(species)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   species   n   percent\n    Adelie 152 0.4418605\n Chinstrap  68 0.1976744\n    Gentoo 124 0.3604651\n```\n\n\n:::\n:::\n\n\n\n## Motivation\n\nHere, we have *three* categories, whereas logistic regression is limited to classifying *binary* response variables.  As an alternative, **naive Bayes classification** \n\n* can classify categorical response variables $Y$ with two or more categories\n* doesn’t require much theory beyond Bayes’ Rule\n* it’s computationally efficient, i.e., doesn’t require MCMC simulation\n\nBut why is it called \"naive\"?\n\n## One Categorical Predictor\n\nSuppose an Antarctic researcher comes across a penguin that weighs less than 4200g with a 195mm-long flipper and 50mm-long bill. Our goal is to help this researcher identify the species of this penguin: Adelie, Chinstrap, or Gentoo\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_classification_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n\n<details>\n<summary>image code</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |>\n  drop_na(above_average_weight) |>\n  ggplot(aes(fill = above_average_weight, x = species)) + \n  geom_bar(position = \"fill\") + \n  labs(title = \"<span style = 'color:#067476'>For which species is a<br>below-average weight most likely?</span>\",\n       subtitle = \"(focus on the <span style = 'color:#c65ccc'>below-average</span> category)\",\n       caption = \"SML 301\") +\n  scale_fill_manual(values = c(\"#c65ccc\", \"#fb7504\")) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n:::\n\n\n</details>\n\n### Recall: Bayes Rule\n\n$$f(y|x_{1}) = \\frac{\\text{prior}\\cdot\\text{likelihood}}{\\text{normalizing constant}} = \\frac{f(y) \\cdot L(y|x_{1})}{f(x_{1})}$$\nwhere, by the Law of Total Probability,\n\n$$\\begin{array}{rcl}\nf(x_{1} & = & \\displaystyle\\sum_{\\text{all } y'} f(y')L(y'|x_{1}) \\\\\n~ & = & f(y' = A)L(y' = A|x_{1}) + f(y' = C)L(y' = C|x_{1}) + f(y' = G)L(y' = G|x_{1}) \\\\\n\\end{array}$$\n\nover our three penguin species.\n\n### Calculation\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |> \n  select(species, above_average_weight) |> \n  na.omit() |> \n  tabyl(species, above_average_weight) |> \n  adorn_totals(c(\"row\", \"col\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n   species   0   1 Total\n    Adelie 126  25   151\n Chinstrap  61   7    68\n    Gentoo   6 117   123\n     Total 193 149   342\n```\n\n\n:::\n:::\n\n\n\nPrior probabilities:\n\n$$f(y = A) = \\frac{151}{342}, \\quad f(y = C) = \\frac{68}{342}, \\quad f(y = G) = \\frac{123}{342}$$\n\nLikelihoods:\n\n$$\\begin{array}{rcccl}\n  L(y = A | x_{1} = 0) & = & \\frac{126}{151} & \\approx & 0.8344 \\\\\n  L(y = C | x_{1} = 0) & = & \\frac{61}{68} & \\approx & 0.8971 \\\\\n  L(y = G | x_{1} = 0) & = & \\frac{6}{123} & \\approx & 0.0488 \\\\\n\\end{array}$$\n\nTotal probability:\n\n$$f(x_{1} = 0) = \\frac{151}{342}\\cdot\\frac{126}{151} + \\frac{68}{342}\\cdot\\frac{61}{68} + \\frac{123}{342}\\cdot\\frac{6}{123} = \\frac{193}{342}$$\n\nBayes' Rules:\n\n$$\\begin{array}{rcccccl}\n  f(y = A | x_{1} = 0) & = & \\frac{f(y = A) \\cdot L(y = A | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{151}{342}\\cdot\\frac{126}{151}}{\\frac{193}{342}} & \\approx & 0.6528 \\\\\n  f(y = C | x_{1} = 0) & = & \\frac{f(y = A) \\cdot L(y = C | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{68}{342}\\cdot\\frac{61}{68}}{\\frac{193}{342}} & \\approx & 0.3161 \\\\\n  f(y = G | x_{1} = 0) & = & \\frac{f(y = A) \\cdot L(y = G | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{123}{342}\\cdot\\frac{6}{123}}{\\frac{193}{342}} & \\approx & 0.0311 \\\\\n\\end{array}$$\n\nThe posterior probability that this penguin is an Adelie is more than double that of the other two species\n\n\n## One Numerical Predictor\n\nLet’s ignore the penguin’s weight for now and classify its species using only the fact that it has a 50mm-long bill\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_classification_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\n\n\n<details>\n<summary>image code</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins|>\n  ggplot(aes(x = bill_length_mm, fill = species)) + \n  geom_density(alpha = 0.7) + \n  geom_vline(xintercept = 50, linetype = \"dashed\", linewidth = 3) + \n  labs(title = \"<span style = 'color:#c65ccc'>For which species is a<br>50mm-long bill the most common?</span>\",\n       subtitle = \"one numerical predictor\",\n       caption = \"SML 301\") +\n  scale_fill_manual(values = c(adelie_color, chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n:::\n\n\n</details>\n\nOur data points to our penguin being a Chinstrap\n\n* we must weigh this data against the fact that Chinstraps are the rarest of these three species\n* difficult to compute likelihood $L(y = A | x_{2} = 50)$\n\nThis is where one “*naive*” part of naive Bayes classification comes into play. The naive Bayes method typically assumes that any quantitative predictor, here $X_{2}$, is **continuous** and **conditionally normal**:\n\n$$\\begin{array}{rcl}\n  X_{2} | (Y = A) & \\sim & N(\\mu_{A}, \\sigma_{A}^{2}) \\\\\n  X_{2} | (Y = C) & \\sim & N(\\mu_{C}, \\sigma_{C}^{2}) \\\\\n  X_{2} | (Y = G) & \\sim & N(\\mu_{G}, \\sigma_{G}^{2}) \\\\\n\\end{array}$$\n\n### Prior Probability Distributions\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Calculate sample mean and sd for each Y group\npenguins |> \n  group_by(species) |> \n  summarize(mean = mean(bill_length_mm, na.rm = TRUE), \n            sd = sd(bill_length_mm, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  species    mean    sd\n  <fct>     <dbl> <dbl>\n1 Adelie     38.8  2.66\n2 Chinstrap  48.8  3.34\n3 Gentoo     47.5  3.08\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |>\n  ggplot(aes(x = bill_length_mm, color = species)) + \n  stat_function(fun = dnorm, args = list(mean = 38.8, sd = 2.66), \n                aes(color = \"Adelie\"), linewidth = 3) +\n  stat_function(fun = dnorm, args = list(mean = 48.8, sd = 3.34),\n                aes(color = \"Chinstrap\"), linewidth = 3) +\n  stat_function(fun = dnorm, args = list(mean = 47.5, sd = 3.08),\n                aes(color = \"Gentoo\"), linewidth = 3) +\n  ...\n```\n:::\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_classification_files/figure-html/unnamed-chunk-16-1.png){width=672}\n:::\n:::\n\n\n\n\n\n<details>\n<summary>image code</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |>\n  ggplot(aes(x = bill_length_mm, color = species)) + \n  stat_function(fun = dnorm, args = list(mean = 38.8, sd = 2.66), \n                aes(color = \"Adelie\"), linewidth = 3) +\n  stat_function(fun = dnorm, args = list(mean = 48.8, sd = 3.34),\n                aes(color = \"Chinstrap\"), linewidth = 3) +\n  stat_function(fun = dnorm, args = list(mean = 47.5, sd = 3.08),\n                aes(color = \"Gentoo\"), linewidth = 3) + \n  geom_vline(xintercept = 50, linetype = \"dashed\") + \n  labs(title = \"<span style = 'color:#c65ccc'>Prior Probabilities</span>\",\n       subtitle = \"conditionally normal\",\n       caption = \"SML 301\") +\n  scale_color_manual(values = c(adelie_color, chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n:::\n\n\n\n</details>\n\nComputing the likelihoods in `R`:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# L(y = A | x_2 = 50) = 2.12e-05\ndnorm(50, mean = 38.8, sd = 2.66)\n\n# L(y = C | x_2 = 50) = 0.112\ndnorm(50, mean = 48.8, sd = 3.34)\n\n# L(y = G | x_2 = 50) = 0.09317\ndnorm(50, mean = 47.5, sd = 3.08)\n```\n:::\n\n\n\nTotal probability:\n\n$$f(x_{2} = 50) = \\frac{151}{342} \\cdot 0.0000212 + \\frac{68}{342} \\cdot 0.112 + \\frac{123}{342} \\cdot 0.09317 \\approx 0.05579$$\n\nBayes' Rules:\n\n$$\\begin{array}{rcccccl}\n  f(y = A | x_{2} = 50) & = & \\frac{f(y = A) \\cdot L(y = A | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{151}{342} \\cdot 0.0000212}{0.05579} & \\approx & 0.0002 \\\\\n  f(y = C | x_{2} = 50) & = & \\frac{f(y = A) \\cdot L(y = C | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{68}{342} \\cdot 0.112}{0.05579} & \\approx & 0.3992 \\\\\n  f(y = G | x_{2} = 50) & = & \\frac{f(y = A) \\cdot L(y = G | x_{1} = 0)}{f(x_{1} = 0)} = \\frac{\\frac{123}{342} \\cdot 0.09317}{0.05579} & \\approx & 0.6006 \\\\\n\\end{array}$$\n\nThough a 50mm-long bill is relatively less common among <span style = 'color:#067476'>Gentoo</span> than among <span style = 'color:#c65ccc'>Chinstrap</span>, it follows that our naive Bayes classification, based on our prior information and penguin’s bill length alone, is that this penguin is a <span style = 'color:#067476'>Gentoo</span> – it has the highest posterior probability.\n\nWe’ve now made two naive Bayes classifications of our penguin’s species, one based solely on the fact that our penguin has below-average weight and the other based solely on its 50mm-long bill (in addition to our prior information). And these classifications **disagree**: we classified the penguin as Adelie in the former analysis and Gentoo in the latter. This discrepancy indicates that there’s *room for improvement* in our naive Bayes classification method.\n\n\n## Two Predictor Variables\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](04_classification_files/figure-html/unnamed-chunk-19-1.png){width=672}\n:::\n:::\n\n\n\n<details>\n<summary>image code</summary>\n\n\n::: {.cell}\n\n```{.r .cell-code}\npenguins |>\nggplot(aes(x = flipper_length_mm, y = bill_length_mm, \n           color = species)) + \n  geom_point(size = 3) + \n  geom_segment(aes(x = 195, y = 30, xend = 195, yend = 50),\n               color = \"black\", linetype = 2, linewidth = 2) +\n  geom_segment(aes(x = 170, y = 50, xend = 195, yend = 50),\n               color = \"black\", linetype = 2, linewidth = 2) +\n  labs(title = \"<span style = 'color:#c65ccc'>Two Predictor Variables</span>\",\n       subtitle = \"50mm-long bill and 195mm-long flipper\",\n       caption = \"SML 301\") +\n  scale_color_manual(values = c(adelie_color, chinstrap_color, gentoo_color)) +\n  theme_minimal() +\n  theme(plot.title = element_markdown(face = \"bold\", size = 24),\n        plot.subtitle = element_markdown(size = 16))\n```\n:::\n\n\n</details>\n\nGeneralizing Bayes' Rule:\n\n$$f(y | x_{2}, x_{3}) = \\frac{f(y) \\cdot L(y | x_{2}, x_{3})}{\\sum_{y'} f(y') \\cdot L(y' | x_{2}, x_{3})}$$\n\nAnother \"naive\" assumption of **conditionally independent**:\n\n$$L(y | x_{2}, x_{3}) = f(x_{2}, x_{3} | y) = f(x_{2} | y) \\cdot f(x_{3} | y)$$\n\n* mathematically efficient\n* but what about correlation?\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# sample statistics of x_3: flipper length\npenguins |> \n  group_by(species) |> \n  summarize(mean = mean(flipper_length_mm, na.rm = TRUE), \n            sd = sd(flipper_length_mm, na.rm = TRUE))\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 × 3\n  species    mean    sd\n  <fct>     <dbl> <dbl>\n1 Adelie     190.  6.54\n2 Chinstrap  196.  7.13\n3 Gentoo     217.  6.48\n```\n\n\n:::\n:::\n\n\n\nLikelihoods of a flipper length of 195 mm:\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# L(y = A | x_3 = 195) = 0.04554\ndnorm(195, mean = 190, sd = 6.54)\n\n# L(y = C | x_3 = 195) = 0.05541\ndnorm(195, mean = 196, sd = 7.13)\n\n# L(y = G | x_3 = 195) = 0.0001934\ndnorm(195, mean = 217, sd = 6.48)\n```\n:::\n\n\n\nTotal probability:\n\n$$f(x_{2} = 50, x_{3} = 195) = \\frac{151}{342} \\cdot 0.0000212 \\cdot 0.04554 + \\frac{68}{342} \\cdot 0.112 \\cdot 0.05541 + \\frac{123}{342} \\cdot 0.09317 \\cdot 0.0001931 \\approx 0.001241$$\n\nBayes' Rules:\n\n$$\\begin{array}{rcccl}\n  f(y = A | x_{2} = 50, x_{3} = 195) & = & \\frac{\\frac{151}{342} \\cdot 0.0000212 \\cdot 0.04554}{0.0001931} & \\approx & 0.0003 \\\\\n  f(y = C | x_{2} = 50, x_{3} = 195) & = & \\frac{\\frac{68}{342} \\cdot 0.112 \\cdot 0.05541}{0.0001931} & \\approx & 0.9944 \\\\\n  f(y = G | x_{2} = 50, x_{3} = 195) & = & \\frac{\\frac{123}{342} \\cdot 0.09317 \\cdot 0.0001931}{0.0001931} & \\approx & 0.0052 \\\\\n\\end{array}$$\n\nIn conclusion, our penguin is *almost certainly* a <span style = 'color:#c65ccc'>Chinstrap</span>.\n\n\n# Bayes and Logistic Regression\n\nThe class posterior distribution for a Naive Bayes classification model has the same form as multinomial logistic regression:\n\n$$p(y = c|\\vec{x}, \\vec{\\theta}) = \\displaystyle\\frac{e^{\\beta_{c}^{T}\\vec{x} + \\gamma_{c}}}{\\displaystyle\\sum_{c'=1}^{C} e^{\\beta_{c}^{T}\\vec{x} + \\gamma_{c}}}$$\n\n### Naive Bayes\n\n$$f(y | x_{1}, x_{2}, ..., x_{p}) = \\frac{f(y) \\cdot L(y | x_{1}, x_{2}, ..., x_{p})}{\\sum_{y'} f(y') \\cdot L(y' | x_{1}, x_{2}, ..., x_{p})}$$\n\n* conditionally independent $\\rightarrow$ computationally efficient\n* generalizes to more than two categories\n* assumptions violated commonly in practice\n* optimizes joint likelihood $\\displaystyle\\prod_{n} p(y_{n},\\vec{x}_{n}|\\vec{\\theta})$\n\n### Logistic Regression\n\n$$\\log\\left(\\frac{\\pi}{1-\\pi}\\right) = \\beta_{0} + \\beta_{1}X_{1} + \\cdots + \\beta_{k}X_{p}$$\n\n* binary classification\n* coefficients $\\rightarrow$ illumination of the relationships among these variables\n* optimizes conditional likelihood $\\displaystyle\\prod_{n} p(y_{n}|\\vec{x}_{n},\\vec{\\theta})$\n\n\n# Discriminative vs Generative\n\n### Advantages of discriminative classifiers\n\n* Better predictive accuracy\n* Can handle feature preprocessing\n* Well-calibrated probabilities\n\n### Advantages of generative classifiers\n\n* Easy to fit\n* Can easily handle missing input features\n* Can fit classes separately\n* Can handle unlabeled training data\n* May be more robust to spurious features\n\n\n\n::: {.cell}\n::: {.cell-output-display}\n\n```{=html}\n<div id=\"pajnzuhewh\" style=\"padding-left:0px;padding-right:0px;padding-top:10px;padding-bottom:10px;overflow-x:auto;overflow-y:auto;width:auto;height:auto;\">\n<style>#pajnzuhewh table {\n  font-family: system-ui, 'Segoe UI', Roboto, Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji', 'Segoe UI Symbol', 'Noto Color Emoji';\n  -webkit-font-smoothing: antialiased;\n  -moz-osx-font-smoothing: grayscale;\n}\n\n#pajnzuhewh thead, #pajnzuhewh tbody, #pajnzuhewh tfoot, #pajnzuhewh tr, #pajnzuhewh td, #pajnzuhewh th {\n  border-style: none;\n}\n\n#pajnzuhewh p {\n  margin: 0;\n  padding: 0;\n}\n\n#pajnzuhewh .gt_table {\n  display: table;\n  border-collapse: collapse;\n  line-height: normal;\n  margin-left: auto;\n  margin-right: auto;\n  color: #333333;\n  font-size: 16px;\n  font-weight: normal;\n  font-style: normal;\n  background-color: #FFFFFF;\n  width: auto;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #A8A8A8;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #A8A8A8;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_caption {\n  padding-top: 4px;\n  padding-bottom: 4px;\n}\n\n#pajnzuhewh .gt_title {\n  color: #333333;\n  font-size: 125%;\n  font-weight: initial;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-color: #FFFFFF;\n  border-bottom-width: 0;\n}\n\n#pajnzuhewh .gt_subtitle {\n  color: #333333;\n  font-size: 85%;\n  font-weight: initial;\n  padding-top: 3px;\n  padding-bottom: 5px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-color: #FFFFFF;\n  border-top-width: 0;\n}\n\n#pajnzuhewh .gt_heading {\n  background-color: #FFFFFF;\n  text-align: center;\n  border-bottom-color: #FFFFFF;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_bottom_border {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_col_headings {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_col_heading {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 6px;\n  padding-left: 5px;\n  padding-right: 5px;\n  overflow-x: hidden;\n}\n\n#pajnzuhewh .gt_column_spanner_outer {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: normal;\n  text-transform: inherit;\n  padding-top: 0;\n  padding-bottom: 0;\n  padding-left: 4px;\n  padding-right: 4px;\n}\n\n#pajnzuhewh .gt_column_spanner_outer:first-child {\n  padding-left: 0;\n}\n\n#pajnzuhewh .gt_column_spanner_outer:last-child {\n  padding-right: 0;\n}\n\n#pajnzuhewh .gt_column_spanner {\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: bottom;\n  padding-top: 5px;\n  padding-bottom: 5px;\n  overflow-x: hidden;\n  display: inline-block;\n  width: 100%;\n}\n\n#pajnzuhewh .gt_spanner_row {\n  border-bottom-style: hidden;\n}\n\n#pajnzuhewh .gt_group_heading {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  text-align: left;\n}\n\n#pajnzuhewh .gt_empty_group_heading {\n  padding: 0.5px;\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  vertical-align: middle;\n}\n\n#pajnzuhewh .gt_from_md > :first-child {\n  margin-top: 0;\n}\n\n#pajnzuhewh .gt_from_md > :last-child {\n  margin-bottom: 0;\n}\n\n#pajnzuhewh .gt_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  margin: 10px;\n  border-top-style: solid;\n  border-top-width: 1px;\n  border-top-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 1px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 1px;\n  border-right-color: #D3D3D3;\n  vertical-align: middle;\n  overflow-x: hidden;\n}\n\n#pajnzuhewh .gt_stub {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pajnzuhewh .gt_stub_row_group {\n  color: #333333;\n  background-color: #FFFFFF;\n  font-size: 100%;\n  font-weight: initial;\n  text-transform: inherit;\n  border-right-style: solid;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n  padding-left: 5px;\n  padding-right: 5px;\n  vertical-align: top;\n}\n\n#pajnzuhewh .gt_row_group_first td {\n  border-top-width: 2px;\n}\n\n#pajnzuhewh .gt_row_group_first th {\n  border-top-width: 2px;\n}\n\n#pajnzuhewh .gt_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pajnzuhewh .gt_first_summary_row {\n  border-top-style: solid;\n  border-top-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_first_summary_row.thick {\n  border-top-width: 2px;\n}\n\n#pajnzuhewh .gt_last_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_grand_summary_row {\n  color: #333333;\n  background-color: #FFFFFF;\n  text-transform: inherit;\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pajnzuhewh .gt_first_grand_summary_row {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-top-style: double;\n  border-top-width: 6px;\n  border-top-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_last_grand_summary_row_top {\n  padding-top: 8px;\n  padding-bottom: 8px;\n  padding-left: 5px;\n  padding-right: 5px;\n  border-bottom-style: double;\n  border-bottom-width: 6px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_striped {\n  background-color: rgba(128, 128, 128, 0.05);\n}\n\n#pajnzuhewh .gt_table_body {\n  border-top-style: solid;\n  border-top-width: 2px;\n  border-top-color: #D3D3D3;\n  border-bottom-style: solid;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_footnotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_footnote {\n  margin: 0px;\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pajnzuhewh .gt_sourcenotes {\n  color: #333333;\n  background-color: #FFFFFF;\n  border-bottom-style: none;\n  border-bottom-width: 2px;\n  border-bottom-color: #D3D3D3;\n  border-left-style: none;\n  border-left-width: 2px;\n  border-left-color: #D3D3D3;\n  border-right-style: none;\n  border-right-width: 2px;\n  border-right-color: #D3D3D3;\n}\n\n#pajnzuhewh .gt_sourcenote {\n  font-size: 90%;\n  padding-top: 4px;\n  padding-bottom: 4px;\n  padding-left: 5px;\n  padding-right: 5px;\n}\n\n#pajnzuhewh .gt_left {\n  text-align: left;\n}\n\n#pajnzuhewh .gt_center {\n  text-align: center;\n}\n\n#pajnzuhewh .gt_right {\n  text-align: right;\n  font-variant-numeric: tabular-nums;\n}\n\n#pajnzuhewh .gt_font_normal {\n  font-weight: normal;\n}\n\n#pajnzuhewh .gt_font_bold {\n  font-weight: bold;\n}\n\n#pajnzuhewh .gt_font_italic {\n  font-style: italic;\n}\n\n#pajnzuhewh .gt_super {\n  font-size: 65%;\n}\n\n#pajnzuhewh .gt_footnote_marks {\n  font-size: 75%;\n  vertical-align: 0.4em;\n  position: initial;\n}\n\n#pajnzuhewh .gt_asterisk {\n  font-size: 100%;\n  vertical-align: 0;\n}\n\n#pajnzuhewh .gt_indent_1 {\n  text-indent: 5px;\n}\n\n#pajnzuhewh .gt_indent_2 {\n  text-indent: 10px;\n}\n\n#pajnzuhewh .gt_indent_3 {\n  text-indent: 15px;\n}\n\n#pajnzuhewh .gt_indent_4 {\n  text-indent: 20px;\n}\n\n#pajnzuhewh .gt_indent_5 {\n  text-indent: 25px;\n}\n\n#pajnzuhewh .katex-display {\n  display: inline-flex !important;\n  margin-bottom: 0.75em !important;\n}\n\n#pajnzuhewh div.Reactable > div.rt-table > div.rt-thead > div.rt-tr.rt-tr-group-header > div.rt-th-group:after {\n  height: 0px !important;\n}\n</style>\n<table class=\"gt_table\" data-quarto-disable-processing=\"false\" data-quarto-bootstrap=\"false\">\n  <thead>\n    <tr class=\"gt_heading\">\n      <td colspan=\"2\" class=\"gt_heading gt_title gt_font_normal gt_bottom_border\" style>Types of Classification Techniques<span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span></td>\n    </tr>\n    \n    <tr class=\"gt_col_headings\">\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"discriminative_classifiers\">Discriminative Classifiers</th>\n      <th class=\"gt_col_heading gt_columns_bottom_border gt_center\" rowspan=\"1\" colspan=\"1\" scope=\"col\" id=\"generative_classifiers\">Generative Classifiers</th>\n    </tr>\n  </thead>\n  <tbody class=\"gt_table_body\">\n    <tr><td headers=\"discriminative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #F9E3D6;\">Logistic regression</td>\n<td headers=\"generative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #E0FFFF;\">Naive Bayes</td></tr>\n    <tr><td headers=\"discriminative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #F9E3D6;\">Support vector machines</td>\n<td headers=\"generative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #E0FFFF;\">Bayesian networks</td></tr>\n    <tr><td headers=\"discriminative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #F9E3D6;\">Neural networks</td>\n<td headers=\"generative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #E0FFFF;\">Markov random fields</td></tr>\n    <tr><td headers=\"discriminative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #F9E3D6;\">Nearest neighbor</td>\n<td headers=\"generative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #E0FFFF;\">Hidden Markov Models</td></tr>\n    <tr><td headers=\"discriminative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #F9E3D6;\">Conditional Random Fields</td>\n<td headers=\"generative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #E0FFFF;\">Latent Dirichlet Allocation</td></tr>\n    <tr><td headers=\"discriminative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #F9E3D6;\">Random Forests</td>\n<td headers=\"generative_classifiers\" class=\"gt_row gt_center\" style=\"background-color: #E0FFFF;\">Generative Adversarial Networks</td></tr>\n  </tbody>\n  \n  <tfoot class=\"gt_footnotes\">\n    <tr>\n      <td class=\"gt_footnote\" colspan=\"2\"><span class=\"gt_footnote_marks\" style=\"white-space:nowrap;font-style:italic;font-weight:normal;line-height:0;\"><sup>1</sup></span> Source: https://www.analyticsvidhya.com/blog/2021/07/deep-understanding-of-discriminative-and-generative-models-in-machine-learning/</td>\n    </tr>\n  </tfoot>\n</table>\n</div>\n```\n\n:::\n:::\n\n\n\n\n# Quo Vadimus?\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n* due this Friday (5 PM):\n\n    - Precept 2\n\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n* Advice: You will be asked to pick teammates for project groups next week, so take some time to talk with your classmates\n\n:::\n\n::::\n\n\n# Footnotes\n\n::: {.callout-note collapse=\"true\"}\n\n## (optional) Additional Resources\n\n* [Logistic Regression in Python](https://medium.com/towards-data-science/building-a-logistic-regression-in-python-step-by-step-becd4d56c9c8) by Susan Li\n* [Naive Bayes in Python](https://medium.com/@shuv.sdr/na%C3%AFve-bayes-classification-in-python-f869c2e0dbf1) by Shuvrajyoti Debroy\n\n* [Naive Bayes (from scratch)](https://machinelearningmastery.com/naive-bayes-classifier-scratch-python/) by Jason Brownlee\n\n\n:::\n\n::: {.callout-note collapse=\"true\"}\n## Session Info\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsessionInfo()\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nR version 4.4.2 (2024-10-31 ucrt)\nPlatform: x86_64-w64-mingw32/x64\nRunning under: Windows 10 x64 (build 19045)\n\nMatrix products: default\n\n\nlocale:\n[1] LC_COLLATE=English_United States.utf8 \n[2] LC_CTYPE=English_United States.utf8   \n[3] LC_MONETARY=English_United States.utf8\n[4] LC_NUMERIC=C                          \n[5] LC_TIME=English_United States.utf8    \n\ntime zone: America/New_York\ntzcode source: internal\n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nother attached packages:\n[1] palmerpenguins_0.1.1 tidyr_1.3.1          janitor_2.2.0       \n[4] gt_0.11.1            ggtext_0.1.2         ggplot2_3.5.1       \n[7] dplyr_1.1.4          bayesrules_0.0.2    \n\nloaded via a namespace (and not attached):\n  [1] gridExtra_2.3        inline_0.3.19        rlang_1.1.5         \n  [4] magrittr_2.0.3       snakecase_0.11.1     matrixStats_1.4.1   \n  [7] e1071_1.7-16         compiler_4.4.2       loo_2.8.0           \n [10] vctrs_0.6.5          reshape2_1.4.4       stringr_1.5.1       \n [13] pkgconfig_2.0.3      fastmap_1.2.0        backports_1.5.0     \n [16] labeling_0.4.3       utf8_1.2.4           threejs_0.3.3       \n [19] promises_1.3.0       rmarkdown_2.29       markdown_1.13       \n [22] nloptr_2.1.1         purrr_1.0.2          xfun_0.50           \n [25] jsonlite_1.8.9       later_1.3.2          parallel_4.4.2      \n [28] R6_2.5.1             dygraphs_1.1.1.6     stringi_1.8.4       \n [31] StanHeaders_2.32.10  boot_1.3-31          lubridate_1.9.3     \n [34] Rcpp_1.0.12          rstan_2.32.6         knitr_1.49          \n [37] zoo_1.8-12           base64enc_0.1-3      bayesplot_1.11.1    \n [40] httpuv_1.6.15        Matrix_1.7-1         splines_4.4.2       \n [43] igraph_2.1.4         timechange_0.3.0     tidyselect_1.2.1    \n [46] rstudioapi_0.17.1    abind_1.4-8          yaml_2.3.10         \n [49] codetools_0.2-20     miniUI_0.1.1.1       curl_5.2.3          \n [52] pkgbuild_1.4.6       lattice_0.22-6       tibble_3.2.1        \n [55] plyr_1.8.9           shiny_1.9.1          withr_3.0.2         \n [58] groupdata2_2.0.3     posterior_1.6.0      evaluate_1.0.3      \n [61] survival_3.7-0       proxy_0.4-27         RcppParallel_5.1.9  \n [64] xts_0.14.0           xml2_1.3.6           pillar_1.10.1       \n [67] tensorA_0.36.2.1     checkmate_2.3.2      DT_0.33             \n [70] stats4_4.4.2         shinyjs_2.1.0        distributional_0.5.0\n [73] generics_0.1.3       commonmark_1.9.2     rstantools_2.4.0    \n [76] munsell_0.5.1        scales_1.3.0         minqa_1.2.8         \n [79] gtools_3.9.5         xtable_1.8-4         class_7.3-22        \n [82] glue_1.8.0           tools_4.4.2          shinystan_2.6.0     \n [85] lme4_1.1-35.5        colourpicker_1.3.0   grid_4.4.2          \n [88] QuickJSR_1.4.0       crosstalk_1.2.1      colorspace_2.1-1    \n [91] nlme_3.1-166         cli_3.6.3            V8_6.0.0            \n [94] gtable_0.3.6         sass_0.4.9           digest_0.6.37       \n [97] farver_2.1.2         htmlwidgets_1.6.4    htmltools_0.5.8.1   \n[100] lifecycle_1.0.4      mime_0.12            rstanarm_2.32.1     \n[103] gridtext_0.1.5       shinythemes_1.2.0    MASS_7.3-61         \n```\n\n\n:::\n:::\n\n\n:::\n\n\n:::: {.columns}\n\n::: {.column width=\"45%\"}\n\t\n:::\n\n::: {.column width=\"10%\"}\n\t\n:::\n\n::: {.column width=\"45%\"}\n\n:::\n\n::::\n\n::::: {.panel-tabset}\n\n\n\n:::::",
    "supporting": [
      "04_classification_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}